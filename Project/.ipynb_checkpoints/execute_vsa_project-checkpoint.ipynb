{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab56392-9bd5-48da-aef6-5dddab880329",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f493cf4-15f9-4d57-b16c-cb3ee2b33977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "  RUNNING PARALLEL MULTI-TIMEFRAME SCAN ON ALL EXCHANGES\n",
      "================================================================================\n",
      "\n",
      "• Exchanges: binance_spot, gateio_spot\n",
      "• Timeframes: 1w\n",
      "• Strategies: consolidation\n",
      "• Notifications: Enabled\n",
      "• Recipients: default\n",
      "• Start time: 10:55:39\n",
      "\n",
      "Fetching market data...\n",
      "\n",
      "Processing 1w timeframe\n",
      "[10:55:39] Starting scan on binance_spot for 1w timeframe...\n",
      "[10:55:39] Starting scan on gateio_spot for 1w timeframe...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Added /home/jovyan/work/Crypto/sevenfigures-bot/hbs_2025/Project/Project to sys.path\n",
      "✓ Added /home/jovyan/work/Crypto/sevenfigures-bot/hbs_2025/Project to sys.path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 409 markets on Binance Spot for 1w timeframe\n",
      "Processing 409 symbols for Binance Spot...\n",
      "Found 2512 markets on Gateio for 1w timeframe\n",
      "Processing 2512 symbols for Gateio...\n",
      "consolidation detected for AMPUSDT (current bar)\n",
      "consolidation detected for AMPUSDT\n",
      "consolidation detected for DEGOUSDT (current bar)\n",
      "consolidation detected for DEXEUSDT (current bar)\n",
      "consolidation detected for DFUSDT (current bar)\n",
      "consolidation detected for DEGOUSDT\n",
      "consolidation detected for DEXEUSDT\n",
      "consolidation detected for DFUSDT\n",
      "consolidation detected for FDUSDUSDT (last closed bar)\n",
      "consolidation detected for FDUSDUSDT (current bar)\n",
      "consolidation detected for FDUSDUSDT\n",
      "consolidation detected for IQUSDT (last closed bar)\n",
      "consolidation detected for IQUSDT (current bar)\n",
      "consolidation detected for IQUSDT\n",
      "consolidation detected for KAVAUSDT (last closed bar)\n",
      "consolidation detected for KAVAUSDT\n",
      "consolidation detected for MASKUSDT (last closed bar)\n",
      "consolidation detected for MASKUSDT (current bar)\n",
      "consolidation detected for MASKUSDT\n",
      "consolidation detected for OXTUSDT (last closed bar)\n",
      "consolidation detected for OXTUSDT (current bar)\n",
      "consolidation detected for OXTUSDT\n",
      "consolidation detected for PAXGUSDT (current bar)\n",
      "consolidation detected for PAXGUSDT\n",
      "consolidation detected for PONDUSDT (last closed bar)\n",
      "consolidation detected for PONDUSDT (current bar)\n",
      "consolidation detected for PONDUSDT\n",
      "consolidation detected for BADGER_USDT (current bar)\n",
      "consolidation detected for BADGER_USDT\n",
      "consolidation detected for RADUSDT (last closed bar)\n",
      "consolidation detected for RADUSDT (current bar)\n",
      "consolidation detected for RADUSDT\n",
      "consolidation detected for SOLVUSDT (last closed bar)\n",
      "consolidation detected for SOLVUSDT (current bar)\n",
      "consolidation detected for STGUSDT (last closed bar)\n",
      "consolidation detected for STGUSDT (current bar)\n",
      "consolidation detected for SOLVUSDT\n",
      "consolidation detected for STGUSDT\n",
      "consolidation detected for TONUSDT (last closed bar)\n",
      "consolidation detected for TONUSDT (current bar)\n",
      "consolidation detected for TRUMPUSDT (last closed bar)\n",
      "consolidation detected for TRUMPUSDT (current bar)\n",
      "consolidation detected for TONUSDT\n",
      "consolidation detected for TRUMPUSDT\n",
      "consolidation detected for TUSDUSDT (last closed bar)\n",
      "consolidation detected for TUSDUSDT (current bar)\n",
      "consolidation detected for USDCUSDT (last closed bar)\n",
      "consolidation detected for USDCUSDT (current bar)\n",
      "consolidation detected for TUSDUSDT\n",
      "consolidation detected for USDCUSDT\n",
      "consolidation detected for USDPUSDT (last closed bar)\n",
      "consolidation detected for USDPUSDT (current bar)\n",
      "consolidation detected for USDPUSDT\n",
      "consolidation detected for VTHOUSDT (current bar)\n",
      "consolidation detected for WINUSDT (last closed bar)\n",
      "consolidation detected for VTHOUSDT\n",
      "consolidation detected for WINUSDT\n",
      "[10:56:36] ✓ Completed binance_spot scan: 21 signals found\n",
      "consolidation detected for DAI_USDT (last closed bar)\n",
      "consolidation detected for DAI_USDT (current bar)\n",
      "consolidation detected for DAO_USDT (last closed bar)\n",
      "consolidation detected for DAO_USDT (current bar)\n",
      "consolidation detected for DAI_USDT\n",
      "consolidation detected for DAO_USDT\n",
      "consolidation detected for DEGO_USDT (last closed bar)\n",
      "consolidation detected for DEGO_USDT (current bar)\n",
      "consolidation detected for DEGO_USDT\n",
      "consolidation detected for DEXE_USDT (current bar)\n",
      "consolidation detected for DEXE_USDT\n",
      "consolidation detected for ELA_USDT (last closed bar)\n",
      "consolidation detected for ELA_USDT (current bar)\n",
      "consolidation detected for ELA_USDT\n",
      "consolidation detected for FDUSD_USDT (last closed bar)\n",
      "consolidation detected for FDUSD_USDT (current bar)\n",
      "consolidation detected for FDUSD_USDT\n",
      "consolidation detected for INTER_USDT (last closed bar)\n",
      "consolidation detected for INTER_USDT (current bar)\n",
      "consolidation detected for INTER_USDT\n",
      "consolidation detected for KAVA_USDT (last closed bar)\n",
      "consolidation detected for KAVA_USDT\n",
      "consolidation detected for LEO_USDT (last closed bar)\n",
      "consolidation detected for LEO_USDT (current bar)\n",
      "consolidation detected for LEO_USDT\n",
      "consolidation detected for MASK_USDT (last closed bar)\n",
      "consolidation detected for MASK_USDT (current bar)\n",
      "consolidation detected for MASK_USDT\n",
      "consolidation detected for OMG_USDT (last closed bar)\n",
      "consolidation detected for OMG_USDT (current bar)\n",
      "consolidation detected for OMG_USDT\n",
      "consolidation detected for PUFF_USDT (last closed bar)\n",
      "consolidation detected for PUFF_USDT (current bar)\n",
      "consolidation detected for PUFF_USDT\n",
      "consolidation detected for RAD_USDT (last closed bar)\n",
      "consolidation detected for RAD_USDT (current bar)\n",
      "consolidation detected for RAD_USDT\n",
      "consolidation detected for TON_USDT (last closed bar)\n",
      "consolidation detected for TON_USDT (current bar)\n",
      "consolidation detected for TON_USDT\n",
      "consolidation detected for TRUMP_USDT (last closed bar)\n",
      "consolidation detected for TRUMP_USDT (current bar)\n",
      "consolidation detected for TRUMP_USDT\n",
      "consolidation detected for TUSD_USDT (last closed bar)\n",
      "consolidation detected for TUSD_USDT (current bar)\n",
      "consolidation detected for TUSD_USDT\n",
      "consolidation detected for XTTA_USDT (last closed bar)\n",
      "consolidation detected for XTTA_USDT (current bar)\n",
      "consolidation detected for XTTA_USDT\n",
      "[11:02:08] ✓ Completed gateio_spot scan: 18 signals found\n",
      "\n",
      "================================================================================\n",
      "  PARALLEL MULTI-TIMEFRAME MULTI-EXCHANGE SCAN RESULTS\n",
      "================================================================================\n",
      "\n",
      "Total signals found across all exchanges and timeframes: 39\n",
      "Start time: 10:55:39\n",
      "End time: 11:02:10\n",
      "Duration: 0:06:31\n",
      "\n",
      "Consolidation: 39 signals\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>close</th>\n",
       "      <th>current_bar</th>\n",
       "      <th>bars_inside</th>\n",
       "      <th>min_bars_inside_req</th>\n",
       "      <th>height_pct</th>\n",
       "      <th>max_height_pct_req</th>\n",
       "      <th>atr_ok</th>\n",
       "      <th>range_high</th>\n",
       "      <th>range_low</th>\n",
       "      <th>range_mid</th>\n",
       "      <th>timeframe</th>\n",
       "      <th>exchange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AMPUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31.180108</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004393</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.003801</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEGOUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.246000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.993614</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>0.969000</td>\n",
       "      <td>1.174500</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEXEUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>7.308000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.259269</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8.849000</td>\n",
       "      <td>6.795000</td>\n",
       "      <td>7.822000</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DFUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.029880</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.606595</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.035930</td>\n",
       "      <td>0.025330</td>\n",
       "      <td>0.030630</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDUSDUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.997500</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270419</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.997100</td>\n",
       "      <td>0.998450</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IQUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.003671</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>28.460543</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004415</td>\n",
       "      <td>0.003315</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KAVAUSDT</td>\n",
       "      <td>2025-08-04</td>\n",
       "      <td>0.393400</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>17.738038</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450500</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MASKUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.353000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33.284884</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.605000</td>\n",
       "      <td>1.147000</td>\n",
       "      <td>1.376000</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OXTUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>23.681936</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.051000</td>\n",
       "      <td>0.057850</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PAXGUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>3346.890000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.805706</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3434.520000</td>\n",
       "      <td>3273.340000</td>\n",
       "      <td>3353.930000</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PONDUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.008210</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>29.616519</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.009730</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.008475</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RADUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.673000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>29.517639</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.797000</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.694500</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SOLVUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.041620</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>21.100410</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049930</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>0.045165</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>STGUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>35.135135</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.177600</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TONUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>3.507000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31.920817</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.749000</td>\n",
       "      <td>2.717000</td>\n",
       "      <td>3.233000</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TRUMPUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>9.450000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.299754</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11.920000</td>\n",
       "      <td>8.430000</td>\n",
       "      <td>10.175000</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TUSDUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.997250</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>USDCUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.150038</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.000500</td>\n",
       "      <td>0.999000</td>\n",
       "      <td>0.999750</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>USDPUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.999400</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.847162</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.007600</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>1.003350</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>VTHOUSDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33.451286</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WINUSDT</td>\n",
       "      <td>2025-08-04</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40.526043</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>1w</td>\n",
       "      <td>binance_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BADGER_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.070900</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31.318956</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.273700</td>\n",
       "      <td>0.928800</td>\n",
       "      <td>1.101250</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DAI_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.999650</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.336587</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.008500</td>\n",
       "      <td>0.995110</td>\n",
       "      <td>1.001805</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>DAO_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.124990</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>35.779321</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.163790</td>\n",
       "      <td>0.114080</td>\n",
       "      <td>0.138935</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>DEGO_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.243300</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.706510</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.374500</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>1.171250</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DEXE_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>7.290000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>26.034670</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>8.834000</td>\n",
       "      <td>6.799000</td>\n",
       "      <td>7.816500</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ELA_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.290500</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>40.047377</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.722700</td>\n",
       "      <td>1.147900</td>\n",
       "      <td>1.435300</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>FDUSD_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.997700</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.370797</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.997850</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>INTER_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.602700</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>50.193050</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.793800</td>\n",
       "      <td>0.475300</td>\n",
       "      <td>0.634550</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KAVA_USDT</td>\n",
       "      <td>2025-08-04</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>17.610823</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.450400</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.413950</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LEO_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>9.273000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>7.548430</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>9.321000</td>\n",
       "      <td>8.643000</td>\n",
       "      <td>8.982000</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MASK_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>1.349000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>33.163636</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1.603000</td>\n",
       "      <td>1.147000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>OMG_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.186560</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31.185440</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.235000</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>PUFF_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>38.045752</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.088190</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RAD_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.674500</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>29.349470</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>0.592200</td>\n",
       "      <td>0.694050</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>TON_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>3.509000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31.832947</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>3.747000</td>\n",
       "      <td>2.718000</td>\n",
       "      <td>3.232500</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TRUMP_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>9.477000</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>34.157370</td>\n",
       "      <td>35.0</td>\n",
       "      <td>True</td>\n",
       "      <td>11.911000</td>\n",
       "      <td>8.436000</td>\n",
       "      <td>10.173500</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TUSD_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.997600</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.371318</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.998300</td>\n",
       "      <td>0.994600</td>\n",
       "      <td>0.996450</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>XTTA_USDT</td>\n",
       "      <td>2025-08-11</td>\n",
       "      <td>0.325680</td>\n",
       "      <td>True</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>18.824085</td>\n",
       "      <td>35.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.347520</td>\n",
       "      <td>0.287730</td>\n",
       "      <td>0.317625</td>\n",
       "      <td>1w</td>\n",
       "      <td>gateio_spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         symbol       date        close  current_bar  bars_inside  \\\n",
       "0       AMPUSDT 2025-08-11     0.003712         True          7.0   \n",
       "1      DEGOUSDT 2025-08-11     1.246000         True          7.0   \n",
       "2      DEXEUSDT 2025-08-11     7.308000         True          7.0   \n",
       "3        DFUSDT 2025-08-11     0.029880         True          7.0   \n",
       "4     FDUSDUSDT 2025-08-11     0.997500         True          7.0   \n",
       "5        IQUSDT 2025-08-11     0.003671         True          7.0   \n",
       "6      KAVAUSDT 2025-08-04     0.393400        False          7.0   \n",
       "7      MASKUSDT 2025-08-11     1.353000         True          7.0   \n",
       "8       OXTUSDT 2025-08-11     0.057700         True          7.0   \n",
       "9      PAXGUSDT 2025-08-11  3346.890000         True          7.0   \n",
       "10     PONDUSDT 2025-08-11     0.008210         True          7.0   \n",
       "11      RADUSDT 2025-08-11     0.673000         True          7.0   \n",
       "12     SOLVUSDT 2025-08-11     0.041620         True          7.0   \n",
       "13      STGUSDT 2025-08-11     0.183500         True          7.0   \n",
       "14      TONUSDT 2025-08-11     3.507000         True          7.0   \n",
       "15    TRUMPUSDT 2025-08-11     9.450000         True          7.0   \n",
       "16     TUSDUSDT 2025-08-11     0.997700         True          7.0   \n",
       "17     USDCUSDT 2025-08-11     0.999400         True          7.0   \n",
       "18     USDPUSDT 2025-08-11     0.999400         True          7.0   \n",
       "19     VTHOUSDT 2025-08-11     0.001971         True          7.0   \n",
       "20      WINUSDT 2025-08-04     0.000062        False          7.0   \n",
       "21  BADGER_USDT 2025-08-11     1.070900         True          7.0   \n",
       "22     DAI_USDT 2025-08-11     0.999650         True          7.0   \n",
       "23     DAO_USDT 2025-08-11     0.124990         True          7.0   \n",
       "24    DEGO_USDT 2025-08-11     1.243300         True          7.0   \n",
       "25    DEXE_USDT 2025-08-11     7.290000         True          7.0   \n",
       "26     ELA_USDT 2025-08-11     1.290500         True          7.0   \n",
       "27   FDUSD_USDT 2025-08-11     0.997700         True          7.0   \n",
       "28   INTER_USDT 2025-08-11     0.602700         True          7.0   \n",
       "29    KAVA_USDT 2025-08-04     0.393000        False          7.0   \n",
       "30     LEO_USDT 2025-08-11     9.273000         True          7.0   \n",
       "31    MASK_USDT 2025-08-11     1.349000         True          7.0   \n",
       "32     OMG_USDT 2025-08-11     0.186560         True          7.0   \n",
       "33    PUFF_USDT 2025-08-11     0.084400         True          7.0   \n",
       "34     RAD_USDT 2025-08-11     0.674500         True          7.0   \n",
       "35     TON_USDT 2025-08-11     3.509000         True          7.0   \n",
       "36   TRUMP_USDT 2025-08-11     9.477000         True          7.0   \n",
       "37    TUSD_USDT 2025-08-11     0.997600         True          7.0   \n",
       "38    XTTA_USDT 2025-08-11     0.325680         True          7.0   \n",
       "\n",
       "    min_bars_inside_req  height_pct  max_height_pct_req  atr_ok   range_high  \\\n",
       "0                     4   31.180108                35.0    True     0.004393   \n",
       "1                     4   34.993614                35.0    True     1.380000   \n",
       "2                     4   26.259269                35.0    True     8.849000   \n",
       "3                     4   34.606595                35.0    True     0.035930   \n",
       "4                     4    0.270419                35.0    True     0.999800   \n",
       "5                     4   28.460543                35.0   False     0.004415   \n",
       "6                     4   17.738038                35.0    True     0.450500   \n",
       "7                     4   33.284884                35.0    True     1.605000   \n",
       "8                     4   23.681936                35.0   False     0.064700   \n",
       "9                     4    4.805706                35.0    True  3434.520000   \n",
       "10                    4   29.616519                35.0    True     0.009730   \n",
       "11                    4   29.517639                35.0   False     0.797000   \n",
       "12                    4   21.100410                35.0    True     0.049930   \n",
       "13                    4   35.135135                35.0   False     0.208800   \n",
       "14                    4   31.920817                35.0   False     3.749000   \n",
       "15                    4   34.299754                35.0    True    11.920000   \n",
       "16                    4    0.250689                35.0    True     0.998500   \n",
       "17                    4    0.150038                35.0   False     1.000500   \n",
       "18                    4    0.847162                35.0   False     1.007600   \n",
       "19                    4   33.451286                35.0    True     0.002474   \n",
       "20                    4   40.526043                35.0   False     0.000069   \n",
       "21                    4   31.318956                35.0    True     1.273700   \n",
       "22                    4    1.336587                35.0   False     1.008500   \n",
       "23                    4   35.779321                35.0    True     0.163790   \n",
       "24                    4   34.706510                35.0    True     1.374500   \n",
       "25                    4   26.034670                35.0    True     8.834000   \n",
       "26                    4   40.047377                35.0    True     1.722700   \n",
       "27                    4    0.370797                35.0   False     0.999700   \n",
       "28                    4   50.193050                35.0   False     0.793800   \n",
       "29                    4   17.610823                35.0    True     0.450400   \n",
       "30                    4    7.548430                35.0    True     9.321000   \n",
       "31                    4   33.163636                35.0    True     1.603000   \n",
       "32                    4   31.185440                35.0    True     0.235000   \n",
       "33                    4   38.045752                35.0   False     0.088190   \n",
       "34                    4   29.349470                35.0   False     0.795900   \n",
       "35                    4   31.832947                35.0   False     3.747000   \n",
       "36                    4   34.157370                35.0    True    11.911000   \n",
       "37                    4    0.371318                35.0   False     0.998300   \n",
       "38                    4   18.824085                35.0   False     0.347520   \n",
       "\n",
       "      range_low    range_mid timeframe      exchange  \n",
       "0      0.003208     0.003801        1w  binance_spot  \n",
       "1      0.969000     1.174500        1w  binance_spot  \n",
       "2      6.795000     7.822000        1w  binance_spot  \n",
       "3      0.025330     0.030630        1w  binance_spot  \n",
       "4      0.997100     0.998450        1w  binance_spot  \n",
       "5      0.003315     0.003865        1w  binance_spot  \n",
       "6      0.377100     0.413800        1w  binance_spot  \n",
       "7      1.147000     1.376000        1w  binance_spot  \n",
       "8      0.051000     0.057850        1w  binance_spot  \n",
       "9   3273.340000  3353.930000        1w  binance_spot  \n",
       "10     0.007220     0.008475        1w  binance_spot  \n",
       "11     0.592000     0.694500        1w  binance_spot  \n",
       "12     0.040400     0.045165        1w  binance_spot  \n",
       "13     0.146400     0.177600        1w  binance_spot  \n",
       "14     2.717000     3.233000        1w  binance_spot  \n",
       "15     8.430000    10.175000        1w  binance_spot  \n",
       "16     0.996000     0.997250        1w  binance_spot  \n",
       "17     0.999000     0.999750        1w  binance_spot  \n",
       "18     0.999100     1.003350        1w  binance_spot  \n",
       "19     0.001765     0.002119        1w  binance_spot  \n",
       "20     0.000046     0.000058        1w  binance_spot  \n",
       "21     0.928800     1.101250        1w   gateio_spot  \n",
       "22     0.995110     1.001805        1w   gateio_spot  \n",
       "23     0.114080     0.138935        1w   gateio_spot  \n",
       "24     0.968000     1.171250        1w   gateio_spot  \n",
       "25     6.799000     7.816500        1w   gateio_spot  \n",
       "26     1.147900     1.435300        1w   gateio_spot  \n",
       "27     0.996000     0.997850        1w   gateio_spot  \n",
       "28     0.475300     0.634550        1w   gateio_spot  \n",
       "29     0.377500     0.413950        1w   gateio_spot  \n",
       "30     8.643000     8.982000        1w   gateio_spot  \n",
       "31     1.147000     1.375000        1w   gateio_spot  \n",
       "32     0.171600     0.203300        1w   gateio_spot  \n",
       "33     0.060000     0.074095        1w   gateio_spot  \n",
       "34     0.592200     0.694050        1w   gateio_spot  \n",
       "35     2.718000     3.232500        1w   gateio_spot  \n",
       "36     8.436000    10.173500        1w   gateio_spot  \n",
       "37     0.994600     0.996450        1w   gateio_spot  \n",
       "38     0.287730     0.317625        1w   gateio_spot  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scan completed!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Run Simple Parallel Scan for Test Bar\n",
    "\n",
    "This script runs the test bar scan across multiple exchanges in parallel\n",
    "using a simplified parallel scanning approach that avoids console output issues.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "# Add project directory to path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "print(f\"✓ Added {os.getcwd()} to sys.path\")\n",
    "\n",
    "# Import the simple parallel scanner\n",
    "from run_parallel_scanner import run_parallel_exchanges, run_parallel_multi_timeframes_all_exchanges\n",
    "from scanner.main import kline_cache\n",
    "\n",
    "# Define exchanges\n",
    "futures_exchanges = [\"binance_futures\", \"bybit_futures\", \"mexc_futures\", \"gateio_futures\"]\n",
    "spot_exchanges = [\"binance_spot\", \"bybit_spot\", \"kucoin_spot\", \"mexc_spot\", \"gateio_spot\"]\n",
    "spot_exchanges_1w = [\"binance_spot\", \"bybit_spot\", \"gateio_spot\"]\n",
    "\n",
    "async def main():\n",
    "    # Clear cache for fresh data\n",
    "    kline_cache.clear()\n",
    "    \n",
    "    \"\"\"\n",
    "    # Run parallel scan for test bar strategy on spot exchanges\n",
    "    result = await run_parallel_exchanges(\n",
    "        timeframe=\"4h\",                    # Example timeframe\n",
    "        strategies=[\"confluence\", \"test_bar\", \"consolidation\"],\n",
    "        # strategies=[\"reversal_bar\"],       \n",
    "        exchanges=spot_exchanges,          # Spot exchanges to scan\n",
    "        users=[\"default\"],                 # Recipients for Telegram notifications\n",
    "        send_telegram=True,                # Enable Telegram notifications\n",
    "        min_volume_usd=None                # Use default volume threshold\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Run multi-timeframe parallel scan\n",
    "    result = await run_parallel_multi_timeframes_all_exchanges(\n",
    "        timeframes=[\"2d\", \"3d\", \"1w\"],     # Multiple timeframes\n",
    "        strategies=[\"consolidation\"],        # Strategies to scan\n",
    "        exchanges=[\"binance_spot\", \"binance_futures\", \"bybit_spot\", \"kucoin_spot\", \"mexc_spot\", \"gateio_spot\"],          # Exchanges to scan\n",
    "        users=[\"default\"],                 # Recipients for notifications\n",
    "        send_telegram=True,                # Enable notifications\n",
    "        min_volume_usd=None                # Use default volume threshold\n",
    "    )\n",
    "     #\"\"\"\n",
    "    \n",
    "    print(\"Scan completed!\")\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c86d73-1174-45d1-b215-842f2609b235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 CONFLUENCE SCANNER WITH QUOTE CURRENCY OPTIONS\n",
      "==================================================\n",
      "Available functions:\n",
      "• await main() - Run with default settings\n",
      "• await scan_current_confluence_usdt() - Scan current candle (USDT)\n",
      "• await scan_closed_confluence_usdt() - Scan last closed candle (USDT)\n",
      "• await scan_current_confluence_btc() - Scan current candle (BTC)\n",
      "• await scan_closed_confluence_btc() - Scan last closed candle (BTC)\n",
      "• await run_confluence_scanner('Exchange', 'timeframe', 'quote_currency', offset) - Custom scan\n",
      "\n",
      "Example: await run_confluence_scanner('Mexc', '1w', 'BTC', 1)\n",
      "Starting Confluence scan for last closed candle on Mexc 1w (USDT pairs)...\n",
      "Scanning for Confluence patterns in last closed candle...\n",
      "Quote currency: USDT\n",
      "Minimum volume threshold: $300,000.00\n",
      "Fetching pairs from Mexc...\n",
      "Fetching pairs for exchange: Mexc\n",
      "Found 1669 USDT pairs to scan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: NEXM/USDT (75 candles):   4% 73/1669 [00:04<02:08, 12.46it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: DCB/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: HYPC/USDT (101 candles):  15% 246/1669 [00:15<01:44, 13.66it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: VISTA/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: VIA/USDT (78 candles):  15% 258/1669 [00:17<02:13, 10.60it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: PKR/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: DEXTF/USDT (101 candles):  24% 400/1669 [00:27<01:29, 14.16it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: DEXTF/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: KALIS/USDT (74 candles):  24% 407/1669 [00:28<01:38, 12.80it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: LNQ/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: WRKX/USDT (94 candles):  25% 412/1669 [00:28<01:58, 10.58it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: DDMT/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: PNK/USDT (101 candles):  31% 516/1669 [00:37<01:43, 11.12it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: UBX/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: SWAP/USDT (101 candles):  40% 674/1669 [00:49<01:11, 13.99it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 500: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: UNP/USDT (82 candles):  42% 703/1669 [00:51<01:46,  9.05it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: APEX/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: HKTM/USDT (53 candles):  44% 731/1669 [00:54<01:20, 11.60it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: SNEK/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: OG/USDT (101 candles):  45% 756/1669 [00:56<01:20, 11.36it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: AUKI/USDT 🎯\n",
      "Found Confluence: OG/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: ATRS/USDT (50 candles):  48% 807/1669 [01:00<01:17, 11.19it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: MBD/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: SXCH/USDT (64 candles):  51% 856/1669 [01:04<01:08, 11.93it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: PORTO/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: NEXA/USDT (101 candles):  52% 875/1669 [01:06<01:01, 12.99it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: ITGR/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: HANDY/USDT (101 candles):  53% 885/1669 [01:07<01:11, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: SMX/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: FOR/USDT (101 candles):  54% 901/1669 [01:08<01:11, 10.73it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: ALVA/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: MOTHER/USDT (64 candles):  62% 1043/1669 [01:21<00:56, 11.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: MAS/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: JUNO/USDT (101 candles):  65% 1079/1669 [01:25<00:56, 10.51it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: SIX/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: 5IRE/USDT (86 candles):  67% 1119/1669 [01:28<00:38, 14.32it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 500: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: EL/USDT (101 candles):  72% 1196/1669 [01:35<00:56,  8.34it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: JUSTICE/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: BICITY/USDT (62 candles):  72% 1210/1669 [01:36<00:39, 11.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: CAW/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: SHARKCAT/USDT (63 candles):  75% 1245/1669 [01:38<00:30, 14.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: TAONU/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: WSM/USDT (99 candles):  79% 1320/1669 [01:44<00:22, 15.47it/s]       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: DEAI/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: K21/USDT (101 candles):  91% 1523/1669 [02:01<00:14,  9.86it/s]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: DSYNC/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: ORT/USDT (101 candles):  93% 1553/1669 [02:03<00:08, 13.57it/s]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: CITY/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: METO/USDT (101 candles):  96% 1595/1669 [02:07<00:06, 11.43it/s]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found Confluence: PROPS/USDT 🎯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning: WWY/USDT (101 candles): : 1674it [02:13, 12.52it/s]               \n",
      "HTTP Request: POST https://api.telegram.org/bot8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g/sendMessage \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.telegram.org/bot8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g/sendMessage \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 25 Confluence patterns:\n",
      "         symbol    close  volume_quote  volume_ratio  close_off_low  \\\n",
      "0        OGUSDT  12.5520   53936377.92          2.63           70.5   \n",
      "1     DSYNCUSDT   0.1501   17833325.21          2.25           71.2   \n",
      "2     PROPSUSDT   0.0343    9136369.38          0.85           72.5   \n",
      "3      CITYUSDT   1.2006    8346011.19          1.69           75.3   \n",
      "4     PORTOUSDT   1.0576    4139855.45          2.00           70.5   \n",
      "5      DDMTUSDT   0.1338    2999383.71          0.94           99.4   \n",
      "6      ALVAUSDT   0.2593    1574609.02          0.91           75.5   \n",
      "7      DEAIUSDT   0.0778    1401766.89          1.15           84.4   \n",
      "8      SNEKUSDT   0.0044    1268968.43          0.65           77.0   \n",
      "9       CAWUSDT   0.0000    1129642.45          0.88           79.6   \n",
      "10    DEXTFUSDT   0.1602    1002163.47          1.00           81.4   \n",
      "11    VISTAUSDT   8.6050     893260.96          0.66           88.7   \n",
      "12      UBXUSDT   0.0000     794220.30          1.09           91.8   \n",
      "13      LNQUSDT   0.0428     775906.34          0.90           93.8   \n",
      "14      DCBUSDT   0.0122     734048.92          1.24           82.9   \n",
      "15      MBDUSDT   0.0000     718755.27          1.31           91.1   \n",
      "16     APEXUSDT   0.3601     619019.80          0.61           78.4   \n",
      "17     ITGRUSDT   0.0049     517808.27          1.22           91.9   \n",
      "18      PKRUSDT   0.0013     514084.80          1.58           90.7   \n",
      "19    TAONUUSDT   0.0019     501510.13          1.57           70.7   \n",
      "20  JUSTICEUSDT   0.0001     448800.07          0.90           92.7   \n",
      "21      SIXUSDT   0.0272     439207.19          0.38           70.3   \n",
      "22     AUKIUSDT   0.0140     436628.86          1.35           72.0   \n",
      "23      SMXUSDT   0.0015     404533.34          1.29           75.5   \n",
      "24      MASUSDT   0.0166     391380.95          0.99           97.6   \n",
      "\n",
      "    momentum_score  high_volume  spread_breakout  momentum_breakout  \n",
      "0           0.2493         True             True               True  \n",
      "1           0.1486         True             True               True  \n",
      "2           0.2246         True             True               True  \n",
      "3           0.2467         True             True               True  \n",
      "4           0.1658         True             True               True  \n",
      "5           1.3192         True             True               True  \n",
      "6           0.2612         True             True               True  \n",
      "7           0.2202         True             True               True  \n",
      "8           0.1555         True             True               True  \n",
      "9           0.2842         True             True               True  \n",
      "10          0.2223         True             True               True  \n",
      "11          0.4205         True             True               True  \n",
      "12          1.0520         True             True               True  \n",
      "13          0.5024         True             True               True  \n",
      "14          0.5070         True             True               True  \n",
      "15          1.0585         True             True               True  \n",
      "16          0.3223         True             True               True  \n",
      "17          1.1717         True             True               True  \n",
      "18          0.8495         True             True               True  \n",
      "19          0.0552         True             True               True  \n",
      "20          0.8653         True             True               True  \n",
      "21          0.1888         True             True               True  \n",
      "22          0.1438         True             True               True  \n",
      "23          0.0438         True             True               True  \n",
      "24          1.4470         True             True               True  \n",
      "\n",
      "🔧 COMPONENT ANALYSIS:\n",
      "High Volume signals: 25/25 (100.0%)\n",
      "Spread Breakout signals: 25/25 (100.0%)\n",
      "Momentum Breakout signals: 25/25 (100.0%)\n"
     ]
    }
   ],
   "source": [
    "# Seven Figures API Confluence Scanner with bar offset and quote currency options\n",
    "\n",
    "from telegram.ext import Application\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import logging\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import sys\n",
    "import os\n",
    "import html\n",
    "\n",
    "# Add project path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from exchanges.sf_pairs_service import SFPairsService\n",
    "from custom_strategies import detect_confluence\n",
    "\n",
    "class ConfluenceScanner:\n",
    "    def __init__(self, telegram_token, telegram_chat_id, exchange, timeframe, quote_currency=\"USDT\", offset=1):\n",
    "        self.telegram_token = telegram_token\n",
    "        self.telegram_chat_id = telegram_chat_id\n",
    "        self.telegram_app = None\n",
    "        self.exchange = exchange\n",
    "        self.timeframe = timeframe\n",
    "        self.quote_currency = quote_currency.upper()  # USDT or BTC\n",
    "        self.offset = offset  # Added offset parameter\n",
    "        self.sf_service = SFPairsService()\n",
    "        \n",
    "    async def init_telegram(self):\n",
    "        if self.telegram_app is None:\n",
    "            self.telegram_app = Application.builder().token(self.telegram_token).build()\n",
    "\n",
    "    async def send_telegram_alert(self, results):\n",
    "        if not results:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            message = f\"🚨 Confluence Detection - {self.exchange} {self.timeframe} ({self.quote_currency})\\n\\n\"\n",
    "            \n",
    "            # Map timeframe to TradingView format\n",
    "            tv_timeframe_map = {\n",
    "                \"1d\": \"1D\",\n",
    "                \"2d\": \"2D\",\n",
    "                \"1w\": \"1W\"\n",
    "            }\n",
    "            tv_timeframe = tv_timeframe_map.get(self.timeframe.lower(), self.timeframe)\n",
    "            \n",
    "            for result in results:\n",
    "                exchange_name = self.exchange.upper()\n",
    "                formatted_symbol = f\"{result['symbol']}\"\n",
    "                tv_link = f\"https://www.tradingview.com/chart/?symbol={exchange_name}:{formatted_symbol}&interval={tv_timeframe}\"\n",
    "                \n",
    "                # Escape HTML entities in the URL\n",
    "                escaped_link = html.escape(tv_link)\n",
    "                \n",
    "                # Format price value based on quote currency\n",
    "                price_prefix = \"₿\" if self.quote_currency == \"BTC\" else \"$\"\n",
    "                price_decimals = 8 if self.quote_currency == \"BTC\" else 4\n",
    "                \n",
    "                # Format according to specified requirements\n",
    "                time_str = \"\"\n",
    "                if result.get('timestamp') is not None:\n",
    "                    time_str = f\"Time: {result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "                \n",
    "                message += (\n",
    "                    f\"Symbol: {result['symbol']}\\n\"\n",
    "                    f\"{time_str}\"\n",
    "                    f\"Volume: {price_prefix}{result['volume_quote']:,.2f}\\n\"\n",
    "                    f\"Close: <a href='{escaped_link}'>{price_prefix}{result['close']:.{price_decimals}f}</a>\\n\"\n",
    "                    f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                    f\"Close Off Low: {result['close_off_low']:.1f}%\\n\"\n",
    "                    f\"{'='*30}\\n\"\n",
    "                )\n",
    "            \n",
    "            # Split message more carefully to avoid breaking HTML tags\n",
    "            max_length = 4000  # Reduced from 4096 to be safer\n",
    "            \n",
    "            if len(message) > max_length:\n",
    "                # Split at natural breaks (between results) to avoid breaking HTML\n",
    "                sections = message.split('='*30 + '\\n')\n",
    "                current_chunk = \"\"\n",
    "                \n",
    "                for section in sections:\n",
    "                    if len(current_chunk + section + '='*30 + '\\n') > max_length:\n",
    "                        if current_chunk:\n",
    "                            await self.telegram_app.bot.send_message(\n",
    "                                chat_id=self.telegram_chat_id,\n",
    "                                text=current_chunk.strip(),\n",
    "                                parse_mode='HTML',\n",
    "                                disable_web_page_preview=True\n",
    "                            )\n",
    "                        current_chunk = section + '\\n'\n",
    "                    else:\n",
    "                        current_chunk += section + '='*30 + '\\n'\n",
    "                \n",
    "                # Send remaining chunk\n",
    "                if current_chunk.strip():\n",
    "                    await self.telegram_app.bot.send_message(\n",
    "                        chat_id=self.telegram_chat_id,\n",
    "                        text=current_chunk.strip(),\n",
    "                        parse_mode='HTML',\n",
    "                        disable_web_page_preview=True\n",
    "                    )\n",
    "            else:\n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=message,\n",
    "                    parse_mode='HTML',\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending Telegram alert: {str(e)}\")\n",
    "            \n",
    "            # Fallback: send without HTML formatting\n",
    "            try:\n",
    "                price_prefix = \"₿\" if self.quote_currency == \"BTC\" else \"$\"\n",
    "                simple_message = f\"🚨 Confluence Detection - {self.exchange} {self.timeframe} ({self.quote_currency})\\n\\n\"\n",
    "                for result in results:\n",
    "                    simple_message += (\n",
    "                        f\"Symbol: {result['symbol']}\\n\"\n",
    "                        f\"Volume: {price_prefix}{result['volume_quote']:,.2f}\\n\"\n",
    "                        f\"Close: {price_prefix}{result['close']:,.8f}\\n\"\n",
    "                        f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                        f\"Components: Vol={result['high_volume']}, Spread={result['spread_breakout']}, Mom={result['momentum_breakout']}\\n\\n\"\n",
    "                    )\n",
    "                \n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=simple_message,\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "            except Exception as fallback_error:\n",
    "                logging.error(f\"Fallback Telegram send also failed: {str(fallback_error)}\")\n",
    "\n",
    "    def prepare_sf_data(self, raw_df):\n",
    "        \"\"\"Convert SF data to confluence-compatible format\"\"\"\n",
    "        if raw_df is None or len(raw_df) == 0:\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(raw_df)\n",
    "        \n",
    "        # Convert datetime column to pandas datetime and set as index\n",
    "        if 'datetime' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df = df.set_index('datetime')\n",
    "        elif 'time' in df.columns:\n",
    "            # Convert Unix timestamp to datetime\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "            df = df.set_index('time')\n",
    "        \n",
    "        # Select only OHLCV columns needed for confluence\n",
    "        required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        \n",
    "        if len(available_cols) != 5:\n",
    "            return None\n",
    "        \n",
    "        # Select and clean data\n",
    "        result_df = df[required_cols].copy()\n",
    "        \n",
    "        # Ensure numeric types\n",
    "        for col in required_cols:\n",
    "            result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "        \n",
    "        # Drop any NaN rows\n",
    "        result_df = result_df.dropna()\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def scan_single_market(self, pair, ohlcv_data):\n",
    "        \"\"\"Scan a single market for Confluence pattern in the specified bar\"\"\"\n",
    "        try:\n",
    "            # Prepare data for confluence analysis\n",
    "            df = self.prepare_sf_data(ohlcv_data)\n",
    "            \n",
    "            if df is None or len(df) < 50:  # Need enough data for confluence\n",
    "                return None\n",
    "            \n",
    "            # Calculate which bar to check based on offset\n",
    "            check_bar = -(self.offset + 1)  # offset=0 means current bar (-1), offset=1 means last closed (-2), etc.\n",
    "            \n",
    "            # Run confluence detection\n",
    "            detected, result = detect_confluence(df, check_bar=check_bar)\n",
    "            \n",
    "            if detected:\n",
    "                # Calculate volume in quote currency for the target bar\n",
    "                target_close = df['close'].iloc[check_bar]\n",
    "                target_volume = df['volume'].iloc[check_bar]\n",
    "                volume_quote = float(target_close) * float(target_volume)\n",
    "                \n",
    "                confluence_result = {\n",
    "                    'symbol': f\"{pair['Token']}{self.quote_currency}\",\n",
    "                    'volume_quote': volume_quote,\n",
    "                    'close': float(target_close),\n",
    "                    'volume': float(target_volume),\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                    'bar_range': result['bar_range']\n",
    "                }\n",
    "                return confluence_result\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {pair['Token']}{self.quote_currency}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def scan_all_markets(self):\n",
    "        \"\"\"Scan all markets for Confluence pattern\"\"\"\n",
    "        await self.init_telegram()\n",
    "        try:\n",
    "            # Define volume thresholds based on quote currency\n",
    "            if self.quote_currency == \"USDT\":\n",
    "                volume_thresholds = {\n",
    "                    \"1w\": 300000,\n",
    "                    \"2d\": 100000,\n",
    "                    \"1d\": 50000\n",
    "                }\n",
    "            else:  # BTC\n",
    "                volume_thresholds = {\n",
    "                    \"1w\": 3,\n",
    "                    \"2d\": 1,\n",
    "                    \"1d\": 0.5\n",
    "                }\n",
    "                \n",
    "            min_volume = volume_thresholds.get(self.timeframe.lower(), 50000 if self.quote_currency == \"USDT\" else 0.5)\n",
    "            currency_symbol = \"$\" if self.quote_currency == \"USDT\" else \"₿\"\n",
    "            \n",
    "            # Create offset description\n",
    "            if self.offset == 0:\n",
    "                offset_desc = \"current candle\"\n",
    "            elif self.offset == 1:\n",
    "                offset_desc = \"last closed candle\"\n",
    "            else:\n",
    "                offset_desc = f\"{self.offset} candles ago\"\n",
    "            \n",
    "            print(f\"Scanning for Confluence patterns in {offset_desc}...\")\n",
    "            print(f\"Quote currency: {self.quote_currency}\")\n",
    "            print(f\"Minimum volume threshold: {currency_symbol}{min_volume:,.2f}\")\n",
    "            \n",
    "            # Get all pairs from SF service\n",
    "            print(f\"Fetching pairs from {self.exchange}...\")\n",
    "            all_pairs = self.sf_service.get_pairs_of_exchange(self.exchange)\n",
    "            \n",
    "            # Filter pairs based on quote currency\n",
    "            if self.quote_currency == \"USDT\":\n",
    "                quote_filtered_pairs = [\n",
    "                    pair for pair in all_pairs \n",
    "                    if 'Quote' in pair and pair['Quote'].upper() == \"USDT\"\n",
    "                ]\n",
    "                print(f\"Found {len(quote_filtered_pairs)} USDT pairs to scan\")\n",
    "            else:  # BTC pairs\n",
    "                usdt_pairs = [\n",
    "                    pair for pair in all_pairs \n",
    "                    if 'Quote' in pair and pair['Quote'].upper() == \"USDT\"\n",
    "                ]\n",
    "                # Create BTC pairs by replacing Quote field in USDT pairs\n",
    "                quote_filtered_pairs = []\n",
    "                for pair in usdt_pairs:\n",
    "                    btc_pair = pair.copy()\n",
    "                    btc_pair['Quote'] = 'BTC'\n",
    "                    quote_filtered_pairs.append(btc_pair)\n",
    "                print(f\"Created {len(quote_filtered_pairs)} BTC pairs from USDT pairs\")\n",
    "            \n",
    "            # Process all pairs with progress bar\n",
    "            all_results = []\n",
    "            with tqdm(total=len(quote_filtered_pairs), desc=\"Scanning markets\") as pbar:\n",
    "                for pair in quote_filtered_pairs:\n",
    "                    try:\n",
    "                        # Skip stable coins for BTC pairs (they likely don't have BTC pairs)\n",
    "                        if self.quote_currency == \"BTC\" and pair['Token'].upper() in ['USDT', 'USDC', 'BUSD', 'DAI', 'TUSD']:\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                            \n",
    "                        # Skip certain tokens for BTC pairs (they likely don't have BTC pairs)\n",
    "                        if self.quote_currency == \"BTC\" and len(pair['Token']) >= 10:\n",
    "                            # Skip very long token names (likely newer tokens that won't have BTC pairs)\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        # Get OHLCV data from SF service\n",
    "                        try:\n",
    "                            ohlcv_data = self.sf_service.get_ohlcv_for_pair(\n",
    "                                pair['Token'], \n",
    "                                pair['Quote'], \n",
    "                                self.exchange, \n",
    "                                self.timeframe, \n",
    "                                100  # Get more data for confluence analysis\n",
    "                            )\n",
    "                        except Exception:\n",
    "                            # If error, just skip this pair silently\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        if ohlcv_data is None or len(ohlcv_data) == 0:\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        df = pd.DataFrame(ohlcv_data)\n",
    "                        \n",
    "                        # Check if we have enough data\n",
    "                        if len(df) >= 50:  # Need enough for confluence analysis\n",
    "                            target_idx = -(self.offset + 1)  # Adjust index based on offset\n",
    "                            \n",
    "                            # Only display when we have enough data\n",
    "                            pbar.set_description(f\"Scanning: {pair['Token']}/{pair['Quote']} ({len(df)} candles)\")\n",
    "                            \n",
    "                            # Check volume threshold for the target candle\n",
    "                            try:\n",
    "                                target_candle_volume = float(df['close'].iloc[target_idx]) * float(df['volume'].iloc[target_idx])\n",
    "                                \n",
    "                                # Only process if volume meets threshold\n",
    "                                if target_candle_volume >= min_volume:\n",
    "                                    result = self.scan_single_market(pair, ohlcv_data)\n",
    "                                    if result:\n",
    "                                        all_results.append(result)\n",
    "                                        print(f\"Found Confluence: {pair['Token']}/{pair['Quote']} 🎯\")\n",
    "                            except (IndexError, ValueError):\n",
    "                                pass  # Skip if we can't calculate volume\n",
    "                                    \n",
    "                    except Exception:\n",
    "                        pass  # Skip errors silently\n",
    "                    finally:\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            # Sort by volume\n",
    "            all_results.sort(key=lambda x: x['volume_quote'], reverse=True)\n",
    "            \n",
    "            # Send Telegram alert if we found any patterns\n",
    "            if all_results:\n",
    "                await self.send_telegram_alert(all_results)\n",
    "            \n",
    "            return all_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scanning markets: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "async def run_confluence_scanner(exchange, timeframe, quote_currency=\"USDT\", offset=1):\n",
    "    \"\"\"\n",
    "    Run the Confluence scanner\n",
    "    \n",
    "    Parameters:\n",
    "    exchange (str): Exchange name (Kucoin, Mexc, Binance)\n",
    "    timeframe (str): Time period (1d, 2d, 1w)\n",
    "    quote_currency (str): Quote currency to scan (USDT or BTC)\n",
    "    offset (int): Bar offset (0=current, 1=last closed, 2=two bars ago, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if offset == 0:\n",
    "        offset_desc = \"current candle\"\n",
    "    elif offset == 1:\n",
    "        offset_desc = \"last closed candle\"\n",
    "    else:\n",
    "        offset_desc = f\"{offset} candles ago\"\n",
    "    \n",
    "    print(f\"Starting Confluence scan for {offset_desc} on {exchange} {timeframe} ({quote_currency} pairs)...\")\n",
    "    \n",
    "    # Use the confluence telegram token from your big project config\n",
    "    # You should replace this with the actual token from utils/config.py TELEGRAM_TOKENS[\"confluence\"]\n",
    "    telegram_token = \"8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g\"  # Replace with confluence token\n",
    "    telegram_chat_id = \"375812423\"  # Your chat ID\n",
    "    \n",
    "    scanner = ConfluenceScanner(telegram_token, telegram_chat_id, exchange, timeframe, quote_currency, offset)\n",
    "    results = await scanner.scan_all_markets()\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nFound {len(results)} Confluence patterns:\")\n",
    "        \n",
    "        # Convert results to DataFrame for console display\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # Determine decimals based on quote currency\n",
    "        price_decimals = 8 if quote_currency == \"BTC\" else 4\n",
    "        \n",
    "        # Round numeric columns\n",
    "        df_results['volume_quote'] = df_results['volume_quote'].round(2)\n",
    "        df_results['close'] = df_results['close'].round(price_decimals)\n",
    "        df_results['volume'] = df_results['volume'].round(2)\n",
    "        df_results['volume_ratio'] = df_results['volume_ratio'].round(2)\n",
    "        df_results['close_off_low'] = df_results['close_off_low'].round(1)\n",
    "        df_results['momentum_score'] = df_results['momentum_score'].round(4)\n",
    "        \n",
    "        # Reorder columns for better display\n",
    "        display_cols = ['symbol', 'close', 'volume_quote', 'volume_ratio', 'close_off_low', \n",
    "                       'momentum_score', 'high_volume', 'spread_breakout', 'momentum_breakout']\n",
    "        available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "        \n",
    "        # Display the results\n",
    "        print(df_results[available_cols])\n",
    "        \n",
    "        # Show component analysis\n",
    "        print(f\"\\n🔧 COMPONENT ANALYSIS:\")\n",
    "        vol_count = df_results['high_volume'].sum()\n",
    "        spread_count = df_results['spread_breakout'].sum()\n",
    "        momentum_count = df_results['momentum_breakout'].sum()\n",
    "        \n",
    "        print(f\"High Volume signals: {vol_count}/{len(results)} ({vol_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Spread Breakout signals: {spread_count}/{len(results)} ({spread_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Momentum Breakout signals: {momentum_count}/{len(results)} ({momentum_count/len(results)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nNo Confluence patterns found in {offset_desc}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Apply nest_asyncio to allow async operations in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Example usage functions\n",
    "async def scan_current_confluence_usdt():\n",
    "    \"\"\"Scan current candle for confluence - USDT pairs\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", \"USDT\", offset=0)\n",
    "\n",
    "async def scan_closed_confluence_usdt():\n",
    "    \"\"\"Scan last closed candle for confluence - USDT pairs\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", \"USDT\", offset=1)\n",
    "\n",
    "async def scan_current_confluence_btc():\n",
    "    \"\"\"Scan current candle for confluence - BTC pairs\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", \"BTC\", offset=0)\n",
    "\n",
    "async def scan_closed_confluence_btc():\n",
    "    \"\"\"Scan last closed candle for confluence - BTC pairs\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", \"BTC\", offset=1)\n",
    "\n",
    "# Main execution function\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main execution - modify parameters here\n",
    "    \"\"\"\n",
    "    exchange = \"Mexc\"        # Binance, Kucoin, Mexc, Gateio\n",
    "    timeframe = \"1w\"         # 1d, 2d, 1w\n",
    "    quote_currency = \"USDT\"  # USDT or BTC\n",
    "    offset = 1               # 0 = current candle, 1 = last closed candle, 2 = two candles ago\n",
    "    \n",
    "    await run_confluence_scanner(exchange, timeframe, quote_currency, offset)\n",
    "\n",
    "# Run the async main function\n",
    "print(\"🔍 CONFLUENCE SCANNER WITH QUOTE CURRENCY OPTIONS\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Available functions:\")\n",
    "print(\"• await main() - Run with default settings\")\n",
    "print(\"• await scan_current_confluence_usdt() - Scan current candle (USDT)\")\n",
    "print(\"• await scan_closed_confluence_usdt() - Scan last closed candle (USDT)\")\n",
    "print(\"• await scan_current_confluence_btc() - Scan current candle (BTC)\")\n",
    "print(\"• await scan_closed_confluence_btc() - Scan last closed candle (BTC)\")\n",
    "print(\"• await run_confluence_scanner('Exchange', 'timeframe', 'quote_currency', offset) - Custom scan\")\n",
    "print(\"\\nExample: await run_confluence_scanner('Mexc', '1w', 'BTC', 1)\")\n",
    "\n",
    "# Uncomment to auto-run:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caac56a-df34-4974-8cd6-8fb33f8d477a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Binance BTC dominated pairs - Confluence Scanner with Direct API\n",
    "\n",
    "from telegram.ext import Application\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import sys\n",
    "import os\n",
    "import html\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "# Add project path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from custom_strategies import detect_confluence\n",
    "\n",
    "class BinanceBTCConfluenceScanner:\n",
    "    def __init__(self, telegram_token, telegram_chat_id, timeframe, offset=1):\n",
    "        self.telegram_token = telegram_token\n",
    "        self.telegram_chat_id = telegram_chat_id\n",
    "        self.telegram_app = None\n",
    "        self.exchange = \"Binance\"\n",
    "        self.timeframe = timeframe\n",
    "        self.quote_currency = \"BTC\"\n",
    "        self.offset = offset\n",
    "        self.base_url = \"https://api.binance.com\"\n",
    "        self.session = None\n",
    "        \n",
    "        # Binance timeframe mapping - All available intervals\n",
    "        self.timeframe_map = {\n",
    "            # Minutes\n",
    "            \"1m\": \"1m\",\n",
    "            \"3m\": \"3m\", \n",
    "            \"5m\": \"5m\",\n",
    "            \"15m\": \"15m\",\n",
    "            \"30m\": \"30m\",\n",
    "            # Hours\n",
    "            \"1h\": \"1h\",\n",
    "            \"2h\": \"2h\",\n",
    "            \"4h\": \"4h\",\n",
    "            \"6h\": \"6h\",\n",
    "            \"8h\": \"8h\",\n",
    "            \"12h\": \"12h\",\n",
    "            # Days\n",
    "            \"1d\": \"1d\",\n",
    "            \"2d\": \"2d\",\n",
    "            \"3d\": \"3d\",\n",
    "            # Weeks/Months\n",
    "            \"1w\": \"1w\",\n",
    "            \"1M\": \"1M\"\n",
    "        }\n",
    "        \n",
    "    async def init_session(self):\n",
    "        \"\"\"Initialize aiohttp session\"\"\"\n",
    "        if self.session is None:\n",
    "            self.session = aiohttp.ClientSession()\n",
    "            \n",
    "    async def close_session(self):\n",
    "        \"\"\"Close aiohttp session\"\"\"\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "            self.session = None\n",
    "        \n",
    "    async def init_telegram(self):\n",
    "        if self.telegram_app is None:\n",
    "            self.telegram_app = Application.builder().token(self.telegram_token).build()\n",
    "\n",
    "    async def get_btc_pairs(self):\n",
    "        \"\"\"Get all BTC trading pairs from Binance\"\"\"\n",
    "        await self.init_session()\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.base_url}/api/v3/exchangeInfo\"\n",
    "            async with self.session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    \n",
    "                    # Filter for BTC pairs that are actively trading\n",
    "                    btc_pairs = []\n",
    "                    for symbol_info in data['symbols']:\n",
    "                        if (symbol_info['quoteAsset'] == 'BTC' and \n",
    "                            symbol_info['status'] == 'TRADING' and\n",
    "                            symbol_info['isSpotTradingAllowed']):\n",
    "                            \n",
    "                            btc_pairs.append({\n",
    "                                'symbol': symbol_info['symbol'],\n",
    "                                'baseAsset': symbol_info['baseAsset'],\n",
    "                                'quoteAsset': symbol_info['quoteAsset']\n",
    "                            })\n",
    "                    \n",
    "                    return btc_pairs\n",
    "                else:\n",
    "                    logging.error(f\"Error fetching exchange info: {response.status}\")\n",
    "                    return []\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching BTC pairs: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    async def get_klines(self, symbol, interval, limit=100):\n",
    "        \"\"\"Get kline/candlestick data from Binance\"\"\"\n",
    "        await self.init_session()\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.base_url}/api/v3/klines\"\n",
    "            params = {\n",
    "                'symbol': symbol,\n",
    "                'interval': interval,\n",
    "                'limit': limit\n",
    "            }\n",
    "            \n",
    "            async with self.session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    \n",
    "                    # Convert to DataFrame\n",
    "                    df = pd.DataFrame(data, columns=[\n",
    "                        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "                        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "                    ])\n",
    "                    \n",
    "                    # Convert timestamps to datetime\n",
    "                    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "                    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "                    \n",
    "                    # Convert OHLCV to numeric\n",
    "                    for col in ['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume']:\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                    \n",
    "                    # Set datetime index\n",
    "                    df.set_index('open_time', inplace=True)\n",
    "                    \n",
    "                    # Select only OHLCV columns needed for confluence\n",
    "                    # Note: Using quote_asset_volume as it's the volume in BTC\n",
    "                    result_df = df[['open', 'high', 'low', 'close', 'quote_asset_volume']].copy()\n",
    "                    result_df.rename(columns={'quote_asset_volume': 'volume'}, inplace=True)\n",
    "                    \n",
    "                    return result_df\n",
    "                    \n",
    "                elif response.status == 429:\n",
    "                    # Rate limit hit, wait a bit\n",
    "                    await asyncio.sleep(1)\n",
    "                    return None\n",
    "                else:\n",
    "                    return None\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching klines for {symbol}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    async def send_telegram_alert(self, results):\n",
    "        if not results:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            message = f\"🚨 Confluence Detection - Binance BTC Pairs {self.timeframe}\\n\\n\"\n",
    "            \n",
    "            # Map timeframe to TradingView format - Extended mapping\n",
    "            tv_timeframe_map = {\n",
    "                # Minutes\n",
    "                \"1m\": \"1\", \"3m\": \"3\", \"5m\": \"5\", \"15m\": \"15\", \"30m\": \"30\",\n",
    "                # Hours  \n",
    "                \"1h\": \"60\", \"2h\": \"120\", \"4h\": \"240\", \"6h\": \"360\", \"8h\": \"480\", \"12h\": \"720\",\n",
    "                # Days\n",
    "                \"1d\": \"1D\", \"2d\": \"2D\", \"3d\": \"3D\",\n",
    "                # Weeks/Months\n",
    "                \"1w\": \"1W\", \"1M\": \"1M\"\n",
    "            }\n",
    "            tv_timeframe = tv_timeframe_map.get(self.timeframe.lower(), self.timeframe)\n",
    "            \n",
    "            for result in results:\n",
    "                formatted_symbol = result['symbol']\n",
    "                tv_link = f\"https://www.tradingview.com/chart/?symbol=BINANCE:{formatted_symbol}&interval={tv_timeframe}\"\n",
    "                \n",
    "                # Escape HTML entities in the URL\n",
    "                escaped_link = html.escape(tv_link)\n",
    "                \n",
    "                # Format according to BTC specifications\n",
    "                time_str = \"\"\n",
    "                if result.get('timestamp') is not None:\n",
    "                    time_str = f\"Time: {result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "                \n",
    "                message += (\n",
    "                    f\"Symbol: {result['symbol']}\\n\"\n",
    "                    f\"{time_str}\"\n",
    "                    f\"Volume BTC: ₿{result['volume_btc']:,.4f}\\n\"\n",
    "                    f\"Close: <a href='{escaped_link}'>₿{result['close']:.8f}</a>\\n\"\n",
    "                    f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                    f\"Close Off Low: {result['close_off_low']:.1f}%\\n\"\n",
    "                    f\"Momentum: {result['momentum_score']:.4f}\\n\"\n",
    "                    f\"{'='*30}\\n\"\n",
    "                )\n",
    "            \n",
    "            # Split message more carefully to avoid breaking HTML tags\n",
    "            max_length = 4000\n",
    "            \n",
    "            if len(message) > max_length:\n",
    "                # Split at natural breaks (between results) to avoid breaking HTML\n",
    "                sections = message.split('='*30 + '\\n')\n",
    "                current_chunk = \"\"\n",
    "                \n",
    "                for section in sections:\n",
    "                    if len(current_chunk + section + '='*30 + '\\n') > max_length:\n",
    "                        if current_chunk:\n",
    "                            await self.telegram_app.bot.send_message(\n",
    "                                chat_id=self.telegram_chat_id,\n",
    "                                text=current_chunk.strip(),\n",
    "                                parse_mode='HTML',\n",
    "                                disable_web_page_preview=True\n",
    "                            )\n",
    "                        current_chunk = section + '\\n'\n",
    "                    else:\n",
    "                        current_chunk += section + '='*30 + '\\n'\n",
    "                \n",
    "                # Send remaining chunk\n",
    "                if current_chunk.strip():\n",
    "                    await self.telegram_app.bot.send_message(\n",
    "                        chat_id=self.telegram_chat_id,\n",
    "                        text=current_chunk.strip(),\n",
    "                        parse_mode='HTML',\n",
    "                        disable_web_page_preview=True\n",
    "                    )\n",
    "            else:\n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=message,\n",
    "                    parse_mode='HTML',\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending Telegram alert: {str(e)}\")\n",
    "            \n",
    "            # Fallback: send without HTML formatting\n",
    "            try:\n",
    "                simple_message = f\"🚨 Confluence Detection - Binance BTC Pairs {self.timeframe}\\n\\n\"\n",
    "                for result in results:\n",
    "                    simple_message += (\n",
    "                        f\"Symbol: {result['symbol']}\\n\"\n",
    "                        f\"Volume BTC: ₿{result['volume_btc']:,.4f}\\n\"\n",
    "                        f\"Close: ₿{result['close']:.8f}\\n\"\n",
    "                        f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                        f\"Components: Vol={result['high_volume']}, Spread={result['spread_breakout']}, Mom={result['momentum_breakout']}\\n\\n\"\n",
    "                    )\n",
    "                \n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=simple_message,\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "            except Exception as fallback_error:\n",
    "                logging.error(f\"Fallback Telegram send also failed: {str(fallback_error)}\")\n",
    "\n",
    "    def scan_single_market(self, pair, df):\n",
    "        \"\"\"Scan a single market for Confluence pattern in the specified bar\"\"\"\n",
    "        try:\n",
    "            if df is None or len(df) < 50:  # Need enough data for confluence\n",
    "                return None\n",
    "            \n",
    "            # Calculate which bar to check based on offset\n",
    "            check_bar = -(self.offset + 1)  # offset=0 means current bar (-1), offset=1 means last closed (-2), etc.\n",
    "            \n",
    "            # Run confluence detection\n",
    "            detected, result = detect_confluence(df, check_bar=check_bar)\n",
    "            \n",
    "            if detected:\n",
    "                # Get the target bar values\n",
    "                target_close = df['close'].iloc[check_bar]\n",
    "                target_volume = df['volume'].iloc[check_bar]  # This is already in BTC\n",
    "                \n",
    "                confluence_result = {\n",
    "                    'symbol': pair['symbol'],\n",
    "                    'volume_btc': float(target_volume),\n",
    "                    'close': float(target_close),\n",
    "                    'volume': float(target_volume),\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                    'bar_range': result['bar_range'],\n",
    "                    'timestamp': df.index[check_bar] if hasattr(df.index, '__getitem__') else None\n",
    "                }\n",
    "                return confluence_result\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {pair['symbol']}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def scan_all_markets(self):\n",
    "        \"\"\"Scan all BTC markets for Confluence pattern\"\"\"\n",
    "        await self.init_telegram()\n",
    "        \n",
    "        try:\n",
    "            # Define volume thresholds for BTC pairs based on timeframe\n",
    "            volume_thresholds = {\n",
    "                # Minutes - higher volume needed for shorter timeframes\n",
    "                \"1m\": 0.01,   \"3m\": 0.02,   \"5m\": 0.03,\n",
    "                \"15m\": 0.05,  \"30m\": 0.08,\n",
    "                # Hours\n",
    "                \"1h\": 0.1,    \"2h\": 0.15,   \"4h\": 0.2,\n",
    "                \"6h\": 0.25,   \"8h\": 0.3,    \"12h\": 0.35,\n",
    "                # Days\n",
    "                \"1d\": 0.4,    \"2d\": 0.8,    \"3d\": 1.2,\n",
    "                # Weeks/Months\n",
    "                \"1w\": 2.0,    \"1M\": 8.0\n",
    "            }\n",
    "            min_volume = volume_thresholds.get(self.timeframe.lower(), 0.1)  # Default 0.1 BTC\n",
    "            \n",
    "            # Create offset description\n",
    "            if self.offset == 0:\n",
    "                offset_desc = \"current candle\"\n",
    "            elif self.offset == 1:\n",
    "                offset_desc = \"last closed candle\"\n",
    "            else:\n",
    "                offset_desc = f\"{self.offset} candles ago\"\n",
    "            \n",
    "            print(f\"Scanning Binance BTC pairs for Confluence patterns in {offset_desc}...\")\n",
    "            print(f\"Timeframe: {self.timeframe}\")\n",
    "            print(f\"Minimum volume threshold: ₿{min_volume:.2f}\")\n",
    "            \n",
    "            # Get all BTC pairs from Binance\n",
    "            print(\"Fetching BTC pairs from Binance...\")\n",
    "            btc_pairs = await self.get_btc_pairs()\n",
    "            \n",
    "            if not btc_pairs:\n",
    "                print(\"No BTC pairs found or error fetching pairs\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"Found {len(btc_pairs)} BTC pairs to scan\")\n",
    "            \n",
    "            # Filter out stablecoins and obvious non-trading pairs\n",
    "            filtered_pairs = []\n",
    "            skip_tokens = ['USDT', 'USDC', 'BUSD', 'DAI', 'TUSD', 'USDD', 'FDUSD']\n",
    "            \n",
    "            for pair in btc_pairs:\n",
    "                if pair['baseAsset'] not in skip_tokens:\n",
    "                    filtered_pairs.append(pair)\n",
    "            \n",
    "            print(f\"After filtering: {len(filtered_pairs)} pairs to scan\")\n",
    "            \n",
    "            # Get Binance timeframe - fallback to 1d if not found\n",
    "            binance_interval = self.timeframe_map.get(self.timeframe.lower(), \"1d\")\n",
    "            \n",
    "            # Process all pairs with progress bar\n",
    "            all_results = []\n",
    "            successful_scans = 0\n",
    "            \n",
    "            with tqdm(total=len(filtered_pairs), desc=\"Scanning markets\") as pbar:\n",
    "                for pair in filtered_pairs:\n",
    "                    try:\n",
    "                        # Get OHLCV data from Binance\n",
    "                        df = await self.get_klines(pair['symbol'], binance_interval, 100)\n",
    "                        \n",
    "                        if df is None or len(df) < 50:\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        successful_scans += 1\n",
    "                        target_idx = -(self.offset + 1)\n",
    "                        \n",
    "                        # Update progress bar with current symbol\n",
    "                        pbar.set_description(f\"Scanning: {pair['symbol']} ({len(df)} candles)\")\n",
    "                        \n",
    "                        # Check volume threshold for the target candle\n",
    "                        try:\n",
    "                            target_candle_volume = float(df['volume'].iloc[target_idx])  # Already in BTC\n",
    "                            \n",
    "                            # Only process if volume meets threshold\n",
    "                            if target_candle_volume >= min_volume:\n",
    "                                result = self.scan_single_market(pair, df)\n",
    "                                if result:\n",
    "                                    all_results.append(result)\n",
    "                                    print(f\"Found Confluence: {pair['symbol']} 🎯\")\n",
    "                        except (IndexError, ValueError):\n",
    "                            pass  # Skip if we can't calculate volume\n",
    "                        \n",
    "                        # Add small delay to respect rate limits\n",
    "                        await asyncio.sleep(0.1)\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        if \"429\" in str(e):\n",
    "                            # Rate limit - add longer delay\n",
    "                            await asyncio.sleep(2)\n",
    "                    finally:\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            print(f\"Successfully scanned {successful_scans}/{len(filtered_pairs)} pairs\")\n",
    "            \n",
    "            # Sort by volume\n",
    "            all_results.sort(key=lambda x: x['volume_btc'], reverse=True)\n",
    "            \n",
    "            # Send Telegram alert if we found any patterns\n",
    "            if all_results:\n",
    "                await self.send_telegram_alert(all_results)\n",
    "            \n",
    "            return all_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scanning markets: {str(e)}\")\n",
    "            return []\n",
    "        finally:\n",
    "            await self.close_session()\n",
    "\n",
    "async def run_binance_btc_confluence_scanner(timeframe, offset=1):\n",
    "    \"\"\"\n",
    "    Run the Binance BTC Confluence scanner\n",
    "    \n",
    "    Parameters:\n",
    "    timeframe (str): Time period - Available options:\n",
    "                    Minutes: 1m, 3m, 5m, 15m, 30m\n",
    "                    Hours: 1h, 2h, 4h, 6h, 8h, 12h  \n",
    "                    Days: 1d, 2d, 3d\n",
    "                    Weeks/Months: 1w, 1M\n",
    "    offset (int): Bar offset (0=current, 1=last closed, 2=two bars ago, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if offset == 0:\n",
    "        offset_desc = \"current candle\"\n",
    "    elif offset == 1:\n",
    "        offset_desc = \"last closed candle\"\n",
    "    else:\n",
    "        offset_desc = f\"{offset} candles ago\"\n",
    "    \n",
    "    print(f\"Starting Binance BTC Confluence scan for {offset_desc} on {timeframe}...\")\n",
    "    \n",
    "    # Use the confluence telegram token\n",
    "    telegram_token = \"8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g\"\n",
    "    telegram_chat_id = \"375812423\"\n",
    "    \n",
    "    scanner = BinanceBTCConfluenceScanner(telegram_token, telegram_chat_id, timeframe, offset)\n",
    "    results = await scanner.scan_all_markets()\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nFound {len(results)} Confluence patterns:\")\n",
    "        \n",
    "        # Convert results to DataFrame for console display\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # Round numeric columns for BTC precision\n",
    "        df_results['volume_btc'] = df_results['volume_btc'].round(4)\n",
    "        df_results['close'] = df_results['close'].round(8)\n",
    "        df_results['volume'] = df_results['volume'].round(4)\n",
    "        df_results['volume_ratio'] = df_results['volume_ratio'].round(2)\n",
    "        df_results['close_off_low'] = df_results['close_off_low'].round(1)\n",
    "        df_results['momentum_score'] = df_results['momentum_score'].round(4)\n",
    "        \n",
    "        # Reorder columns for better display\n",
    "        display_cols = ['symbol', 'close', 'volume_btc', 'volume_ratio', 'close_off_low', \n",
    "                       'momentum_score', 'high_volume', 'spread_breakout', 'momentum_breakout']\n",
    "        available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "        \n",
    "        # Display the results\n",
    "        print(df_results[available_cols])\n",
    "        \n",
    "        # Show component analysis\n",
    "        print(f\"\\n🔧 COMPONENT ANALYSIS:\")\n",
    "        vol_count = df_results['high_volume'].sum()\n",
    "        spread_count = df_results['spread_breakout'].sum()\n",
    "        momentum_count = df_results['momentum_breakout'].sum()\n",
    "        \n",
    "        print(f\"High Volume signals: {vol_count}/{len(results)} ({vol_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Spread Breakout signals: {spread_count}/{len(results)} ({spread_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Momentum Breakout signals: {momentum_count}/{len(results)} ({momentum_count/len(results)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nNo Confluence patterns found in {offset_desc}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Apply nest_asyncio to allow async operations in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Example usage functions\n",
    "async def scan_binance_btc_current():\n",
    "    \"\"\"Scan current candle for confluence - Binance BTC pairs\"\"\"\n",
    "    await run_binance_btc_confluence_scanner(\"1w\", offset=0)\n",
    "\n",
    "async def scan_binance_btc_closed():\n",
    "    \"\"\"Scan last closed candle for confluence - Binance BTC pairs\"\"\"\n",
    "    await run_binance_btc_confluence_scanner(\"1w\", offset=1)\n",
    "\n",
    "async def scan_binance_btc_previous():\n",
    "    \"\"\"Scan two candles ago for confluence - Binance BTC pairs\"\"\"\n",
    "    await run_binance_btc_confluence_scanner(\"1w\", offset=2)\n",
    "\n",
    "# Main execution function\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main execution - modify parameters here\n",
    "    \"\"\"\n",
    "    timeframe = \"1w\"  # 1d, 2d, 3d, 1w\n",
    "    offset = 0        # 0 = current candle, 1 = last closed candle, 2 = two candles ago\n",
    "    \n",
    "    await run_binance_btc_confluence_scanner(timeframe, offset)\n",
    "\n",
    "# Run the async main function\n",
    "print(\"🔍 BINANCE BTC CONFLUENCE SCANNER\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Available timeframes:\")\n",
    "print(\"• Minutes: 1m, 3m, 5m, 15m, 30m\")\n",
    "print(\"• Hours: 1h, 2h, 4h, 6h, 8h, 12h\") \n",
    "print(\"• Days: 1d, 2d, 3d\")\n",
    "print(\"• Weeks/Months: 1w, 1M\")\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"• await main() - Run with default settings\")\n",
    "print(\"• await scan_binance_btc_current() - Scan current candle\")\n",
    "print(\"• await scan_binance_btc_closed() - Scan last closed candle\")\n",
    "print(\"• await scan_binance_btc_previous() - Scan two candles ago\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('timeframe', offset) - Custom scan\")\n",
    "print(\"\\nExamples:\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('4h', 1)  # 4-hour last closed\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('15m', 0) # 15-min current\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('1M', 1)  # Monthly last closed\")\n",
    "print(\"This scanner uses REAL Binance BTC pair volumes!\")\n",
    "\n",
    "# Uncomment to auto-run:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804bead-b40b-4676-9951-8d4e30e29ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug ohlcv data of any pair\n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "from exchanges import BybitFuturesClient  # Ensure this matches your exchanges/__init__.py\n",
    "\n",
    "async def test_fetch():\n",
    "    client = BybitFuturesClient(timeframe=\"2d\")\n",
    "    await client.init_session()\n",
    "    df = await client.fetch_klines(\"L3USDT\")\n",
    "    await client.close_session()\n",
    "    if df is not None:\n",
    "        print(\"2d Candles for L3:\")\n",
    "        print(df.tail(5))  # Last 5 weeks\n",
    "        last_row = df.iloc[-1]\n",
    "        volume_usd = last_row['volume'] * last_row['close']\n",
    "        print(f\"Last Week: volume_usd={volume_usd:.2f}, close={last_row['close']}, volume={last_row['volume']:.2f}\")\n",
    "\n",
    "# Run the async function directly in the notebook\n",
    "await test_fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b52f4-ca65-425b-a41a-42b70a57aefa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Direct strategy debug of any pair on any exchange\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "from exchanges import MexcSpotClient, BybitSpotClient, GateioSpotClient, KucoinSpotClient, BinanceSpotClient, BinanceFuturesClient, BybitFuturesClient\n",
    "from custom_strategies import detect_volume_surge, detect_weak_uptrend, detect_pin_down\n",
    "from breakout_vsa import vsa_detector, breakout_bar_vsa, stop_bar_vsa, reversal_bar_vsa, start_bar_vsa, loaded_bar_vsa, test_bar_vsa\n",
    "\n",
    "async def test_strategy(exchange_client_class, timeframe, symbol, strategy_name):\n",
    "    client = exchange_client_class(timeframe=timeframe)\n",
    "    await client.init_session()\n",
    "    df = await client.fetch_klines(symbol)\n",
    "    await client.close_session()\n",
    "    \n",
    "    if df is None or len(df) < 10:\n",
    "        print(f\"No data fetched for {symbol} or insufficient data (< 10 bars)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"{timeframe} Candles for {symbol}:\")\n",
    "    print(df.tail(5))\n",
    "    last_row = df.iloc[-1]\n",
    "    volume_usd = last_row['volume'] * last_row['close']\n",
    "    print(f\"Last Bar: volume_usd={volume_usd:.2f}, close={last_row['close']}, volume={last_row['volume']:.2f}\")\n",
    "    \n",
    "    # Different handling based on strategy type\n",
    "    if strategy_name == \"volume_surge\":\n",
    "        # Use detect_volume_surge directly\n",
    "        detected, result = detect_volume_surge(df)\n",
    "        \n",
    "        print(f\"\\nVolume Surge Detection Results:\")\n",
    "        print(f\"Detected: {detected}\")\n",
    "        \n",
    "        if detected:\n",
    "            print(f\"\\nVolume Surge Details:\")\n",
    "            print(f\"  Date: {result['timestamp']}\")\n",
    "            print(f\"  Close: ${result['close_price']:,.8f}\")\n",
    "            print(f\"  Volume: {result['volume']:,.2f}\")\n",
    "            print(f\"  Volume USD: ${result['volume_usd']:,.2f}\")\n",
    "            print(f\"  Volume Ratio: {result['volume_ratio']:,.2f}x\")\n",
    "            print(f\"  Score: {result['score']:,.2f}\")\n",
    "            print(f\"  Price Extreme: {result['price_extreme']}\")\n",
    "    \n",
    "    elif strategy_name == \"pin_down\":\n",
    "        from custom_strategies import detect_pin_down\n",
    "        detected, result = detect_pin_down(df)\n",
    "        \n",
    "        print(f\"\\nPin Down Detection Results:\")\n",
    "        print(f\"Detected: {detected}\")\n",
    "        \n",
    "        if detected:\n",
    "            print(f\"\\nPin Down Details:\")\n",
    "            for key, value in result.items():\n",
    "                if key != 'symbol':  # Skip symbol as we already know it\n",
    "                    print(f\"  {key}: {value}\")\n",
    "    \n",
    "    elif strategy_name == \"weak_uptrend\":\n",
    "        from custom_strategies import detect_weak_uptrend\n",
    "        detected, result = detect_weak_uptrend(df)\n",
    "        \n",
    "        print(f\"\\nWeak Uptrend Detection Results:\")\n",
    "        print(f\"Detected: {detected}\")\n",
    "        \n",
    "        if detected:\n",
    "            print(f\"\\nWeak Uptrend Details:\")\n",
    "            for key, value in result.items():\n",
    "                if key != 'symbol':  # Skip symbol as we already know it\n",
    "                    print(f\"  {key}: {value}\")\n",
    "    \n",
    "    else:\n",
    "        # For VSA strategies, import the appropriate get_params\n",
    "        if strategy_name == \"reversal_bar\":\n",
    "            from breakout_vsa.strategies.reversal_bar import get_params\n",
    "        elif strategy_name == \"breakout_bar\":\n",
    "            from breakout_vsa.strategies.breakout_bar import get_params\n",
    "        elif strategy_name == \"loaded_bar\":\n",
    "            from breakout_vsa.strategies.loaded_bar import get_params\n",
    "        elif strategy_name == \"stop_bar\":\n",
    "            from breakout_vsa.strategies.stop_bar import get_params\n",
    "        elif strategy_name == \"start_bar\":\n",
    "            from breakout_vsa.strategies.start_bar import get_params\n",
    "        else:\n",
    "            print(f\"Unknown strategy: {strategy_name}\")\n",
    "            return\n",
    "        \n",
    "        # Use vsa_detector with strategy-specific params\n",
    "        params = get_params()\n",
    "        condition, result = vsa_detector(df, params)\n",
    "        \n",
    "        strategy_display_name = strategy_name.replace('_vsa', '').replace('_', ' ').title()\n",
    "        print(f\"\\n{strategy_display_name} Detection Results:\")\n",
    "        print(f\"Current Bar (index -1): {condition.iloc[-1]}\")\n",
    "        if len(df) > 1:\n",
    "            print(f\"Last Closed Bar (index -2): {condition.iloc[-2]}\")\n",
    "        \n",
    "        if condition.iloc[-1] or (len(df) > 1 and condition.iloc[-2]):\n",
    "            detected_idx = -1 if condition.iloc[-1] else -2\n",
    "            volume_mean = df['volume'].rolling(7).mean().iloc[detected_idx]\n",
    "            bar_range = df['high'].iloc[detected_idx] - df['low'].iloc[detected_idx]\n",
    "            close_off_low = (df['close'].iloc[detected_idx] - df['low'].iloc[detected_idx]) / bar_range * 100 if bar_range > 0 else 0\n",
    "            volume_usd_detected = df['volume'].iloc[detected_idx] * df['close'].iloc[detected_idx]\n",
    "            \n",
    "            arctan_ratio = result['arctan_ratio'].iloc[detected_idx]  # From result DataFrame\n",
    "            \n",
    "            print(f\"\\nDetected at index {detected_idx} ({'Current' if detected_idx == -1 else 'Last Closed'} Bar):\")\n",
    "            print(f\"  Date: {df.index[detected_idx]}\")\n",
    "            print(f\"  Close: ${df['close'].iloc[detected_idx]:,.8f}\")\n",
    "            print(f\"  Volume Ratio: {df['volume'].iloc[detected_idx] / volume_mean if volume_mean > 0 else 0:.2f}x\")\n",
    "            print(f\"  {timeframe} Volume: ${volume_usd_detected:.2f}\")\n",
    "            print(f\"  Close Off Low: {close_off_low:.1f}%\")\n",
    "            print(f\"  Angular Ratio: {arctan_ratio:.2f}\")\n",
    "\n",
    "# Define the test case\n",
    "exchange_client = GateioSpotClient\n",
    "timeframe = \"1w\"\n",
    "symbol = \"PRCL_USDT\"\n",
    "strategy = \"loaded_bar\"\n",
    "await test_strategy(exchange_client, timeframe, symbol, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9bf3d-5437-413f-a6a8-2496412059e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#zip the project\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Go to parent directory of your project\n",
    "os.chdir(\"/home/jovyan/work/Crypto/sevenfigures-bot/hbs_2025\")\n",
    "\n",
    "# Create the zip file (this will include everything inside 'hbs_2025')\n",
    "shutil.make_archive(\"Project_VSA_2025_backup\", 'zip', \"Project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c74d8-f489-49e8-8596-c36b3960fbe6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 -> Debug built weekly candles for mexc and kucoin \n",
    "import sys\n",
    "import os\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "import asyncio\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exchanges.kucoin_client import KucoinClient\n",
    "from breakout_vsa.core import calculate_start_bar\n",
    "\n",
    "from scanner.main import kline_cache\n",
    "kline_cache.clear()  # Clear cache for fresh data\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "async def debug_start_bar_detection():\n",
    "    # Initialize client\n",
    "    client = KucoinClient(timeframe=\"1w\")\n",
    "    await client.init_session()\n",
    "    \n",
    "    # Symbol to debug\n",
    "    symbol = \"TAO-USDT\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data\n",
    "        df = await client.fetch_klines(symbol)\n",
    "        \n",
    "        if df is not None:\n",
    "            print(f\"Weekly candles for {symbol}:\")\n",
    "            print(df.tail())\n",
    "            \n",
    "            # Add intermediate calculations to see what's happening\n",
    "            # This is a modified version of calculate_start_bar that adds debugging\n",
    "            lookback = 5\n",
    "            volume_lookback = 30\n",
    "            volume_percentile = 50\n",
    "            low_percentile = 75\n",
    "            range_percentile = 75\n",
    "            close_off_lows_percent = 50\n",
    "            prev_close_range = 75\n",
    "            \n",
    "            # Calculate basic bar characteristics\n",
    "            df['bar_range'] = df['high'] - df['low']\n",
    "            df['volume_rank'] = df['volume'].rolling(lookback).apply(\n",
    "                lambda x: sum(1.0 for val in x if val <= x[-1]) / len(x) * 100, \n",
    "                raw=True\n",
    "            )\n",
    "            \n",
    "            # Calculate rolling values\n",
    "            df['macro_low'] = df['low'].rolling(volume_lookback).min()\n",
    "            df['macro_high'] = df['high'].rolling(volume_lookback).max()\n",
    "            df['highest_high'] = df['high'].rolling(lookback).max()\n",
    "            \n",
    "            # Volume conditions\n",
    "            df['volume_sma'] = df['volume'].rolling(volume_lookback).mean()\n",
    "            df['volume_std'] = df['volume'].rolling(volume_lookback).std()\n",
    "            df['excess_volume'] = df['volume'] > (df['volume_sma'] + 3.0 * df['volume_std'])\n",
    "            \n",
    "            # Range conditions\n",
    "            df['range_sma'] = df['bar_range'].rolling(volume_lookback).mean()\n",
    "            df['range_std'] = df['bar_range'].rolling(volume_lookback).std()\n",
    "            df['excess_range'] = df['bar_range'] > (df['range_sma'] + 3.0 * df['range_std'])\n",
    "            \n",
    "            # Volume percentile condition\n",
    "            def is_in_top_percent(series, length, percent):\n",
    "                ranks = series.rolling(length).apply(\n",
    "                    lambda x: sum(1.0 for val in x if val <= x[-1]) / len(x) * 100, \n",
    "                    raw=True\n",
    "                )\n",
    "                return ranks >= percent\n",
    "            \n",
    "            def is_in_bottom_percent(series, length, percent):\n",
    "                ranks = series.rolling(length).apply(\n",
    "                    lambda x: sum(1.0 for val in x if val <= x[-1]) / len(x) * 100, \n",
    "                    raw=True\n",
    "                )\n",
    "                return ranks <= percent\n",
    "            \n",
    "            # Volume conditions\n",
    "            df['is_higher_volume'] = is_in_top_percent(df['volume'], lookback, volume_percentile)\n",
    "            df['is_high_volume'] = (df['volume'] > 0.75 * df['volume_sma']) & (df['volume'] > df['volume'].shift(1))\n",
    "            \n",
    "            # Price action conditions\n",
    "            df['has_higher_high'] = df['high'] > df['high'].shift(1)\n",
    "            df['no_narrow_range'] = is_in_top_percent(df['bar_range'], lookback, range_percentile)\n",
    "            \n",
    "            # Low price condition\n",
    "            df['is_in_the_lows'] = (\n",
    "                (df['low'] - df['macro_low']).abs() < df['bar_range']\n",
    "            ) | is_in_bottom_percent(df['low'], volume_lookback, low_percentile)\n",
    "            \n",
    "            # Close position conditions\n",
    "            df['close_in_the_highs'] = (\n",
    "                (df['close'] - df['low']) / df['bar_range']\n",
    "            ) >= (close_off_lows_percent / 100)\n",
    "            \n",
    "            # Previous close distance condition\n",
    "            df['far_prev_close'] = (\n",
    "                (df['close'] - df['close'].shift(1)).abs() >=\n",
    "                (df['bar_range'].shift(1) * (prev_close_range / 100))\n",
    "            )\n",
    "            \n",
    "            # New highs condition\n",
    "            df['new_highs'] = df['high'] >= 0.75 * df['highest_high']\n",
    "            \n",
    "            # Optional strength condition\n",
    "            df['strong_close'] = df['close'] >= df['highest_high'].shift(1)\n",
    "            \n",
    "            # Now check the actual values for the last few bars\n",
    "            last_rows = df.tail(3)\n",
    "            \n",
    "            print(\"\\nAnalyzing last 3 bars:\")\n",
    "            for idx, row in last_rows.iterrows():\n",
    "                print(f\"\\nBar at {idx.strftime('%Y-%m-%d')}:\")\n",
    "                print(f\"  is_high_volume: {row['is_high_volume']}\")\n",
    "                print(f\"  has_higher_high: {row['has_higher_high']}\")\n",
    "                print(f\"  no_narrow_range: {row['no_narrow_range']}\")\n",
    "                print(f\"  close_in_the_highs: {row['close_in_the_highs']}\")\n",
    "                print(f\"  far_prev_close: {row['far_prev_close']}\")\n",
    "                print(f\"  excess_range: {row['excess_range']}\")\n",
    "                print(f\"  excess_volume: {row['excess_volume']}\")\n",
    "                print(f\"  new_highs: {row['new_highs']}\")\n",
    "                print(f\"  is_in_the_lows: {row['is_in_the_lows']}\")\n",
    "                print(f\"  volume: {row['volume']}, volume_sma: {row['volume_sma']}\")\n",
    "                print(f\"  bar_range: {row['bar_range']}, range_sma: {row['range_sma']}\")\n",
    "                \n",
    "            # Run the original function to confirm\n",
    "            start_bar_pattern = calculate_start_bar(df)\n",
    "            print(f\"\\nFinal Start Bar detection result:\")\n",
    "            print(start_bar_pattern.tail(3))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in debug: {str(e)}\")\n",
    "    finally:\n",
    "        await client.close_session()\n",
    "\n",
    "# Replace the last part of your script with this:\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # For Jupyter/IPython environments\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        asyncio.run(debug_start_bar_detection())\n",
    "    except ImportError:\n",
    "        # For regular Python environments\n",
    "        asyncio.run(debug_start_bar_detection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffeddd-c2c8-4f75-887f-9ed7d1961a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip the project\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Go to parent directory of your project\n",
    "os.chdir(\"/home/jovyan/work/Crypto/sevenfigures-bot/hbs_2025\")\n",
    "\n",
    "# Create the zip file (this will include everything inside 'hbs_2025')\n",
    "shutil.make_archive(\"Project_VSA_2025_backup\", 'zip', \"Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29951e-0a3b-4d0b-928c-0f2bfce7c11c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ARCHIVE - Confluence Scanner with bar offset\n",
    "\n",
    "from telegram.ext import Application\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import logging\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import sys\n",
    "import os\n",
    "import html\n",
    "\n",
    "# Add project path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from exchanges.sf_pairs_service import SFPairsService\n",
    "from custom_strategies import detect_confluence\n",
    "\n",
    "class ConfluenceScanner:\n",
    "    def __init__(self, telegram_token, telegram_chat_id, exchange, timeframe, offset=1):\n",
    "        self.telegram_token = telegram_token\n",
    "        self.telegram_chat_id = telegram_chat_id\n",
    "        self.telegram_app = None\n",
    "        self.exchange = exchange\n",
    "        self.timeframe = timeframe\n",
    "        self.offset = offset  # Added offset parameter\n",
    "        self.sf_service = SFPairsService()\n",
    "        \n",
    "    async def init_telegram(self):\n",
    "        if self.telegram_app is None:\n",
    "            self.telegram_app = Application.builder().token(self.telegram_token).build()\n",
    "\n",
    "    async def send_telegram_alert(self, results):\n",
    "        if not results:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            message = f\"🚨 Confluence Detection - {self.exchange} {self.timeframe}\\n\\n\"\n",
    "            \n",
    "            # Map timeframe to TradingView format\n",
    "            tv_timeframe_map = {\n",
    "                \"1d\": \"1D\",\n",
    "                \"2d\": \"2D\",\n",
    "                \"1w\": \"1W\"\n",
    "            }\n",
    "            tv_timeframe = tv_timeframe_map.get(self.timeframe.lower(), self.timeframe)\n",
    "            \n",
    "            for result in results:\n",
    "                exchange_name = self.exchange.upper()\n",
    "                formatted_symbol = f\"{result['symbol']}\"\n",
    "                tv_link = f\"https://www.tradingview.com/chart/?symbol={exchange_name}:{formatted_symbol}&interval={tv_timeframe}\"\n",
    "                \n",
    "                # Escape HTML entities in the URL\n",
    "                escaped_link = html.escape(tv_link)\n",
    "                \n",
    "                # Format according to specified requirements\n",
    "                time_str = \"\"\n",
    "                if result.get('timestamp') is not None:\n",
    "                    time_str = f\"Time: {result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "                \n",
    "                message += (\n",
    "                    f\"Symbol: {result['symbol']}\\n\"\n",
    "                    f\"{time_str}\"\n",
    "                    f\"Volume USD: ${result['volume_usd']:,.2f}\\n\"\n",
    "                    f\"Close: <a href='{escaped_link}'>${result['close']:,.8f}</a>\\n\"\n",
    "                    f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                    f\"Close Off Low: {result['close_off_low']:.1f}%\\n\"\n",
    "                    f\"{'='*30}\\n\"\n",
    "                )\n",
    "            \n",
    "            # Split message more carefully to avoid breaking HTML tags\n",
    "            max_length = 4000  # Reduced from 4096 to be safer\n",
    "            \n",
    "            if len(message) > max_length:\n",
    "                # Split at natural breaks (between results) to avoid breaking HTML\n",
    "                sections = message.split('='*30 + '\\n')\n",
    "                current_chunk = \"\"\n",
    "                \n",
    "                for section in sections:\n",
    "                    if len(current_chunk + section + '='*30 + '\\n') > max_length:\n",
    "                        if current_chunk:\n",
    "                            await self.telegram_app.bot.send_message(\n",
    "                                chat_id=self.telegram_chat_id,\n",
    "                                text=current_chunk.strip(),\n",
    "                                parse_mode='HTML',\n",
    "                                disable_web_page_preview=True\n",
    "                            )\n",
    "                        current_chunk = section + '\\n'\n",
    "                    else:\n",
    "                        current_chunk += section + '='*30 + '\\n'\n",
    "                \n",
    "                # Send remaining chunk\n",
    "                if current_chunk.strip():\n",
    "                    await self.telegram_app.bot.send_message(\n",
    "                        chat_id=self.telegram_chat_id,\n",
    "                        text=current_chunk.strip(),\n",
    "                        parse_mode='HTML',\n",
    "                        disable_web_page_preview=True\n",
    "                    )\n",
    "            else:\n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=message,\n",
    "                    parse_mode='HTML',\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending Telegram alert: {str(e)}\")\n",
    "            \n",
    "            # Fallback: send without HTML formatting\n",
    "            try:\n",
    "                simple_message = f\"🚨 Confluence Detection - {self.exchange} {self.timeframe}\\n\\n\"\n",
    "                for result in results:\n",
    "                    simple_message += (\n",
    "                        f\"Symbol: {result['symbol']}\\n\"\n",
    "                        f\"Volume USD: ${result['volume_usd']:,.2f}\\n\"\n",
    "                        f\"Close: ${result['close']:,.8f}\\n\"\n",
    "                        f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                        f\"Components: Vol={result['high_volume']}, Spread={result['spread_breakout']}, Mom={result['momentum_breakout']}\\n\\n\"\n",
    "                    )\n",
    "                \n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=simple_message,\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "            except Exception as fallback_error:\n",
    "                logging.error(f\"Fallback Telegram send also failed: {str(fallback_error)}\")\n",
    "\n",
    "    def prepare_sf_data(self, raw_df):\n",
    "        \"\"\"Convert SF data to confluence-compatible format\"\"\"\n",
    "        if raw_df is None or len(raw_df) == 0:\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(raw_df)\n",
    "        \n",
    "        # Convert datetime column to pandas datetime and set as index\n",
    "        if 'datetime' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df = df.set_index('datetime')\n",
    "        elif 'time' in df.columns:\n",
    "            # Convert Unix timestamp to datetime\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "            df = df.set_index('time')\n",
    "        \n",
    "        # Select only OHLCV columns needed for confluence\n",
    "        required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        \n",
    "        if len(available_cols) != 5:\n",
    "            return None\n",
    "        \n",
    "        # Select and clean data\n",
    "        result_df = df[required_cols].copy()\n",
    "        \n",
    "        # Ensure numeric types\n",
    "        for col in required_cols:\n",
    "            result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "        \n",
    "        # Drop any NaN rows\n",
    "        result_df = result_df.dropna()\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def scan_single_market(self, pair, ohlcv_data):\n",
    "        \"\"\"Scan a single market for Confluence pattern in the specified bar\"\"\"\n",
    "        try:\n",
    "            # Prepare data for confluence analysis\n",
    "            df = self.prepare_sf_data(ohlcv_data)\n",
    "            \n",
    "            if df is None or len(df) < 50:  # Need enough data for confluence\n",
    "                return None\n",
    "            \n",
    "            # Calculate which bar to check based on offset\n",
    "            check_bar = -(self.offset + 1)  # offset=0 means current bar (-1), offset=1 means last closed (-2), etc.\n",
    "            \n",
    "            # Run confluence detection\n",
    "            detected, result = detect_confluence(df, check_bar=check_bar)\n",
    "            \n",
    "            if detected:\n",
    "                # Calculate volume in USD for the target bar\n",
    "                target_close = df['close'].iloc[check_bar]\n",
    "                target_volume = df['volume'].iloc[check_bar]\n",
    "                volume_usd = float(target_close) * float(target_volume)\n",
    "                \n",
    "                confluence_result = {\n",
    "                    'symbol': f\"{pair['Token']}{pair['Quote']}\",\n",
    "                    'volume_usd': volume_usd,\n",
    "                    'close': float(target_close),\n",
    "                    'volume': float(target_volume),\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                    'bar_range': result['bar_range']\n",
    "                }\n",
    "                return confluence_result\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {pair['Token']}{pair['Quote']}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def scan_all_markets(self):\n",
    "        \"\"\"Scan all markets for Confluence pattern\"\"\"\n",
    "        await self.init_telegram()\n",
    "        try:\n",
    "            # Define volume thresholds\n",
    "            volume_thresholds = {\n",
    "                \"1w\": 300000,\n",
    "                \"2d\": 100000,\n",
    "                \"1d\": 50000\n",
    "            }\n",
    "            min_volume = volume_thresholds.get(self.timeframe.lower(), 50000)\n",
    "            \n",
    "            # Create offset description\n",
    "            if self.offset == 0:\n",
    "                offset_desc = \"current candle\"\n",
    "            elif self.offset == 1:\n",
    "                offset_desc = \"last closed candle\"\n",
    "            else:\n",
    "                offset_desc = f\"{self.offset} candles ago\"\n",
    "            \n",
    "            print(f\"Scanning for Confluence patterns in {offset_desc}...\")\n",
    "            print(f\"Minimum volume threshold: ${min_volume:,.0f}\")\n",
    "            \n",
    "            # Get all pairs from SF service\n",
    "            pairs = self.sf_service.get_pairs_of_exchange(self.exchange)\n",
    "            print(f\"Found {len(pairs)} markets to scan...\")\n",
    "            \n",
    "            # Process all pairs with progress bar\n",
    "            all_results = []\n",
    "            with tqdm(total=len(pairs), desc=\"Scanning markets\") as pbar:\n",
    "                for pair in pairs:\n",
    "                    try:\n",
    "                        # Get OHLCV data from SF service\n",
    "                        ohlcv_data = self.sf_service.get_ohlcv_for_pair(\n",
    "                            pair['Token'], \n",
    "                            pair['Quote'], \n",
    "                            self.exchange, \n",
    "                            self.timeframe, \n",
    "                            100  # Get more data for confluence analysis\n",
    "                        )\n",
    "                        \n",
    "                        if ohlcv_data is None or len(ohlcv_data) == 0:\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        df = pd.DataFrame(ohlcv_data)\n",
    "                        \n",
    "                        # Check if we have enough data\n",
    "                        if len(df) >= 50:  # Need enough for confluence analysis\n",
    "                            target_idx = -(self.offset + 1)  # Adjust index based on offset\n",
    "                            \n",
    "                            # Check volume threshold for the target candle\n",
    "                            try:\n",
    "                                target_candle_volume = float(df['close'].iloc[target_idx]) * float(df['volume'].iloc[target_idx])\n",
    "                                \n",
    "                                # Only process if volume meets threshold\n",
    "                                if target_candle_volume >= min_volume:\n",
    "                                    result = self.scan_single_market(pair, ohlcv_data)\n",
    "                                    if result:\n",
    "                                        all_results.append(result)\n",
    "                                        print(f\"Found Confluence: {pair['Token']}{pair['Quote']} 🎯\")\n",
    "                            except (IndexError, ValueError):\n",
    "                                pass  # Skip if we can't calculate volume\n",
    "                                    \n",
    "                    except Exception as e:\n",
    "                        if \"500\" not in str(e):  # Don't log 500 errors\n",
    "                            logging.error(f\"Error processing {pair['Token']}{pair['Quote']}: {str(e)}\")\n",
    "                    finally:\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            # Sort by volume\n",
    "            all_results.sort(key=lambda x: x['volume_usd'], reverse=True)\n",
    "            \n",
    "            # Send Telegram alert if we found any patterns\n",
    "            if all_results:\n",
    "                await self.send_telegram_alert(all_results)\n",
    "            \n",
    "            return all_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scanning markets: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "async def run_confluence_scanner(exchange, timeframe, offset=1):\n",
    "    \"\"\"\n",
    "    Run the Confluence scanner\n",
    "    \n",
    "    Parameters:\n",
    "    exchange (str): Exchange name (Kucoin, Mexc, Binance)\n",
    "    timeframe (str): Time period (1d, 2d, 1w)\n",
    "    offset (int): Bar offset (0=current, 1=last closed, 2=two bars ago, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if offset == 0:\n",
    "        offset_desc = \"current candle\"\n",
    "    elif offset == 1:\n",
    "        offset_desc = \"last closed candle\"\n",
    "    else:\n",
    "        offset_desc = f\"{offset} candles ago\"\n",
    "    \n",
    "    print(f\"Starting Confluence scan for {offset_desc} on {exchange} {timeframe}...\")\n",
    "    \n",
    "    # Use the confluence telegram token from your big project config\n",
    "    # You should replace this with the actual token from utils/config.py TELEGRAM_TOKENS[\"confluence\"]\n",
    "    telegram_token = \"8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g\"  # Replace with confluence token\n",
    "    telegram_chat_id = \"375812423\"  # Your chat ID\n",
    "    \n",
    "    scanner = ConfluenceScanner(telegram_token, telegram_chat_id, exchange, timeframe, offset)\n",
    "    results = await scanner.scan_all_markets()\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nFound {len(results)} Confluence patterns:\")\n",
    "        \n",
    "        # Convert results to DataFrame for console display\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # Round numeric columns\n",
    "        df_results['volume_usd'] = df_results['volume_usd'].round(2)\n",
    "        df_results['close'] = df_results['close'].round(8)\n",
    "        df_results['volume'] = df_results['volume'].round(2)\n",
    "        df_results['volume_ratio'] = df_results['volume_ratio'].round(2)\n",
    "        df_results['close_off_low'] = df_results['close_off_low'].round(1)\n",
    "        df_results['momentum_score'] = df_results['momentum_score'].round(4)\n",
    "        \n",
    "        # Reorder columns for better display\n",
    "        display_cols = ['symbol', 'close', 'volume_usd', 'volume_ratio', 'close_off_low', \n",
    "                       'momentum_score', 'high_volume', 'spread_breakout', 'momentum_breakout']\n",
    "        available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "        \n",
    "        # Display the results\n",
    "        print(df_results[available_cols])\n",
    "        \n",
    "        # Show component analysis\n",
    "        print(f\"\\n🔧 COMPONENT ANALYSIS:\")\n",
    "        vol_count = df_results['high_volume'].sum()\n",
    "        spread_count = df_results['spread_breakout'].sum()\n",
    "        momentum_count = df_results['momentum_breakout'].sum()\n",
    "        \n",
    "        print(f\"High Volume signals: {vol_count}/{len(results)} ({vol_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Spread Breakout signals: {spread_count}/{len(results)} ({spread_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Momentum Breakout signals: {momentum_count}/{len(results)} ({momentum_count/len(results)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nNo Confluence patterns found in {offset_desc}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Apply nest_asyncio to allow async operations in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Example usage functions\n",
    "async def scan_current_confluence():\n",
    "    \"\"\"Scan current candle for confluence\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", offset=0)\n",
    "\n",
    "async def scan_closed_confluence():\n",
    "    \"\"\"Scan last closed candle for confluence\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", offset=1)\n",
    "\n",
    "async def scan_previous_confluence():\n",
    "    \"\"\"Scan two candles ago for confluence\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", offset=2)\n",
    "\n",
    "# Main execution function\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main execution - modify parameters here\n",
    "    \"\"\"\n",
    "    exchange = \"Mexc\"  # Binance, Kucoin, Mexc\n",
    "    timeframe = \"1w\"     # 1d, 2d, 1w\n",
    "    offset = 0           # 0 = current candle, 1 = last closed candle, 2 = two candles ago\n",
    "    \n",
    "    await run_confluence_scanner(exchange, timeframe, offset)\n",
    "\n",
    "# Run the async main function\n",
    "print(\"🔍 CONFLUENCE SCANNER\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Available functions:\")\n",
    "print(\"• await main() - Run with default settings\")\n",
    "print(\"• await scan_current_confluence() - Scan current candle\")\n",
    "print(\"• await scan_closed_confluence() - Scan last closed candle\")\n",
    "print(\"• await scan_previous_confluence() - Scan two candles ago\")\n",
    "print(\"• await run_confluence_scanner('Exchange', 'timeframe', offset) - Custom scan\")\n",
    "print(\"\\nExample: await main()\")\n",
    "\n",
    "# Uncomment to auto-run:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016f39c-4a43-4dba-ab57-5c161bff6e4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Direct Test Bar Pattern Tester\n",
    "# This script directly tests the calculate_test_bar function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Apply nest_asyncio to make asyncio work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Add project directory to path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "# Import the necessary modules\n",
    "from exchanges import MexcSpotClient, BybitSpotClient, KucoinSpotClient\n",
    "\n",
    "def calculate_test_bar_direct(df):\n",
    "    \"\"\"\n",
    "    Direct implementation of Test Bar pattern detection for testing\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    df['bar_range'] = df['high'] - df['low']\n",
    "    \n",
    "    # Function to check if current bar is an inside bar\n",
    "    df['is_inside_bar'] = (df['high'] < df['high'].shift(1)) & (df['low'] > df['low'].shift(1))\n",
    "    \n",
    "    # Function to check if bar is down (close < open)\n",
    "    df['is_down_bar'] = df['close'] < df['open']\n",
    "    \n",
    "    # Function to check if close is in higher 65% of the spread (closing off the lows)\n",
    "    df['close_position'] = np.where(df['bar_range'] != 0, (df['close'] - df['low']) / df['bar_range'], 0)\n",
    "    df['close_off_lows'] = df['close_position'] >= 0.65\n",
    "    \n",
    "    # Function to check if current volume is less than 40% of previous bar volume\n",
    "    df['lower_volume_than_prev'] = df['volume'] < (df['volume'].shift(1) * 0.4)\n",
    "    \n",
    "    # Function to check if current volume is the lowest in last 3 bars\n",
    "    df['lowest_volume_in_3_bars'] = (df['volume'] < df['volume'].shift(1)) & (df['volume'] < df['volume'].shift(2))\n",
    "    \n",
    "    # Debug columns\n",
    "    df['debug_inside'] = df['is_inside_bar']\n",
    "    df['debug_down'] = df['is_down_bar'] \n",
    "    df['debug_close_off_lows'] = df['close_off_lows']\n",
    "    df['debug_lower_vol'] = df['lower_volume_than_prev']\n",
    "    df['debug_lowest_vol_3'] = df['lowest_volume_in_3_bars']\n",
    "    \n",
    "    # Main condition: all criteria must be met\n",
    "    test_bar_pattern = (\n",
    "        df['is_inside_bar'] &\n",
    "        df['is_down_bar'] &\n",
    "        df['close_off_lows'] &\n",
    "        df['lower_volume_than_prev'] &\n",
    "        df['lowest_volume_in_3_bars']\n",
    "    )\n",
    "    \n",
    "    # Signal only new occurrences\n",
    "    test_bar = test_bar_pattern & ~test_bar_pattern.shift(1).fillna(False)\n",
    "    \n",
    "    return test_bar, df\n",
    "\n",
    "async def test_direct_test_bar(exchange_client_class, timeframe, symbol):\n",
    "    \"\"\"Test the direct test_bar function on a specific symbol\"\"\"\n",
    "    print(f\"Testing DIRECT Test Bar detection on {symbol} ({timeframe})\")\n",
    "    \n",
    "    # Initialize exchange client and fetch data\n",
    "    client = exchange_client_class(timeframe=timeframe)\n",
    "    try:\n",
    "        await client.init_session()\n",
    "        df = await client.fetch_klines(symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {str(e)}\")\n",
    "        return\n",
    "    finally:\n",
    "        await client.close_session()\n",
    "    \n",
    "    if df is None or len(df) < 10:\n",
    "        print(f\"No data fetched for {symbol} or insufficient data\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\\\nLast 5 bars for {symbol}:\")\n",
    "    print(df[['open', 'high', 'low', 'close', 'volume']].tail(5))\n",
    "    \n",
    "    # Apply direct test_bar function\n",
    "    print(\"\\\\nApplying direct test_bar detection...\")\n",
    "    try:\n",
    "        test_bar_signals, df_with_debug = calculate_test_bar_direct(df)\n",
    "        \n",
    "        # Quick results first\n",
    "        current_detected = test_bar_signals.iloc[-1]\n",
    "        prev_detected = test_bar_signals.iloc[-2] if len(df) > 1 else False\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"QUICK RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Current Bar Test Pattern:  {current_detected}\")\n",
    "        print(f\"Previous Bar Test Pattern: {prev_detected}\")\n",
    "        \n",
    "        # If pattern detected, show which bar(s)\n",
    "        if current_detected or prev_detected:\n",
    "            print(\"\\\\nPATTERN DETECTED!\")\n",
    "            if current_detected:\n",
    "                print(\"  -> Current bar matches test pattern\")\n",
    "            if prev_detected:\n",
    "                print(\"  -> Previous bar matches test pattern\")\n",
    "        else:\n",
    "            print(\"\\\\nNO PATTERN DETECTED\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"CONDITION BREAKDOWN\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Show only last 2 bars for condition analysis\n",
    "        for i in range(max(0, len(df)-2), len(df)):\n",
    "            if i < 2:  # Skip early bars that don't have enough history\n",
    "                continue\n",
    "            \n",
    "            bar_range = df['high'].iloc[i] - df['low'].iloc[i]\n",
    "            close_position = (df['close'].iloc[i] - df['low'].iloc[i]) / bar_range * 100 if bar_range > 0 else 0\n",
    "            \n",
    "            print(f\"\\\\nBAR {i} ({df.index[i].date()})\")\n",
    "            print(f\"OHLC: O={df['open'].iloc[i]:.6f} H={df['high'].iloc[i]:.6f} L={df['low'].iloc[i]:.6f} C={df['close'].iloc[i]:.6f}\")\n",
    "            print(f\"Volume: {df['volume'].iloc[i]:,.0f}\")\n",
    "            \n",
    "            if i > 0:\n",
    "                prev_high = df['high'].iloc[i-1]\n",
    "                prev_low = df['low'].iloc[i-1]\n",
    "                prev_volume = df['volume'].iloc[i-1]\n",
    "                volume_40_pct = prev_volume * 0.4\n",
    "                \n",
    "                # Show conditions in a clean table format\n",
    "                conditions = [\n",
    "                    (\"Inside Bar\", df_with_debug['debug_inside'].iloc[i]),\n",
    "                    (\"Down Bar\", df_with_debug['debug_down'].iloc[i]),\n",
    "                    (\"Close >= 65% from Low\", df_with_debug['debug_close_off_lows'].iloc[i]),\n",
    "                    (\"Volume < 40% of Previous\", df_with_debug['debug_lower_vol'].iloc[i]),\n",
    "                    (\"Lowest Volume in 3 bars\", df_with_debug['debug_lowest_vol_3'].iloc[i])\n",
    "                ]\n",
    "                \n",
    "                print(\"\\\\nConditions:\")\n",
    "                for condition_name, result in conditions:\n",
    "                    status = \"✓\" if result else \"✗\"\n",
    "                    print(f\"  {status} {condition_name:<25} {result}\")\n",
    "                \n",
    "                # Show key metrics\n",
    "                print(\"\\\\nKey Metrics:\")\n",
    "                print(f\"  Close Position: {close_position:.1f}% from low\")\n",
    "                print(f\"  Current Volume: {df['volume'].iloc[i]:,.0f}\")\n",
    "                print(f\"  40% of Prev Vol: {volume_40_pct:,.0f}\")\n",
    "                \n",
    "                if i > 1:\n",
    "                    vol_prev_2 = df['volume'].iloc[i-2]\n",
    "                    print(f\"  Previous Vol: {prev_volume:,.0f}\")\n",
    "                    print(f\"  Previous-2 Vol: {vol_prev_2:,.0f}\")\n",
    "                \n",
    "                # Final result for this bar\n",
    "                all_conditions_met = all(result for _, result in conditions)\n",
    "                print(f\"\\\\nAll Conditions Met: {all_conditions_met}\")\n",
    "                print(f\"Test Bar Signal: {test_bar_signals.iloc[i]}\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error running direct test_bar detection: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Test parameters\n",
    "exchange_client = KucoinSpotClient\n",
    "timeframe = \"1d\"\n",
    "symbol = \"TEL-USDT\"\n",
    "\n",
    "# Run the test\n",
    "await test_direct_test_bar(exchange_client, timeframe, symbol)\n",
    "\n",
    "print(\"\\\\n✅ Direct test bar detection test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0c836-afa7-4fba-94d7-0dfafef0f8c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standalone HLC Bar Chart Plotter\n",
    "A reusable function for plotting HLC bars with optional pattern highlighting\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_hlc_bars(data, highlighted_bars=None, title=\"HLC Chart\", symbol=\"SYMBOL\", \n",
    "                  interval=\"1d\", semilog=False, highlight_color=\"fuchsia\", \n",
    "                  highlight_label=\"Pattern\", figsize=(14, 10), show_volume=True):\n",
    "    \"\"\"\n",
    "    Plot HLC bar chart with optional pattern highlighting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with columns: ['datetime', 'high', 'low', 'close', 'volume']\n",
    "        - datetime: timestamp column (will be used for x-axis)\n",
    "        - high: high prices\n",
    "        - low: low prices  \n",
    "        - close: close prices\n",
    "        - volume: volume data (optional if show_volume=False)\n",
    "        \n",
    "    highlighted_bars : pandas.Series or list/array, optional\n",
    "        Boolean series or array indicating which bars to highlight\n",
    "        Length must match data length\n",
    "        \n",
    "    title : str, default \"HLC Chart\"\n",
    "        Chart title\n",
    "        \n",
    "    symbol : str, default \"SYMBOL\" \n",
    "        Symbol name for display\n",
    "        \n",
    "    interval : str, default \"1d\"\n",
    "        Time interval for date formatting (1m, 5m, 15m, 30m, 1h, 4h, 1d, 3d, 1w, 1M)\n",
    "        \n",
    "    semilog : bool, default False\n",
    "        Use logarithmic scale for price chart\n",
    "        \n",
    "    highlight_color : str, default \"fuchsia\"\n",
    "        Color for highlighted bars\n",
    "        \n",
    "    highlight_label : str, default \"Pattern\"\n",
    "        Label for highlighted bars in legend\n",
    "        \n",
    "    figsize : tuple, default (14, 10)\n",
    "        Figure size (width, height)\n",
    "        \n",
    "    show_volume : bool, default True\n",
    "        Whether to show volume subplot\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The created figure object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"data must be a pandas DataFrame\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_cols = ['datetime', 'high', 'low', 'close']\n",
    "    if show_volume:\n",
    "        required_cols.append('volume')\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"data DataFrame is empty\")\n",
    "    \n",
    "    # Validate highlighted_bars\n",
    "    if highlighted_bars is not None:\n",
    "        if len(highlighted_bars) != len(data):\n",
    "            raise ValueError(\"highlighted_bars length must match data length\")\n",
    "        # Convert to boolean array\n",
    "        highlighted_bars = np.array(highlighted_bars, dtype=bool)\n",
    "    else:\n",
    "        highlighted_bars = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    if show_volume:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, \n",
    "                                       gridspec_kw={'height_ratios': [3, 1]})\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "        ax2 = None\n",
    "    \n",
    "    # Convert dates to numbers for plotting\n",
    "    dates = mdates.date2num(data['datetime'])\n",
    "    \n",
    "    # Calculate margins and tick length\n",
    "    date_range = dates[-1] - dates[0] if len(dates) > 1 else 1\n",
    "    margin = date_range * 0.05\n",
    "    \n",
    "    # Calculate actual bar spacing for consistent tick length\n",
    "    if len(dates) > 1:\n",
    "        avg_bar_spacing = date_range / (len(dates) - 1)\n",
    "        tick_length = avg_bar_spacing * 0.4  # 40% of bar spacing\n",
    "        volume_bar_width = avg_bar_spacing * 0.8\n",
    "    else:\n",
    "        tick_length = date_range * 0.01\n",
    "        volume_bar_width = date_range * 0.02\n",
    "    \n",
    "    # Draw HLC bars\n",
    "    for i, (date, high, low, close) in enumerate(zip(dates, data['high'], data['low'], data['close'])):\n",
    "        is_highlighted = highlighted_bars[i]\n",
    "        color = highlight_color if is_highlighted else 'black'\n",
    "        line_width = 1.2\n",
    "        \n",
    "        # Vertical line from low to high\n",
    "        ax1.plot([date, date], [low, high], color=color, linewidth=line_width, solid_capstyle='butt')\n",
    "        \n",
    "        # Horizontal tick mark for close (on the right side)\n",
    "        ax1.plot([date, date + tick_length], [close, close], color=color, \n",
    "                linewidth=line_width+0.5, solid_capstyle='butt')\n",
    "    \n",
    "    # Configure price chart\n",
    "    if semilog:\n",
    "        ax1.set_yscale('log')\n",
    "        scale_text = \"Semilog Scale\"\n",
    "    else:\n",
    "        scale_text = \"Linear Scale\"\n",
    "    \n",
    "    ax1.set_title(f'{symbol} {title} - {scale_text}', fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel('Price', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format x-axis based on timeframe\n",
    "    _format_datetime_axis(ax1, interval)\n",
    "    ax1.set_xlim(dates[0] - margin, dates[-1] + margin)\n",
    "    \n",
    "    # Volume chart\n",
    "    if show_volume and ax2 is not None:\n",
    "        volume_colors = [highlight_color if highlighted_bars[i] else 'orange' for i in range(len(dates))]\n",
    "        volume_edges = ['darkmagenta' if highlighted_bars[i] else 'darkorange' for i in range(len(dates))]\n",
    "        \n",
    "        ax2.bar(dates, data['volume'], width=volume_bar_width, alpha=0.6, \n",
    "                color=volume_colors, edgecolor=volume_edges)\n",
    "        ax2.set_ylabel('Volume', fontsize=12)\n",
    "        ax2.set_xlabel('Date', fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        _format_datetime_axis(ax2, interval)\n",
    "        ax2.set_xlim(dates[0] - margin, dates[-1] + margin)\n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    else:\n",
    "        ax1.set_xlabel('Date', fontsize=12)\n",
    "    \n",
    "    # Create legend\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='black', linewidth=2, label='High-Low Range'),\n",
    "        Line2D([0], [0], color='black', linewidth=3, label='Close Price (right tick)')\n",
    "    ]\n",
    "    \n",
    "    # Add highlighted bars to legend if any exist\n",
    "    if highlighted_bars.any():\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=highlight_color, linewidth=3, label=highlight_label)\n",
    "        )\n",
    "        highlight_count = highlighted_bars.sum()\n",
    "    else:\n",
    "        highlight_count = 0\n",
    "    \n",
    "    ax1.legend(handles=legend_elements, loc='upper left', title=scale_text)\n",
    "    \n",
    "    # Add pattern count if patterns exist\n",
    "    if highlight_count > 0:\n",
    "        ax1.text(0.99, 0.95, f'{highlight_label}: {highlight_count}', \n",
    "                transform=ax1.transAxes, ha='right', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                fontsize=10)\n",
    "    \n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def _format_datetime_axis(ax, interval):\n",
    "    \"\"\"Helper function to format datetime axis based on interval\"\"\"\n",
    "    if interval in ['1m', '5m', '15m', '30m']:\n",
    "        ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "    elif interval in ['1h', '2h', '4h', '6h', '12h']:\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    elif interval in ['1d', '3d']:\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    else:  # weekly, monthly\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "# Example usage and test function\n",
    "def example_usage():\n",
    "    \"\"\"Example showing how to use the plot_hlc_bars function\"\"\"\n",
    "    \n",
    "    # Create sample data\n",
    "    import datetime\n",
    "    dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate realistic OHLC data\n",
    "    closes = 100 + np.cumsum(np.random.randn(100) * 0.02)\n",
    "    highs = closes + np.random.rand(100) * 5\n",
    "    lows = closes - np.random.rand(100) * 5\n",
    "    volumes = np.random.rand(100) * 1000000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'datetime': dates,\n",
    "        'high': highs,\n",
    "        'low': lows, \n",
    "        'close': closes,\n",
    "        'volume': volumes\n",
    "    })\n",
    "    \n",
    "    # Create some random pattern detections\n",
    "    pattern_detected = np.random.choice([True, False], size=100, p=[0.1, 0.9])\n",
    "    \n",
    "    # Plot with pattern highlighting\n",
    "    fig = plot_hlc_bars(\n",
    "        data=data,\n",
    "        highlighted_bars=pattern_detected,\n",
    "        title=\"Daily Chart with Pattern Detection\",\n",
    "        symbol=\"EXAMPLE\",\n",
    "        interval=\"1d\",\n",
    "        semilog=False,\n",
    "        highlight_color=\"red\",\n",
    "        highlight_label=\"Detected Pattern\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# Scanner integration example\n",
    "def scanner_integration_example():\n",
    "    \"\"\"Example of how to integrate with a scanner function\"\"\"\n",
    "    \n",
    "    def my_pattern_scanner(data):\n",
    "        \"\"\"\n",
    "        Example scanner function - replace with your actual scanner logic\n",
    "        Returns boolean array indicating pattern detection\n",
    "        \"\"\"\n",
    "        # Example: detect when close > 20-period moving average\n",
    "        ma20 = data['close'].rolling(20).mean()\n",
    "        pattern = (data['close'] > ma20) & (data['volume'] > data['volume'].rolling(10).mean())\n",
    "        return pattern.fillna(False)\n",
    "    \n",
    "    # Your data loading logic here\n",
    "    # data = load_your_data()  # Replace with actual data loading\n",
    "    \n",
    "    # For demo, create sample data\n",
    "    dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
    "    np.random.seed(42)\n",
    "    closes = 100 + np.cumsum(np.random.randn(200) * 0.02)\n",
    "    highs = closes + np.random.rand(200) * 3\n",
    "    lows = closes - np.random.rand(200) * 3\n",
    "    volumes = np.random.rand(200) * 1000000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'datetime': dates,\n",
    "        'high': highs,\n",
    "        'low': lows,\n",
    "        'close': closes,\n",
    "        'volume': volumes\n",
    "    })\n",
    "    \n",
    "    # Run your scanner\n",
    "    detected_patterns = my_pattern_scanner(data)\n",
    "    \n",
    "    # Plot only if patterns are detected\n",
    "    if detected_patterns.any():\n",
    "        print(f\"Patterns detected! Found {detected_patterns.sum()} occurrences\")\n",
    "        fig = plot_hlc_bars(\n",
    "            data=data,\n",
    "            highlighted_bars=detected_patterns,\n",
    "            title=\"Scanner Results\",\n",
    "            symbol=\"SCANNED_SYMBOL\",\n",
    "            interval=\"1d\",\n",
    "            highlight_color=\"lime\",\n",
    "            highlight_label=\"Scanner Hit\"\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No patterns detected\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run example\n",
    "    example_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
