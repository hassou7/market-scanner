{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab56392-9bd5-48da-aef6-5dddab880329",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f493cf4-15f9-4d57-b16c-cb3ee2b33977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Run Simple Parallel Scan for Test Bar\n",
    "\n",
    "This script runs the test bar scan across multiple exchanges in parallel\n",
    "using a simplified parallel scanning approach that avoids console output issues.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "# Add project directory to path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "# Add current directory to path\n",
    "sys.path.append(os.getcwd())\n",
    "print(f\"✓ Added {os.getcwd()} to sys.path\")\n",
    "\n",
    "# Import the simple parallel scanner\n",
    "from run_parallel_scanner import run_parallel_exchanges, run_parallel_multi_timeframes_all_exchanges\n",
    "from scanner.main import kline_cache\n",
    "\n",
    "# Define exchanges\n",
    "futures_exchanges = [\"binance_futures\", \"bybit_futures\", \"mexc_futures\", \"gateio_futures\"]\n",
    "spot_exchanges = [\"binance_spot\", \"bybit_spot\", \"kucoin_spot\", \"mexc_spot\", \"gateio_spot\"]\n",
    "spot_exchanges_1w = [\"binance_spot\", \"bybit_spot\", \"gateio_spot\"]\n",
    "\n",
    "async def main():\n",
    "    # Clear cache for fresh data\n",
    "    kline_cache.clear()\n",
    "    \n",
    "    \"\"\"\n",
    "    # Run parallel scan for test bar strategy on spot exchanges\n",
    "    result = await run_parallel_exchanges(\n",
    "        timeframe=\"4h\",                    # Example timeframe\n",
    "        strategies=[\"confluence\", \"test_bar\", \"consolidation\"],\n",
    "        # strategies=[\"reversal_bar\"],       \n",
    "        exchanges=spot_exchanges,          # Spot exchanges to scan\n",
    "        users=[\"default\"],                 # Recipients for Telegram notifications\n",
    "        send_telegram=True,                # Enable Telegram notifications\n",
    "        min_volume_usd=None                # Use default volume threshold\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Run multi-timeframe parallel scan\n",
    "    result = await run_parallel_multi_timeframes_all_exchanges(\n",
    "        timeframes=[\"2d\"],     # Multiple timeframes\n",
    "        strategies=[\"hbs_breakout\"],        # Strategies to scan\n",
    "        exchanges=[\"binance_spot\", \"binance_futures\", \"bybit_spot\", \"kucoin_spot\", \"mexc_spot\", \"gateio_spot\"],          # Exchanges to scan\n",
    "        users=[\"default\"],                 # Recipients for notifications\n",
    "        send_telegram=True,                # Enable notifications\n",
    "        min_volume_usd=None                # Use default volume threshold\n",
    "    )\n",
    "     #\"\"\"\n",
    "    \n",
    "    print(\"Scan completed!\")\n",
    "    return result\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c86d73-1174-45d1-b215-842f2609b235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Seven Figures Weekly Strategy Scanner for KuCoin & MEXC\n",
    "\n",
    "This notebook runs weekly strategy detection using SF server data for KuCoin and MEXC exchanges.\n",
    "You can choose between: hbs_breakout, consolidation_breakout, and confluence strategies.\n",
    "Both exchanges are scanned simultaneously with parallel processing.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import nest_asyncio\n",
    "\n",
    "# Setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Add project directory to path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "# Import strategies and SF service\n",
    "from exchanges.sf_pairs_service import SFPairsService\n",
    "from custom_strategies import detect_consolidation_breakout, detect_confluence\n",
    "\n",
    "class SFWeeklyStrategyScanner:\n",
    "    \"\"\"\n",
    "    Weekly strategy scanner using Seven Figures server data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sf_service = SFPairsService()\n",
    "        self.strategy_functions = {\n",
    "            'consolidation_breakout': self.detect_consolidation_breakout,\n",
    "            'confluence': self.detect_confluence,\n",
    "            'hbs_breakout': self.detect_hbs_breakout\n",
    "        }\n",
    "        \n",
    "    def prepare_sf_data(self, raw_df):\n",
    "        \"\"\"Convert SF data to strategy-compatible format\"\"\"\n",
    "        if raw_df is None or len(raw_df) == 0:\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(raw_df)\n",
    "        \n",
    "        # Convert datetime column to pandas datetime and set as index\n",
    "        if 'datetime' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df = df.set_index('datetime')\n",
    "        elif 'time' in df.columns:\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "            df = df.set_index('time')\n",
    "        \n",
    "        # Select only OHLCV columns needed\n",
    "        required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        \n",
    "        if len(available_cols) != 5:\n",
    "            return None\n",
    "        \n",
    "        # Select and clean data\n",
    "        result_df = df[required_cols].copy()\n",
    "        \n",
    "        # Ensure numeric types\n",
    "        for col in required_cols:\n",
    "            result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "        \n",
    "        # Drop any NaN rows\n",
    "        result_df = result_df.dropna()\n",
    "        \n",
    "        # Sort by index (oldest first)\n",
    "        result_df = result_df.sort_index()\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def detect_consolidation_breakout(self, df, symbol, exchange):\n",
    "        \"\"\"Detect consolidation breakout signals\"\"\"\n",
    "        signals = []\n",
    "        \n",
    "        # Check last closed bar\n",
    "        if len(df) > 1:\n",
    "            detected, result = detect_consolidation_breakout(df, check_bar=-2)\n",
    "            if detected:\n",
    "                # Calculate volume info\n",
    "                volume_usd = df['volume'].iloc[-2] * df['close'].iloc[-2]\n",
    "                volume_mean = df['volume'].rolling(7).mean().iloc[-2]\n",
    "                volume_ratio = df['volume'].iloc[-2] / volume_mean if volume_mean > 0 else 0\n",
    "                \n",
    "                signals.append({\n",
    "                    'symbol': symbol,\n",
    "                    'exchange': exchange,\n",
    "                    'strategy': 'consolidation_breakout',\n",
    "                    'direction': result.get('direction'),\n",
    "                    'timestamp': result.get('timestamp', df.index[-2]),\n",
    "                    'close': df['close'].iloc[-2],\n",
    "                    'current_bar': False,\n",
    "                    'volume_usd': volume_usd,\n",
    "                    'volume_ratio': volume_ratio,\n",
    "                    'box_hi': result.get('box_hi'),\n",
    "                    'box_lo': result.get('box_lo'),\n",
    "                    'box_age': result.get('box_age'),\n",
    "                    'bars_inside': result.get('bars_inside'),\n",
    "                    'height_pct': result.get('height_pct'),\n",
    "                })\n",
    "        \n",
    "        # Check current bar\n",
    "        if len(df) > 2:\n",
    "            detected, result = detect_consolidation_breakout(df, check_bar=-1)\n",
    "            if detected:\n",
    "                # Calculate volume info\n",
    "                volume_usd = df['volume'].iloc[-1] * df['close'].iloc[-1]\n",
    "                volume_mean = df['volume'].rolling(7).mean().iloc[-1]\n",
    "                volume_ratio = df['volume'].iloc[-1] / volume_mean if volume_mean > 0 else 0\n",
    "                \n",
    "                signals.append({\n",
    "                    'symbol': symbol,\n",
    "                    'exchange': exchange,\n",
    "                    'strategy': 'consolidation_breakout',\n",
    "                    'direction': result.get('direction'),\n",
    "                    'timestamp': result.get('timestamp', df.index[-1]),\n",
    "                    'close': df['close'].iloc[-1],\n",
    "                    'current_bar': True,\n",
    "                    'volume_usd': volume_usd,\n",
    "                    'volume_ratio': volume_ratio,\n",
    "                    'box_hi': result.get('box_hi'),\n",
    "                    'box_lo': result.get('box_lo'),\n",
    "                    'box_age': result.get('box_age'),\n",
    "                    'bars_inside': result.get('bars_inside'),\n",
    "                    'height_pct': result.get('height_pct'),\n",
    "                })\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def detect_confluence(self, df, symbol, exchange):\n",
    "        \"\"\"Detect confluence signals\"\"\"\n",
    "        signals = []\n",
    "        \n",
    "        # Check last closed bar\n",
    "        if len(df) > 1:\n",
    "            detected, result = detect_confluence(df, check_bar=-2)\n",
    "            if detected:\n",
    "                signals.append({\n",
    "                    'symbol': symbol,\n",
    "                    'exchange': exchange,\n",
    "                    'strategy': 'confluence',\n",
    "                    'timestamp': result['timestamp'],\n",
    "                    'close': result['close_price'],\n",
    "                    'current_bar': False,\n",
    "                    'volume': result['volume'],\n",
    "                    'volume_usd': result['volume_usd'],\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                })\n",
    "        \n",
    "        # Check current bar\n",
    "        if len(df) > 2:\n",
    "            detected, result = detect_confluence(df, check_bar=-1)\n",
    "            if detected:\n",
    "                signals.append({\n",
    "                    'symbol': symbol,\n",
    "                    'exchange': exchange,\n",
    "                    'strategy': 'confluence',\n",
    "                    'timestamp': result['timestamp'],\n",
    "                    'close': result['close_price'],\n",
    "                    'current_bar': True,\n",
    "                    'volume': result['volume'],\n",
    "                    'volume_usd': result['volume_usd'],\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                })\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    def detect_hbs_breakout(self, df, symbol, exchange):\n",
    "        \"\"\"Detect HBS (Consolidation + Confluence) breakout signals\"\"\"\n",
    "        signals = []\n",
    "        \n",
    "        # Check both bars for consolidation breakout\n",
    "        cb_detected_prev, cb_result_prev = detect_consolidation_breakout(df, check_bar=-2)\n",
    "        cb_detected_curr, cb_result_curr = detect_consolidation_breakout(df, check_bar=-1)\n",
    "        \n",
    "        # Check both bars for confluence\n",
    "        cf_detected_prev, cf_result_prev = detect_confluence(df, check_bar=-2)\n",
    "        cf_detected_curr, cf_result_curr = detect_confluence(df, check_bar=-1)\n",
    "        \n",
    "        # HBS requires BOTH consolidation breakout AND confluence\n",
    "        cb_fired = cb_detected_prev or cb_detected_curr\n",
    "        cf_fired = cf_detected_prev or cf_detected_curr\n",
    "        \n",
    "        if cb_fired and cf_fired:\n",
    "            # Use the most recent consolidation breakout result\n",
    "            if cb_detected_curr:\n",
    "                cb_result = cb_result_curr\n",
    "                bar_idx = -1\n",
    "                current_bar = True\n",
    "            else:\n",
    "                cb_result = cb_result_prev\n",
    "                bar_idx = -2\n",
    "                current_bar = False\n",
    "            \n",
    "            # Calculate volume info\n",
    "            volume_usd = df['volume'].iloc[bar_idx] * df['close'].iloc[bar_idx]\n",
    "            volume_mean = df['volume'].rolling(7).mean().iloc[bar_idx]\n",
    "            volume_ratio = df['volume'].iloc[bar_idx] / volume_mean if volume_mean > 0 else 0\n",
    "            \n",
    "            signals.append({\n",
    "                'symbol': symbol,\n",
    "                'exchange': exchange,\n",
    "                'strategy': 'hbs_breakout',\n",
    "                'direction': cb_result.get('direction'),\n",
    "                'timestamp': cb_result.get('timestamp', df.index[bar_idx]),\n",
    "                'close': df['close'].iloc[bar_idx],\n",
    "                'current_bar': current_bar,\n",
    "                'volume_usd': volume_usd,\n",
    "                'volume_ratio': volume_ratio,\n",
    "                \n",
    "                # Consolidation data\n",
    "                'box_hi': cb_result.get('box_hi'),\n",
    "                'box_lo': cb_result.get('box_lo'),\n",
    "                'box_age': cb_result.get('box_age'),\n",
    "                'bars_inside': cb_result.get('bars_inside'),\n",
    "                'height_pct': cb_result.get('height_pct'),\n",
    "                \n",
    "                # Confluence data\n",
    "                'cf_detected_prev': cf_detected_prev,\n",
    "                'cf_detected_curr': cf_detected_curr,\n",
    "                'cb_detected_prev': cb_detected_prev,\n",
    "                'cb_detected_curr': cb_detected_curr,\n",
    "            })\n",
    "        \n",
    "        return signals\n",
    "    \n",
    "    async def scan_exchange_pairs(self, exchange, strategy, volume_threshold=300000, max_pairs=None):\n",
    "        \"\"\"Scan all pairs for an exchange with the selected strategy\"\"\"\n",
    "        print(f\"\\n🔍 Scanning {exchange} for {strategy} signals...\")\n",
    "        print(f\"📊 Volume threshold: ${volume_threshold:,}\")\n",
    "        \n",
    "        # Get all pairs from exchange\n",
    "        all_pairs = self.sf_service.get_pairs_of_exchange(exchange)\n",
    "        \n",
    "        # Filter for USDT pairs\n",
    "        usdt_pairs = [\n",
    "            pair for pair in all_pairs \n",
    "            if 'Quote' in pair and pair['Quote'].upper() == \"USDT\"\n",
    "        ]\n",
    "        \n",
    "        print(f\"📋 Found {len(usdt_pairs)} USDT pairs on {exchange}\")\n",
    "        \n",
    "        # Use all pairs unless max_pairs is specified\n",
    "        if max_pairs is None:\n",
    "            pairs_to_scan = usdt_pairs\n",
    "            print(f\"🔄 Scanning ALL {len(pairs_to_scan)} pairs...\")\n",
    "        else:\n",
    "            pairs_to_scan = usdt_pairs[:max_pairs]\n",
    "            print(f\"🔄 Scanning {len(pairs_to_scan)} pairs (limited by max_pairs={max_pairs})...\")\n",
    "        \n",
    "        all_signals = []\n",
    "        \n",
    "        # Use tqdm for progress tracking\n",
    "        for pair in tqdm(pairs_to_scan, desc=f\"{exchange} {strategy}\"):\n",
    "            try:\n",
    "                token = pair['Token']\n",
    "                \n",
    "                # Skip stablecoins\n",
    "                if token.upper() in ['USDT', 'USDC', 'BUSD', 'DAI', 'TUSD']:\n",
    "                    continue\n",
    "                \n",
    "                # Get weekly OHLCV data (50 weeks for good analysis)\n",
    "                raw_data = self.sf_service.get_ohlcv_for_pair(\n",
    "                    token, 'USDT', exchange, '1w', 50\n",
    "                )\n",
    "                \n",
    "                if raw_data is None or len(raw_data) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Prepare data\n",
    "                df = self.prepare_sf_data(raw_data)\n",
    "                if df is None or len(df) < 25:  # Need minimum data\n",
    "                    continue\n",
    "                \n",
    "                # Check volume threshold on recent bars (both current and last closed)\n",
    "                current_volume_usd = df['close'].iloc[-1] * df['volume'].iloc[-1]\n",
    "                last_closed_volume_usd = df['close'].iloc[-2] * df['volume'].iloc[-2]\n",
    "                \n",
    "                # Accept if either current or last closed bar meets volume threshold\n",
    "                if current_volume_usd < volume_threshold and last_closed_volume_usd < volume_threshold:\n",
    "                    continue\n",
    "                \n",
    "                # Run the selected strategy\n",
    "                strategy_func = self.strategy_functions.get(strategy)\n",
    "                if strategy_func:\n",
    "                    signals = strategy_func(df, f\"{token}USDT\", exchange)\n",
    "                    if signals:\n",
    "                        all_signals.extend(signals)\n",
    "                        for signal in signals:\n",
    "                            bar_type = \"current\" if signal.get('current_bar') else \"last closed\"\n",
    "                            direction = signal.get('direction', 'N/A')\n",
    "                            print(f\"🎯 {strategy} signal found: {token}USDT on {exchange} ({bar_type} bar, {direction})\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                # Skip errors silently to avoid spam\n",
    "                continue\n",
    "        \n",
    "        print(f\"✅ {exchange} scan complete: {len(all_signals)} {strategy} signals found\")\n",
    "        return all_signals\n",
    "    \n",
    "    async def run_parallel_scan(self, strategy='consolidation_breakout', volume_threshold=300000, max_pairs=None):\n",
    "        \"\"\"Run parallel scan on both KuCoin and MEXC\"\"\"\n",
    "        \n",
    "        exchanges = ['Kucoin', 'Mexc']\n",
    "        strategy_name = strategy.replace('_', ' ').title()\n",
    "        \n",
    "        print(f\"🚀 STARTING PARALLEL SF WEEKLY SCAN\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"📊 Strategy: {strategy_name}\")\n",
    "        print(f\"🏢 Exchanges: {', '.join(exchanges)}\")\n",
    "        print(f\"📅 Timeframe: Weekly (1w)\")\n",
    "        print(f\"💰 Min Volume: ${volume_threshold:,}\")\n",
    "        if max_pairs:\n",
    "            print(f\"🎯 Max Pairs per Exchange: {max_pairs}\")\n",
    "        else:\n",
    "            print(f\"🎯 Scanning ALL pairs on each exchange\")\n",
    "        print(f\"📊 Checking: Current bar AND last closed bar\")\n",
    "        print(f\"🕐 Start Time: {datetime.now().strftime('%H:%M:%S')}\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Create tasks for both exchanges\n",
    "        tasks = [\n",
    "            self.scan_exchange_pairs(exchange, strategy, volume_threshold, max_pairs)\n",
    "            for exchange in exchanges\n",
    "        ]\n",
    "        \n",
    "        # Run both exchanges in parallel\n",
    "        results = await asyncio.gather(*tasks)\n",
    "        \n",
    "        # Combine results\n",
    "        all_signals = []\n",
    "        for exchange_signals in results:\n",
    "            all_signals.extend(exchange_signals)\n",
    "        \n",
    "        end_time = datetime.now()\n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"📊 SCAN RESULTS - {strategy_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"🕐 Duration: {str(duration).split('.')[0]}\")\n",
    "        print(f\"🎯 Total Signals: {len(all_signals)}\")\n",
    "        \n",
    "        if all_signals:\n",
    "            # Convert to DataFrame for better display\n",
    "            df_results = pd.DataFrame(all_signals)\n",
    "            \n",
    "            # Group by exchange\n",
    "            for exchange in exchanges:\n",
    "                exchange_signals = [s for s in all_signals if s['exchange'] == exchange]\n",
    "                print(f\"\\n📈 {exchange}: {len(exchange_signals)} signals\")\n",
    "            \n",
    "            # Sort by volume for display\n",
    "            df_results = df_results.sort_values('volume_usd', ascending=False)\n",
    "            \n",
    "            # Display key columns based on strategy\n",
    "            if strategy == 'consolidation_breakout':\n",
    "                display_cols = ['symbol', 'exchange', 'direction', 'close', 'volume_usd', \n",
    "                               'volume_ratio', 'box_age', 'bars_inside', 'height_pct']\n",
    "            elif strategy == 'confluence':\n",
    "                display_cols = ['symbol', 'exchange', 'close', 'volume_usd', 'volume_ratio', \n",
    "                               'momentum_score', 'high_volume', 'spread_breakout', 'momentum_breakout']\n",
    "            elif strategy == 'hbs_breakout':\n",
    "                display_cols = ['symbol', 'exchange', 'direction', 'close', 'volume_usd', \n",
    "                               'volume_ratio', 'box_age', 'cf_detected_prev', 'cf_detected_curr']\n",
    "            \n",
    "            # Filter available columns\n",
    "            available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "            \n",
    "            print(f\"\\n📋 DETAILED RESULTS:\")\n",
    "            print(\"-\" * 120)\n",
    "            print(df_results[available_cols].to_string(index=False))\n",
    "            \n",
    "            # Show some statistics\n",
    "            if 'direction' in df_results.columns:\n",
    "                direction_counts = df_results['direction'].value_counts()\n",
    "                print(f\"\\n📊 Direction Breakdown:\")\n",
    "                for direction, count in direction_counts.items():\n",
    "                    print(f\"  {direction}: {count} signals\")\n",
    "            \n",
    "            print(f\"\\n💰 Volume Statistics:\")\n",
    "            print(f\"  Average Volume: ${df_results['volume_usd'].mean():,.0f}\")\n",
    "            print(f\"  Max Volume: ${df_results['volume_usd'].max():,.0f}\")\n",
    "            print(f\"  Min Volume: ${df_results['volume_usd'].min():,.0f}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n❌ No {strategy_name} signals found\")\n",
    "            print(\"💡 Try:\")\n",
    "            print(\"   • Lowering volume threshold\")\n",
    "            print(\"   • Increasing max_pairs\")\n",
    "            print(\"   • Different strategy\")\n",
    "        \n",
    "        return all_signals\n",
    "\n",
    "# Create scanner instance\n",
    "scanner = SFWeeklyStrategyScanner()\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "async def scan_consolidation_breakout(volume_threshold=300000, max_pairs=None):\n",
    "    \"\"\"Scan for consolidation breakout signals\"\"\"\n",
    "    return await scanner.run_parallel_scan(\n",
    "        strategy='consolidation_breakout',\n",
    "        volume_threshold=volume_threshold,\n",
    "        max_pairs=max_pairs\n",
    "    )\n",
    "\n",
    "async def scan_confluence(volume_threshold=300000, max_pairs=None):\n",
    "    \"\"\"Scan for confluence signals\"\"\"\n",
    "    return await scanner.run_parallel_scan(\n",
    "        strategy='confluence',\n",
    "        volume_threshold=volume_threshold,\n",
    "        max_pairs=max_pairs\n",
    "    )\n",
    "\n",
    "async def scan_hbs_breakout(volume_threshold=300000, max_pairs=None):\n",
    "    \"\"\"Scan for HBS (hybrid) breakout signals\"\"\"\n",
    "    return await scanner.run_parallel_scan(\n",
    "        strategy='hbs_breakout',\n",
    "        volume_threshold=volume_threshold,\n",
    "        max_pairs=max_pairs\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# EASY-TO-USE INTERFACE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🎯 SF WEEKLY STRATEGY SCANNER FOR KUCOIN & MEXC\")\n",
    "print(\"=\"*60)\n",
    "print(\"Available strategies:\")\n",
    "print(\"1. await scan_consolidation_breakout()  # Consolidation breakout detection\")\n",
    "print(\"2. await scan_confluence()              # Multi-factor confluence signals\")  \n",
    "print(\"3. await scan_hbs_breakout()            # Hybrid breakout (consolidation + confluence)\")\n",
    "print()\n",
    "print(\"Optional parameters:\")\n",
    "print(\"• volume_threshold: Minimum USD volume (default: 300,000)\")\n",
    "print(\"• max_pairs: Max pairs per exchange (default: None = ALL pairs)\")\n",
    "print()\n",
    "print(\"Examples:\")\n",
    "print(\"• await scan_consolidation_breakout()                    # Scan ALL pairs\")\n",
    "print(\"• await scan_hbs_breakout(volume_threshold=500000)       # Higher volume threshold\")\n",
    "print(\"• await scan_confluence(max_pairs=100)                   # Limit to 100 pairs per exchange\")\n",
    "print(\"• await scan_hbs_breakout(volume_threshold=200000)       # Lower volume threshold\")\n",
    "\n",
    "# Uncomment one of these to auto-run:\n",
    "# await scan_consolidation_breakout()\n",
    "# await scan_confluence() \n",
    "await scan_hbs_breakout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caac56a-df34-4974-8cd6-8fb33f8d477a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Binance BTC dominated pairs - Confluence Scanner with Direct API\n",
    "\n",
    "from telegram.ext import Application\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import sys\n",
    "import os\n",
    "import html\n",
    "import aiohttp\n",
    "import time\n",
    "\n",
    "# Add project path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from custom_strategies import detect_confluence\n",
    "\n",
    "class BinanceBTCConfluenceScanner:\n",
    "    def __init__(self, telegram_token, telegram_chat_id, timeframe, offset=1):\n",
    "        self.telegram_token = telegram_token\n",
    "        self.telegram_chat_id = telegram_chat_id\n",
    "        self.telegram_app = None\n",
    "        self.exchange = \"Binance\"\n",
    "        self.timeframe = timeframe\n",
    "        self.quote_currency = \"BTC\"\n",
    "        self.offset = offset\n",
    "        self.base_url = \"https://api.binance.com\"\n",
    "        self.session = None\n",
    "        \n",
    "        # Binance timeframe mapping - All available intervals\n",
    "        self.timeframe_map = {\n",
    "            # Minutes\n",
    "            \"1m\": \"1m\",\n",
    "            \"3m\": \"3m\", \n",
    "            \"5m\": \"5m\",\n",
    "            \"15m\": \"15m\",\n",
    "            \"30m\": \"30m\",\n",
    "            # Hours\n",
    "            \"1h\": \"1h\",\n",
    "            \"2h\": \"2h\",\n",
    "            \"4h\": \"4h\",\n",
    "            \"6h\": \"6h\",\n",
    "            \"8h\": \"8h\",\n",
    "            \"12h\": \"12h\",\n",
    "            # Days\n",
    "            \"1d\": \"1d\",\n",
    "            \"2d\": \"2d\",\n",
    "            \"3d\": \"3d\",\n",
    "            # Weeks/Months\n",
    "            \"1w\": \"1w\",\n",
    "            \"1M\": \"1M\"\n",
    "        }\n",
    "        \n",
    "    async def init_session(self):\n",
    "        \"\"\"Initialize aiohttp session\"\"\"\n",
    "        if self.session is None:\n",
    "            self.session = aiohttp.ClientSession()\n",
    "            \n",
    "    async def close_session(self):\n",
    "        \"\"\"Close aiohttp session\"\"\"\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "            self.session = None\n",
    "        \n",
    "    async def init_telegram(self):\n",
    "        if self.telegram_app is None:\n",
    "            self.telegram_app = Application.builder().token(self.telegram_token).build()\n",
    "\n",
    "    async def get_btc_pairs(self):\n",
    "        \"\"\"Get all BTC trading pairs from Binance\"\"\"\n",
    "        await self.init_session()\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.base_url}/api/v3/exchangeInfo\"\n",
    "            async with self.session.get(url) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    \n",
    "                    # Filter for BTC pairs that are actively trading\n",
    "                    btc_pairs = []\n",
    "                    for symbol_info in data['symbols']:\n",
    "                        if (symbol_info['quoteAsset'] == 'BTC' and \n",
    "                            symbol_info['status'] == 'TRADING' and\n",
    "                            symbol_info['isSpotTradingAllowed']):\n",
    "                            \n",
    "                            btc_pairs.append({\n",
    "                                'symbol': symbol_info['symbol'],\n",
    "                                'baseAsset': symbol_info['baseAsset'],\n",
    "                                'quoteAsset': symbol_info['quoteAsset']\n",
    "                            })\n",
    "                    \n",
    "                    return btc_pairs\n",
    "                else:\n",
    "                    logging.error(f\"Error fetching exchange info: {response.status}\")\n",
    "                    return []\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching BTC pairs: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    async def get_klines(self, symbol, interval, limit=100):\n",
    "        \"\"\"Get kline/candlestick data from Binance\"\"\"\n",
    "        await self.init_session()\n",
    "        \n",
    "        try:\n",
    "            url = f\"{self.base_url}/api/v3/klines\"\n",
    "            params = {\n",
    "                'symbol': symbol,\n",
    "                'interval': interval,\n",
    "                'limit': limit\n",
    "            }\n",
    "            \n",
    "            async with self.session.get(url, params=params) as response:\n",
    "                if response.status == 200:\n",
    "                    data = await response.json()\n",
    "                    \n",
    "                    # Convert to DataFrame\n",
    "                    df = pd.DataFrame(data, columns=[\n",
    "                        'open_time', 'open', 'high', 'low', 'close', 'volume',\n",
    "                        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "                        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "                    ])\n",
    "                    \n",
    "                    # Convert timestamps to datetime\n",
    "                    df['open_time'] = pd.to_datetime(df['open_time'], unit='ms')\n",
    "                    df['close_time'] = pd.to_datetime(df['close_time'], unit='ms')\n",
    "                    \n",
    "                    # Convert OHLCV to numeric\n",
    "                    for col in ['open', 'high', 'low', 'close', 'volume', 'quote_asset_volume']:\n",
    "                        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                    \n",
    "                    # Set datetime index\n",
    "                    df.set_index('open_time', inplace=True)\n",
    "                    \n",
    "                    # Select only OHLCV columns needed for confluence\n",
    "                    # Note: Using quote_asset_volume as it's the volume in BTC\n",
    "                    result_df = df[['open', 'high', 'low', 'close', 'quote_asset_volume']].copy()\n",
    "                    result_df.rename(columns={'quote_asset_volume': 'volume'}, inplace=True)\n",
    "                    \n",
    "                    return result_df\n",
    "                    \n",
    "                elif response.status == 429:\n",
    "                    # Rate limit hit, wait a bit\n",
    "                    await asyncio.sleep(1)\n",
    "                    return None\n",
    "                else:\n",
    "                    return None\n",
    "                    \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching klines for {symbol}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    async def send_telegram_alert(self, results):\n",
    "        if not results:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            message = f\"🚨 Confluence Detection - Binance BTC Pairs {self.timeframe}\\n\\n\"\n",
    "            \n",
    "            # Map timeframe to TradingView format - Extended mapping\n",
    "            tv_timeframe_map = {\n",
    "                # Minutes\n",
    "                \"1m\": \"1\", \"3m\": \"3\", \"5m\": \"5\", \"15m\": \"15\", \"30m\": \"30\",\n",
    "                # Hours  \n",
    "                \"1h\": \"60\", \"2h\": \"120\", \"4h\": \"240\", \"6h\": \"360\", \"8h\": \"480\", \"12h\": \"720\",\n",
    "                # Days\n",
    "                \"1d\": \"1D\", \"2d\": \"2D\", \"3d\": \"3D\",\n",
    "                # Weeks/Months\n",
    "                \"1w\": \"1W\", \"1M\": \"1M\"\n",
    "            }\n",
    "            tv_timeframe = tv_timeframe_map.get(self.timeframe.lower(), self.timeframe)\n",
    "            \n",
    "            for result in results:\n",
    "                formatted_symbol = result['symbol']\n",
    "                tv_link = f\"https://www.tradingview.com/chart/?symbol=BINANCE:{formatted_symbol}&interval={tv_timeframe}\"\n",
    "                \n",
    "                # Escape HTML entities in the URL\n",
    "                escaped_link = html.escape(tv_link)\n",
    "                \n",
    "                # Format according to BTC specifications\n",
    "                time_str = \"\"\n",
    "                if result.get('timestamp') is not None:\n",
    "                    time_str = f\"Time: {result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "                \n",
    "                message += (\n",
    "                    f\"Symbol: {result['symbol']}\\n\"\n",
    "                    f\"{time_str}\"\n",
    "                    f\"Volume BTC: ₿{result['volume_btc']:,.4f}\\n\"\n",
    "                    f\"Close: <a href='{escaped_link}'>₿{result['close']:.8f}</a>\\n\"\n",
    "                    f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                    f\"Close Off Low: {result['close_off_low']:.1f}%\\n\"\n",
    "                    f\"Momentum: {result['momentum_score']:.4f}\\n\"\n",
    "                    f\"{'='*30}\\n\"\n",
    "                )\n",
    "            \n",
    "            # Split message more carefully to avoid breaking HTML tags\n",
    "            max_length = 4000\n",
    "            \n",
    "            if len(message) > max_length:\n",
    "                # Split at natural breaks (between results) to avoid breaking HTML\n",
    "                sections = message.split('='*30 + '\\n')\n",
    "                current_chunk = \"\"\n",
    "                \n",
    "                for section in sections:\n",
    "                    if len(current_chunk + section + '='*30 + '\\n') > max_length:\n",
    "                        if current_chunk:\n",
    "                            await self.telegram_app.bot.send_message(\n",
    "                                chat_id=self.telegram_chat_id,\n",
    "                                text=current_chunk.strip(),\n",
    "                                parse_mode='HTML',\n",
    "                                disable_web_page_preview=True\n",
    "                            )\n",
    "                        current_chunk = section + '\\n'\n",
    "                    else:\n",
    "                        current_chunk += section + '='*30 + '\\n'\n",
    "                \n",
    "                # Send remaining chunk\n",
    "                if current_chunk.strip():\n",
    "                    await self.telegram_app.bot.send_message(\n",
    "                        chat_id=self.telegram_chat_id,\n",
    "                        text=current_chunk.strip(),\n",
    "                        parse_mode='HTML',\n",
    "                        disable_web_page_preview=True\n",
    "                    )\n",
    "            else:\n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=message,\n",
    "                    parse_mode='HTML',\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending Telegram alert: {str(e)}\")\n",
    "            \n",
    "            # Fallback: send without HTML formatting\n",
    "            try:\n",
    "                simple_message = f\"🚨 Confluence Detection - Binance BTC Pairs {self.timeframe}\\n\\n\"\n",
    "                for result in results:\n",
    "                    simple_message += (\n",
    "                        f\"Symbol: {result['symbol']}\\n\"\n",
    "                        f\"Volume BTC: ₿{result['volume_btc']:,.4f}\\n\"\n",
    "                        f\"Close: ₿{result['close']:.8f}\\n\"\n",
    "                        f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                        f\"Components: Vol={result['high_volume']}, Spread={result['spread_breakout']}, Mom={result['momentum_breakout']}\\n\\n\"\n",
    "                    )\n",
    "                \n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=simple_message,\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "            except Exception as fallback_error:\n",
    "                logging.error(f\"Fallback Telegram send also failed: {str(fallback_error)}\")\n",
    "\n",
    "    def scan_single_market(self, pair, df):\n",
    "        \"\"\"Scan a single market for Confluence pattern in the specified bar\"\"\"\n",
    "        try:\n",
    "            if df is None or len(df) < 50:  # Need enough data for confluence\n",
    "                return None\n",
    "            \n",
    "            # Calculate which bar to check based on offset\n",
    "            check_bar = -(self.offset + 1)  # offset=0 means current bar (-1), offset=1 means last closed (-2), etc.\n",
    "            \n",
    "            # Run confluence detection\n",
    "            detected, result = detect_confluence(df, check_bar=check_bar)\n",
    "            \n",
    "            if detected:\n",
    "                # Get the target bar values\n",
    "                target_close = df['close'].iloc[check_bar]\n",
    "                target_volume = df['volume'].iloc[check_bar]  # This is already in BTC\n",
    "                \n",
    "                confluence_result = {\n",
    "                    'symbol': pair['symbol'],\n",
    "                    'volume_btc': float(target_volume),\n",
    "                    'close': float(target_close),\n",
    "                    'volume': float(target_volume),\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                    'bar_range': result['bar_range'],\n",
    "                    'timestamp': df.index[check_bar] if hasattr(df.index, '__getitem__') else None\n",
    "                }\n",
    "                return confluence_result\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {pair['symbol']}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def scan_all_markets(self):\n",
    "        \"\"\"Scan all BTC markets for Confluence pattern\"\"\"\n",
    "        await self.init_telegram()\n",
    "        \n",
    "        try:\n",
    "            # Define volume thresholds for BTC pairs based on timeframe\n",
    "            volume_thresholds = {\n",
    "                # Minutes - higher volume needed for shorter timeframes\n",
    "                \"1m\": 0.01,   \"3m\": 0.02,   \"5m\": 0.03,\n",
    "                \"15m\": 0.05,  \"30m\": 0.08,\n",
    "                # Hours\n",
    "                \"1h\": 0.1,    \"2h\": 0.15,   \"4h\": 0.2,\n",
    "                \"6h\": 0.25,   \"8h\": 0.3,    \"12h\": 0.35,\n",
    "                # Days\n",
    "                \"1d\": 0.4,    \"2d\": 0.8,    \"3d\": 1.2,\n",
    "                # Weeks/Months\n",
    "                \"1w\": 2.0,    \"1M\": 8.0\n",
    "            }\n",
    "            min_volume = volume_thresholds.get(self.timeframe.lower(), 0.1)  # Default 0.1 BTC\n",
    "            \n",
    "            # Create offset description\n",
    "            if self.offset == 0:\n",
    "                offset_desc = \"current candle\"\n",
    "            elif self.offset == 1:\n",
    "                offset_desc = \"last closed candle\"\n",
    "            else:\n",
    "                offset_desc = f\"{self.offset} candles ago\"\n",
    "            \n",
    "            print(f\"Scanning Binance BTC pairs for Confluence patterns in {offset_desc}...\")\n",
    "            print(f\"Timeframe: {self.timeframe}\")\n",
    "            print(f\"Minimum volume threshold: ₿{min_volume:.2f}\")\n",
    "            \n",
    "            # Get all BTC pairs from Binance\n",
    "            print(\"Fetching BTC pairs from Binance...\")\n",
    "            btc_pairs = await self.get_btc_pairs()\n",
    "            \n",
    "            if not btc_pairs:\n",
    "                print(\"No BTC pairs found or error fetching pairs\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"Found {len(btc_pairs)} BTC pairs to scan\")\n",
    "            \n",
    "            # Filter out stablecoins and obvious non-trading pairs\n",
    "            filtered_pairs = []\n",
    "            skip_tokens = ['USDT', 'USDC', 'BUSD', 'DAI', 'TUSD', 'USDD', 'FDUSD']\n",
    "            \n",
    "            for pair in btc_pairs:\n",
    "                if pair['baseAsset'] not in skip_tokens:\n",
    "                    filtered_pairs.append(pair)\n",
    "            \n",
    "            print(f\"After filtering: {len(filtered_pairs)} pairs to scan\")\n",
    "            \n",
    "            # Get Binance timeframe - fallback to 1d if not found\n",
    "            binance_interval = self.timeframe_map.get(self.timeframe.lower(), \"1d\")\n",
    "            \n",
    "            # Process all pairs with progress bar\n",
    "            all_results = []\n",
    "            successful_scans = 0\n",
    "            \n",
    "            with tqdm(total=len(filtered_pairs), desc=\"Scanning markets\") as pbar:\n",
    "                for pair in filtered_pairs:\n",
    "                    try:\n",
    "                        # Get OHLCV data from Binance\n",
    "                        df = await self.get_klines(pair['symbol'], binance_interval, 100)\n",
    "                        \n",
    "                        if df is None or len(df) < 50:\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        successful_scans += 1\n",
    "                        target_idx = -(self.offset + 1)\n",
    "                        \n",
    "                        # Update progress bar with current symbol\n",
    "                        pbar.set_description(f\"Scanning: {pair['symbol']} ({len(df)} candles)\")\n",
    "                        \n",
    "                        # Check volume threshold for the target candle\n",
    "                        try:\n",
    "                            target_candle_volume = float(df['volume'].iloc[target_idx])  # Already in BTC\n",
    "                            \n",
    "                            # Only process if volume meets threshold\n",
    "                            if target_candle_volume >= min_volume:\n",
    "                                result = self.scan_single_market(pair, df)\n",
    "                                if result:\n",
    "                                    all_results.append(result)\n",
    "                                    print(f\"Found Confluence: {pair['symbol']} 🎯\")\n",
    "                        except (IndexError, ValueError):\n",
    "                            pass  # Skip if we can't calculate volume\n",
    "                        \n",
    "                        # Add small delay to respect rate limits\n",
    "                        await asyncio.sleep(0.1)\n",
    "                                \n",
    "                    except Exception as e:\n",
    "                        if \"429\" in str(e):\n",
    "                            # Rate limit - add longer delay\n",
    "                            await asyncio.sleep(2)\n",
    "                    finally:\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            print(f\"Successfully scanned {successful_scans}/{len(filtered_pairs)} pairs\")\n",
    "            \n",
    "            # Sort by volume\n",
    "            all_results.sort(key=lambda x: x['volume_btc'], reverse=True)\n",
    "            \n",
    "            # Send Telegram alert if we found any patterns\n",
    "            if all_results:\n",
    "                await self.send_telegram_alert(all_results)\n",
    "            \n",
    "            return all_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scanning markets: {str(e)}\")\n",
    "            return []\n",
    "        finally:\n",
    "            await self.close_session()\n",
    "\n",
    "async def run_binance_btc_confluence_scanner(timeframe, offset=1):\n",
    "    \"\"\"\n",
    "    Run the Binance BTC Confluence scanner\n",
    "    \n",
    "    Parameters:\n",
    "    timeframe (str): Time period - Available options:\n",
    "                    Minutes: 1m, 3m, 5m, 15m, 30m\n",
    "                    Hours: 1h, 2h, 4h, 6h, 8h, 12h  \n",
    "                    Days: 1d, 2d, 3d\n",
    "                    Weeks/Months: 1w, 1M\n",
    "    offset (int): Bar offset (0=current, 1=last closed, 2=two bars ago, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if offset == 0:\n",
    "        offset_desc = \"current candle\"\n",
    "    elif offset == 1:\n",
    "        offset_desc = \"last closed candle\"\n",
    "    else:\n",
    "        offset_desc = f\"{offset} candles ago\"\n",
    "    \n",
    "    print(f\"Starting Binance BTC Confluence scan for {offset_desc} on {timeframe}...\")\n",
    "    \n",
    "    # Use the confluence telegram token\n",
    "    telegram_token = \"8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g\"\n",
    "    telegram_chat_id = \"375812423\"\n",
    "    \n",
    "    scanner = BinanceBTCConfluenceScanner(telegram_token, telegram_chat_id, timeframe, offset)\n",
    "    results = await scanner.scan_all_markets()\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nFound {len(results)} Confluence patterns:\")\n",
    "        \n",
    "        # Convert results to DataFrame for console display\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # Round numeric columns for BTC precision\n",
    "        df_results['volume_btc'] = df_results['volume_btc'].round(4)\n",
    "        df_results['close'] = df_results['close'].round(8)\n",
    "        df_results['volume'] = df_results['volume'].round(4)\n",
    "        df_results['volume_ratio'] = df_results['volume_ratio'].round(2)\n",
    "        df_results['close_off_low'] = df_results['close_off_low'].round(1)\n",
    "        df_results['momentum_score'] = df_results['momentum_score'].round(4)\n",
    "        \n",
    "        # Reorder columns for better display\n",
    "        display_cols = ['symbol', 'close', 'volume_btc', 'volume_ratio', 'close_off_low', \n",
    "                       'momentum_score', 'high_volume', 'spread_breakout', 'momentum_breakout']\n",
    "        available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "        \n",
    "        # Display the results\n",
    "        print(df_results[available_cols])\n",
    "        \n",
    "        # Show component analysis\n",
    "        print(f\"\\n🔧 COMPONENT ANALYSIS:\")\n",
    "        vol_count = df_results['high_volume'].sum()\n",
    "        spread_count = df_results['spread_breakout'].sum()\n",
    "        momentum_count = df_results['momentum_breakout'].sum()\n",
    "        \n",
    "        print(f\"High Volume signals: {vol_count}/{len(results)} ({vol_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Spread Breakout signals: {spread_count}/{len(results)} ({spread_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Momentum Breakout signals: {momentum_count}/{len(results)} ({momentum_count/len(results)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nNo Confluence patterns found in {offset_desc}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Apply nest_asyncio to allow async operations in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Example usage functions\n",
    "async def scan_binance_btc_current():\n",
    "    \"\"\"Scan current candle for confluence - Binance BTC pairs\"\"\"\n",
    "    await run_binance_btc_confluence_scanner(\"1w\", offset=0)\n",
    "\n",
    "async def scan_binance_btc_closed():\n",
    "    \"\"\"Scan last closed candle for confluence - Binance BTC pairs\"\"\"\n",
    "    await run_binance_btc_confluence_scanner(\"1w\", offset=1)\n",
    "\n",
    "async def scan_binance_btc_previous():\n",
    "    \"\"\"Scan two candles ago for confluence - Binance BTC pairs\"\"\"\n",
    "    await run_binance_btc_confluence_scanner(\"1w\", offset=2)\n",
    "\n",
    "# Main execution function\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main execution - modify parameters here\n",
    "    \"\"\"\n",
    "    timeframe = \"1w\"  # 1d, 2d, 3d, 1w\n",
    "    offset = 0        # 0 = current candle, 1 = last closed candle, 2 = two candles ago\n",
    "    \n",
    "    await run_binance_btc_confluence_scanner(timeframe, offset)\n",
    "\n",
    "# Run the async main function\n",
    "print(\"🔍 BINANCE BTC CONFLUENCE SCANNER\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Available timeframes:\")\n",
    "print(\"• Minutes: 1m, 3m, 5m, 15m, 30m\")\n",
    "print(\"• Hours: 1h, 2h, 4h, 6h, 8h, 12h\") \n",
    "print(\"• Days: 1d, 2d, 3d\")\n",
    "print(\"• Weeks/Months: 1w, 1M\")\n",
    "print(\"\\nAvailable functions:\")\n",
    "print(\"• await main() - Run with default settings\")\n",
    "print(\"• await scan_binance_btc_current() - Scan current candle\")\n",
    "print(\"• await scan_binance_btc_closed() - Scan last closed candle\")\n",
    "print(\"• await scan_binance_btc_previous() - Scan two candles ago\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('timeframe', offset) - Custom scan\")\n",
    "print(\"\\nExamples:\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('4h', 1)  # 4-hour last closed\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('15m', 0) # 15-min current\")\n",
    "print(\"• await run_binance_btc_confluence_scanner('1M', 1)  # Monthly last closed\")\n",
    "print(\"This scanner uses REAL Binance BTC pair volumes!\")\n",
    "\n",
    "# Uncomment to auto-run:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8804bead-b40b-4676-9951-8d4e30e29ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug ohlcv data of any pair\n",
    "\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "from exchanges import BybitFuturesClient  # Ensure this matches your exchanges/__init__.py\n",
    "\n",
    "async def test_fetch():\n",
    "    client = BybitFuturesClient(timeframe=\"2d\")\n",
    "    await client.init_session()\n",
    "    df = await client.fetch_klines(\"L3USDT\")\n",
    "    await client.close_session()\n",
    "    if df is not None:\n",
    "        print(\"2d Candles for L3:\")\n",
    "        print(df.tail(5))  # Last 5 weeks\n",
    "        last_row = df.iloc[-1]\n",
    "        volume_usd = last_row['volume'] * last_row['close']\n",
    "        print(f\"Last Week: volume_usd={volume_usd:.2f}, close={last_row['close']}, volume={last_row['volume']:.2f}\")\n",
    "\n",
    "# Run the async function directly in the notebook\n",
    "await test_fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b52f4-ca65-425b-a41a-42b70a57aefa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Direct strategy debug of any pair on any exchange\n",
    "import asyncio\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "from exchanges import MexcSpotClient, BybitSpotClient, GateioSpotClient, KucoinSpotClient, BinanceSpotClient, BinanceFuturesClient, BybitFuturesClient\n",
    "from custom_strategies import detect_volume_surge, detect_weak_uptrend, detect_pin_down\n",
    "from breakout_vsa import vsa_detector, breakout_bar_vsa, stop_bar_vsa, reversal_bar_vsa, start_bar_vsa, loaded_bar_vsa, test_bar_vsa\n",
    "\n",
    "async def test_strategy(exchange_client_class, timeframe, symbol, strategy_name):\n",
    "    client = exchange_client_class(timeframe=timeframe)\n",
    "    await client.init_session()\n",
    "    df = await client.fetch_klines(symbol)\n",
    "    await client.close_session()\n",
    "    \n",
    "    if df is None or len(df) < 10:\n",
    "        print(f\"No data fetched for {symbol} or insufficient data (< 10 bars)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"{timeframe} Candles for {symbol}:\")\n",
    "    print(df.tail(5))\n",
    "    last_row = df.iloc[-1]\n",
    "    volume_usd = last_row['volume'] * last_row['close']\n",
    "    print(f\"Last Bar: volume_usd={volume_usd:.2f}, close={last_row['close']}, volume={last_row['volume']:.2f}\")\n",
    "    \n",
    "    # Different handling based on strategy type\n",
    "    if strategy_name == \"volume_surge\":\n",
    "        # Use detect_volume_surge directly\n",
    "        detected, result = detect_volume_surge(df)\n",
    "        \n",
    "        print(f\"\\nVolume Surge Detection Results:\")\n",
    "        print(f\"Detected: {detected}\")\n",
    "        \n",
    "        if detected:\n",
    "            print(f\"\\nVolume Surge Details:\")\n",
    "            print(f\"  Date: {result['timestamp']}\")\n",
    "            print(f\"  Close: ${result['close_price']:,.8f}\")\n",
    "            print(f\"  Volume: {result['volume']:,.2f}\")\n",
    "            print(f\"  Volume USD: ${result['volume_usd']:,.2f}\")\n",
    "            print(f\"  Volume Ratio: {result['volume_ratio']:,.2f}x\")\n",
    "            print(f\"  Score: {result['score']:,.2f}\")\n",
    "            print(f\"  Price Extreme: {result['price_extreme']}\")\n",
    "    \n",
    "    elif strategy_name == \"pin_down\":\n",
    "        from custom_strategies import detect_pin_down\n",
    "        detected, result = detect_pin_down(df)\n",
    "        \n",
    "        print(f\"\\nPin Down Detection Results:\")\n",
    "        print(f\"Detected: {detected}\")\n",
    "        \n",
    "        if detected:\n",
    "            print(f\"\\nPin Down Details:\")\n",
    "            for key, value in result.items():\n",
    "                if key != 'symbol':  # Skip symbol as we already know it\n",
    "                    print(f\"  {key}: {value}\")\n",
    "    \n",
    "    elif strategy_name == \"weak_uptrend\":\n",
    "        from custom_strategies import detect_weak_uptrend\n",
    "        detected, result = detect_weak_uptrend(df)\n",
    "        \n",
    "        print(f\"\\nWeak Uptrend Detection Results:\")\n",
    "        print(f\"Detected: {detected}\")\n",
    "        \n",
    "        if detected:\n",
    "            print(f\"\\nWeak Uptrend Details:\")\n",
    "            for key, value in result.items():\n",
    "                if key != 'symbol':  # Skip symbol as we already know it\n",
    "                    print(f\"  {key}: {value}\")\n",
    "    \n",
    "    else:\n",
    "        # For VSA strategies, import the appropriate get_params\n",
    "        if strategy_name == \"reversal_bar\":\n",
    "            from breakout_vsa.strategies.reversal_bar import get_params\n",
    "        elif strategy_name == \"breakout_bar\":\n",
    "            from breakout_vsa.strategies.breakout_bar import get_params\n",
    "        elif strategy_name == \"loaded_bar\":\n",
    "            from breakout_vsa.strategies.loaded_bar import get_params\n",
    "        elif strategy_name == \"stop_bar\":\n",
    "            from breakout_vsa.strategies.stop_bar import get_params\n",
    "        elif strategy_name == \"start_bar\":\n",
    "            from breakout_vsa.strategies.start_bar import get_params\n",
    "        else:\n",
    "            print(f\"Unknown strategy: {strategy_name}\")\n",
    "            return\n",
    "        \n",
    "        # Use vsa_detector with strategy-specific params\n",
    "        params = get_params()\n",
    "        condition, result = vsa_detector(df, params)\n",
    "        \n",
    "        strategy_display_name = strategy_name.replace('_vsa', '').replace('_', ' ').title()\n",
    "        print(f\"\\n{strategy_display_name} Detection Results:\")\n",
    "        print(f\"Current Bar (index -1): {condition.iloc[-1]}\")\n",
    "        if len(df) > 1:\n",
    "            print(f\"Last Closed Bar (index -2): {condition.iloc[-2]}\")\n",
    "        \n",
    "        if condition.iloc[-1] or (len(df) > 1 and condition.iloc[-2]):\n",
    "            detected_idx = -1 if condition.iloc[-1] else -2\n",
    "            volume_mean = df['volume'].rolling(7).mean().iloc[detected_idx]\n",
    "            bar_range = df['high'].iloc[detected_idx] - df['low'].iloc[detected_idx]\n",
    "            close_off_low = (df['close'].iloc[detected_idx] - df['low'].iloc[detected_idx]) / bar_range * 100 if bar_range > 0 else 0\n",
    "            volume_usd_detected = df['volume'].iloc[detected_idx] * df['close'].iloc[detected_idx]\n",
    "            \n",
    "            arctan_ratio = result['arctan_ratio'].iloc[detected_idx]  # From result DataFrame\n",
    "            \n",
    "            print(f\"\\nDetected at index {detected_idx} ({'Current' if detected_idx == -1 else 'Last Closed'} Bar):\")\n",
    "            print(f\"  Date: {df.index[detected_idx]}\")\n",
    "            print(f\"  Close: ${df['close'].iloc[detected_idx]:,.8f}\")\n",
    "            print(f\"  Volume Ratio: {df['volume'].iloc[detected_idx] / volume_mean if volume_mean > 0 else 0:.2f}x\")\n",
    "            print(f\"  {timeframe} Volume: ${volume_usd_detected:.2f}\")\n",
    "            print(f\"  Close Off Low: {close_off_low:.1f}%\")\n",
    "            print(f\"  Angular Ratio: {arctan_ratio:.2f}\")\n",
    "\n",
    "# Define the test case\n",
    "exchange_client = GateioSpotClient\n",
    "timeframe = \"1w\"\n",
    "symbol = \"PRCL_USDT\"\n",
    "strategy = \"loaded_bar\"\n",
    "await test_strategy(exchange_client, timeframe, symbol, strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9bf3d-5437-413f-a6a8-2496412059e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#zip the project\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Go to parent directory of your project\n",
    "os.chdir(\"/home/jovyan/work/Crypto/sevenfigures-bot/hbs_2025\")\n",
    "\n",
    "# Create the zip file (this will include everything inside 'hbs_2025')\n",
    "shutil.make_archive(\"Project_VSA_2025_backup\", 'zip', \"Project\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76c74d8-f489-49e8-8596-c36b3960fbe6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3 -> Debug built weekly candles for mexc and kucoin \n",
    "import sys\n",
    "import os\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "import asyncio\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from exchanges.kucoin_client import KucoinClient\n",
    "from breakout_vsa.core import calculate_start_bar\n",
    "\n",
    "from scanner.main import kline_cache\n",
    "kline_cache.clear()  # Clear cache for fresh data\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "async def debug_start_bar_detection():\n",
    "    # Initialize client\n",
    "    client = KucoinClient(timeframe=\"1w\")\n",
    "    await client.init_session()\n",
    "    \n",
    "    # Symbol to debug\n",
    "    symbol = \"TAO-USDT\"\n",
    "    \n",
    "    try:\n",
    "        # Fetch data\n",
    "        df = await client.fetch_klines(symbol)\n",
    "        \n",
    "        if df is not None:\n",
    "            print(f\"Weekly candles for {symbol}:\")\n",
    "            print(df.tail())\n",
    "            \n",
    "            # Add intermediate calculations to see what's happening\n",
    "            # This is a modified version of calculate_start_bar that adds debugging\n",
    "            lookback = 5\n",
    "            volume_lookback = 30\n",
    "            volume_percentile = 50\n",
    "            low_percentile = 75\n",
    "            range_percentile = 75\n",
    "            close_off_lows_percent = 50\n",
    "            prev_close_range = 75\n",
    "            \n",
    "            # Calculate basic bar characteristics\n",
    "            df['bar_range'] = df['high'] - df['low']\n",
    "            df['volume_rank'] = df['volume'].rolling(lookback).apply(\n",
    "                lambda x: sum(1.0 for val in x if val <= x[-1]) / len(x) * 100, \n",
    "                raw=True\n",
    "            )\n",
    "            \n",
    "            # Calculate rolling values\n",
    "            df['macro_low'] = df['low'].rolling(volume_lookback).min()\n",
    "            df['macro_high'] = df['high'].rolling(volume_lookback).max()\n",
    "            df['highest_high'] = df['high'].rolling(lookback).max()\n",
    "            \n",
    "            # Volume conditions\n",
    "            df['volume_sma'] = df['volume'].rolling(volume_lookback).mean()\n",
    "            df['volume_std'] = df['volume'].rolling(volume_lookback).std()\n",
    "            df['excess_volume'] = df['volume'] > (df['volume_sma'] + 3.0 * df['volume_std'])\n",
    "            \n",
    "            # Range conditions\n",
    "            df['range_sma'] = df['bar_range'].rolling(volume_lookback).mean()\n",
    "            df['range_std'] = df['bar_range'].rolling(volume_lookback).std()\n",
    "            df['excess_range'] = df['bar_range'] > (df['range_sma'] + 3.0 * df['range_std'])\n",
    "            \n",
    "            # Volume percentile condition\n",
    "            def is_in_top_percent(series, length, percent):\n",
    "                ranks = series.rolling(length).apply(\n",
    "                    lambda x: sum(1.0 for val in x if val <= x[-1]) / len(x) * 100, \n",
    "                    raw=True\n",
    "                )\n",
    "                return ranks >= percent\n",
    "            \n",
    "            def is_in_bottom_percent(series, length, percent):\n",
    "                ranks = series.rolling(length).apply(\n",
    "                    lambda x: sum(1.0 for val in x if val <= x[-1]) / len(x) * 100, \n",
    "                    raw=True\n",
    "                )\n",
    "                return ranks <= percent\n",
    "            \n",
    "            # Volume conditions\n",
    "            df['is_higher_volume'] = is_in_top_percent(df['volume'], lookback, volume_percentile)\n",
    "            df['is_high_volume'] = (df['volume'] > 0.75 * df['volume_sma']) & (df['volume'] > df['volume'].shift(1))\n",
    "            \n",
    "            # Price action conditions\n",
    "            df['has_higher_high'] = df['high'] > df['high'].shift(1)\n",
    "            df['no_narrow_range'] = is_in_top_percent(df['bar_range'], lookback, range_percentile)\n",
    "            \n",
    "            # Low price condition\n",
    "            df['is_in_the_lows'] = (\n",
    "                (df['low'] - df['macro_low']).abs() < df['bar_range']\n",
    "            ) | is_in_bottom_percent(df['low'], volume_lookback, low_percentile)\n",
    "            \n",
    "            # Close position conditions\n",
    "            df['close_in_the_highs'] = (\n",
    "                (df['close'] - df['low']) / df['bar_range']\n",
    "            ) >= (close_off_lows_percent / 100)\n",
    "            \n",
    "            # Previous close distance condition\n",
    "            df['far_prev_close'] = (\n",
    "                (df['close'] - df['close'].shift(1)).abs() >=\n",
    "                (df['bar_range'].shift(1) * (prev_close_range / 100))\n",
    "            )\n",
    "            \n",
    "            # New highs condition\n",
    "            df['new_highs'] = df['high'] >= 0.75 * df['highest_high']\n",
    "            \n",
    "            # Optional strength condition\n",
    "            df['strong_close'] = df['close'] >= df['highest_high'].shift(1)\n",
    "            \n",
    "            # Now check the actual values for the last few bars\n",
    "            last_rows = df.tail(3)\n",
    "            \n",
    "            print(\"\\nAnalyzing last 3 bars:\")\n",
    "            for idx, row in last_rows.iterrows():\n",
    "                print(f\"\\nBar at {idx.strftime('%Y-%m-%d')}:\")\n",
    "                print(f\"  is_high_volume: {row['is_high_volume']}\")\n",
    "                print(f\"  has_higher_high: {row['has_higher_high']}\")\n",
    "                print(f\"  no_narrow_range: {row['no_narrow_range']}\")\n",
    "                print(f\"  close_in_the_highs: {row['close_in_the_highs']}\")\n",
    "                print(f\"  far_prev_close: {row['far_prev_close']}\")\n",
    "                print(f\"  excess_range: {row['excess_range']}\")\n",
    "                print(f\"  excess_volume: {row['excess_volume']}\")\n",
    "                print(f\"  new_highs: {row['new_highs']}\")\n",
    "                print(f\"  is_in_the_lows: {row['is_in_the_lows']}\")\n",
    "                print(f\"  volume: {row['volume']}, volume_sma: {row['volume_sma']}\")\n",
    "                print(f\"  bar_range: {row['bar_range']}, range_sma: {row['range_sma']}\")\n",
    "                \n",
    "            # Run the original function to confirm\n",
    "            start_bar_pattern = calculate_start_bar(df)\n",
    "            print(f\"\\nFinal Start Bar detection result:\")\n",
    "            print(start_bar_pattern.tail(3))\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in debug: {str(e)}\")\n",
    "    finally:\n",
    "        await client.close_session()\n",
    "\n",
    "# Replace the last part of your script with this:\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # For Jupyter/IPython environments\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        asyncio.run(debug_start_bar_detection())\n",
    "    except ImportError:\n",
    "        # For regular Python environments\n",
    "        asyncio.run(debug_start_bar_detection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dffeddd-c2c8-4f75-887f-9ed7d1961a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zip the project\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Go to parent directory of your project\n",
    "os.chdir(\"/home/jovyan/work/Crypto/sevenfigures-bot/hbs_2025\")\n",
    "\n",
    "# Create the zip file (this will include everything inside 'hbs_2025')\n",
    "shutil.make_archive(\"Project_VSA_2025_backup\", 'zip', \"Project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29951e-0a3b-4d0b-928c-0f2bfce7c11c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ARCHIVE - Confluence Scanner with bar offset\n",
    "\n",
    "from telegram.ext import Application\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import logging\n",
    "import nest_asyncio\n",
    "from datetime import datetime\n",
    "from tqdm.asyncio import tqdm\n",
    "import sys\n",
    "import os\n",
    "import html\n",
    "\n",
    "# Add project path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "\n",
    "from exchanges.sf_pairs_service import SFPairsService\n",
    "from custom_strategies import detect_confluence\n",
    "\n",
    "class ConfluenceScanner:\n",
    "    def __init__(self, telegram_token, telegram_chat_id, exchange, timeframe, offset=1):\n",
    "        self.telegram_token = telegram_token\n",
    "        self.telegram_chat_id = telegram_chat_id\n",
    "        self.telegram_app = None\n",
    "        self.exchange = exchange\n",
    "        self.timeframe = timeframe\n",
    "        self.offset = offset  # Added offset parameter\n",
    "        self.sf_service = SFPairsService()\n",
    "        \n",
    "    async def init_telegram(self):\n",
    "        if self.telegram_app is None:\n",
    "            self.telegram_app = Application.builder().token(self.telegram_token).build()\n",
    "\n",
    "    async def send_telegram_alert(self, results):\n",
    "        if not results:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            message = f\"🚨 Confluence Detection - {self.exchange} {self.timeframe}\\n\\n\"\n",
    "            \n",
    "            # Map timeframe to TradingView format\n",
    "            tv_timeframe_map = {\n",
    "                \"1d\": \"1D\",\n",
    "                \"2d\": \"2D\",\n",
    "                \"1w\": \"1W\"\n",
    "            }\n",
    "            tv_timeframe = tv_timeframe_map.get(self.timeframe.lower(), self.timeframe)\n",
    "            \n",
    "            for result in results:\n",
    "                exchange_name = self.exchange.upper()\n",
    "                formatted_symbol = f\"{result['symbol']}\"\n",
    "                tv_link = f\"https://www.tradingview.com/chart/?symbol={exchange_name}:{formatted_symbol}&interval={tv_timeframe}\"\n",
    "                \n",
    "                # Escape HTML entities in the URL\n",
    "                escaped_link = html.escape(tv_link)\n",
    "                \n",
    "                # Format according to specified requirements\n",
    "                time_str = \"\"\n",
    "                if result.get('timestamp') is not None:\n",
    "                    time_str = f\"Time: {result['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\\n\"\n",
    "                \n",
    "                message += (\n",
    "                    f\"Symbol: {result['symbol']}\\n\"\n",
    "                    f\"{time_str}\"\n",
    "                    f\"Volume USD: ${result['volume_usd']:,.2f}\\n\"\n",
    "                    f\"Close: <a href='{escaped_link}'>${result['close']:,.8f}</a>\\n\"\n",
    "                    f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                    f\"Close Off Low: {result['close_off_low']:.1f}%\\n\"\n",
    "                    f\"{'='*30}\\n\"\n",
    "                )\n",
    "            \n",
    "            # Split message more carefully to avoid breaking HTML tags\n",
    "            max_length = 4000  # Reduced from 4096 to be safer\n",
    "            \n",
    "            if len(message) > max_length:\n",
    "                # Split at natural breaks (between results) to avoid breaking HTML\n",
    "                sections = message.split('='*30 + '\\n')\n",
    "                current_chunk = \"\"\n",
    "                \n",
    "                for section in sections:\n",
    "                    if len(current_chunk + section + '='*30 + '\\n') > max_length:\n",
    "                        if current_chunk:\n",
    "                            await self.telegram_app.bot.send_message(\n",
    "                                chat_id=self.telegram_chat_id,\n",
    "                                text=current_chunk.strip(),\n",
    "                                parse_mode='HTML',\n",
    "                                disable_web_page_preview=True\n",
    "                            )\n",
    "                        current_chunk = section + '\\n'\n",
    "                    else:\n",
    "                        current_chunk += section + '='*30 + '\\n'\n",
    "                \n",
    "                # Send remaining chunk\n",
    "                if current_chunk.strip():\n",
    "                    await self.telegram_app.bot.send_message(\n",
    "                        chat_id=self.telegram_chat_id,\n",
    "                        text=current_chunk.strip(),\n",
    "                        parse_mode='HTML',\n",
    "                        disable_web_page_preview=True\n",
    "                    )\n",
    "            else:\n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=message,\n",
    "                    parse_mode='HTML',\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error sending Telegram alert: {str(e)}\")\n",
    "            \n",
    "            # Fallback: send without HTML formatting\n",
    "            try:\n",
    "                simple_message = f\"🚨 Confluence Detection - {self.exchange} {self.timeframe}\\n\\n\"\n",
    "                for result in results:\n",
    "                    simple_message += (\n",
    "                        f\"Symbol: {result['symbol']}\\n\"\n",
    "                        f\"Volume USD: ${result['volume_usd']:,.2f}\\n\"\n",
    "                        f\"Close: ${result['close']:,.8f}\\n\"\n",
    "                        f\"Volume Ratio: {result['volume_ratio']:.2f}x\\n\"\n",
    "                        f\"Components: Vol={result['high_volume']}, Spread={result['spread_breakout']}, Mom={result['momentum_breakout']}\\n\\n\"\n",
    "                    )\n",
    "                \n",
    "                await self.telegram_app.bot.send_message(\n",
    "                    chat_id=self.telegram_chat_id,\n",
    "                    text=simple_message,\n",
    "                    disable_web_page_preview=True\n",
    "                )\n",
    "            except Exception as fallback_error:\n",
    "                logging.error(f\"Fallback Telegram send also failed: {str(fallback_error)}\")\n",
    "\n",
    "    def prepare_sf_data(self, raw_df):\n",
    "        \"\"\"Convert SF data to confluence-compatible format\"\"\"\n",
    "        if raw_df is None or len(raw_df) == 0:\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(raw_df)\n",
    "        \n",
    "        # Convert datetime column to pandas datetime and set as index\n",
    "        if 'datetime' in df.columns:\n",
    "            df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "            df = df.set_index('datetime')\n",
    "        elif 'time' in df.columns:\n",
    "            # Convert Unix timestamp to datetime\n",
    "            df['time'] = pd.to_datetime(df['time'], unit='ms')\n",
    "            df = df.set_index('time')\n",
    "        \n",
    "        # Select only OHLCV columns needed for confluence\n",
    "        required_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "        available_cols = [col for col in required_cols if col in df.columns]\n",
    "        \n",
    "        if len(available_cols) != 5:\n",
    "            return None\n",
    "        \n",
    "        # Select and clean data\n",
    "        result_df = df[required_cols].copy()\n",
    "        \n",
    "        # Ensure numeric types\n",
    "        for col in required_cols:\n",
    "            result_df[col] = pd.to_numeric(result_df[col], errors='coerce')\n",
    "        \n",
    "        # Drop any NaN rows\n",
    "        result_df = result_df.dropna()\n",
    "        \n",
    "        return result_df\n",
    "\n",
    "    def scan_single_market(self, pair, ohlcv_data):\n",
    "        \"\"\"Scan a single market for Confluence pattern in the specified bar\"\"\"\n",
    "        try:\n",
    "            # Prepare data for confluence analysis\n",
    "            df = self.prepare_sf_data(ohlcv_data)\n",
    "            \n",
    "            if df is None or len(df) < 50:  # Need enough data for confluence\n",
    "                return None\n",
    "            \n",
    "            # Calculate which bar to check based on offset\n",
    "            check_bar = -(self.offset + 1)  # offset=0 means current bar (-1), offset=1 means last closed (-2), etc.\n",
    "            \n",
    "            # Run confluence detection\n",
    "            detected, result = detect_confluence(df, check_bar=check_bar)\n",
    "            \n",
    "            if detected:\n",
    "                # Calculate volume in USD for the target bar\n",
    "                target_close = df['close'].iloc[check_bar]\n",
    "                target_volume = df['volume'].iloc[check_bar]\n",
    "                volume_usd = float(target_close) * float(target_volume)\n",
    "                \n",
    "                confluence_result = {\n",
    "                    'symbol': f\"{pair['Token']}{pair['Quote']}\",\n",
    "                    'volume_usd': volume_usd,\n",
    "                    'close': float(target_close),\n",
    "                    'volume': float(target_volume),\n",
    "                    'volume_ratio': result['volume_ratio'],\n",
    "                    'close_off_low': result['close_off_low'],\n",
    "                    'momentum_score': result['momentum_score'],\n",
    "                    'high_volume': result['high_volume'],\n",
    "                    'spread_breakout': result['spread_breakout'],\n",
    "                    'momentum_breakout': result['momentum_breakout'],\n",
    "                    'bar_range': result['bar_range']\n",
    "                }\n",
    "                return confluence_result\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing {pair['Token']}{pair['Quote']}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    async def scan_all_markets(self):\n",
    "        \"\"\"Scan all markets for Confluence pattern\"\"\"\n",
    "        await self.init_telegram()\n",
    "        try:\n",
    "            # Define volume thresholds\n",
    "            volume_thresholds = {\n",
    "                \"1w\": 300000,\n",
    "                \"2d\": 100000,\n",
    "                \"1d\": 50000\n",
    "            }\n",
    "            min_volume = volume_thresholds.get(self.timeframe.lower(), 50000)\n",
    "            \n",
    "            # Create offset description\n",
    "            if self.offset == 0:\n",
    "                offset_desc = \"current candle\"\n",
    "            elif self.offset == 1:\n",
    "                offset_desc = \"last closed candle\"\n",
    "            else:\n",
    "                offset_desc = f\"{self.offset} candles ago\"\n",
    "            \n",
    "            print(f\"Scanning for Confluence patterns in {offset_desc}...\")\n",
    "            print(f\"Minimum volume threshold: ${min_volume:,.0f}\")\n",
    "            \n",
    "            # Get all pairs from SF service\n",
    "            pairs = self.sf_service.get_pairs_of_exchange(self.exchange)\n",
    "            print(f\"Found {len(pairs)} markets to scan...\")\n",
    "            \n",
    "            # Process all pairs with progress bar\n",
    "            all_results = []\n",
    "            with tqdm(total=len(pairs), desc=\"Scanning markets\") as pbar:\n",
    "                for pair in pairs:\n",
    "                    try:\n",
    "                        # Get OHLCV data from SF service\n",
    "                        ohlcv_data = self.sf_service.get_ohlcv_for_pair(\n",
    "                            pair['Token'], \n",
    "                            pair['Quote'], \n",
    "                            self.exchange, \n",
    "                            self.timeframe, \n",
    "                            100  # Get more data for confluence analysis\n",
    "                        )\n",
    "                        \n",
    "                        if ohlcv_data is None or len(ohlcv_data) == 0:\n",
    "                            pbar.update(1)\n",
    "                            continue\n",
    "                        \n",
    "                        df = pd.DataFrame(ohlcv_data)\n",
    "                        \n",
    "                        # Check if we have enough data\n",
    "                        if len(df) >= 50:  # Need enough for confluence analysis\n",
    "                            target_idx = -(self.offset + 1)  # Adjust index based on offset\n",
    "                            \n",
    "                            # Check volume threshold for the target candle\n",
    "                            try:\n",
    "                                target_candle_volume = float(df['close'].iloc[target_idx]) * float(df['volume'].iloc[target_idx])\n",
    "                                \n",
    "                                # Only process if volume meets threshold\n",
    "                                if target_candle_volume >= min_volume:\n",
    "                                    result = self.scan_single_market(pair, ohlcv_data)\n",
    "                                    if result:\n",
    "                                        all_results.append(result)\n",
    "                                        print(f\"Found Confluence: {pair['Token']}{pair['Quote']} 🎯\")\n",
    "                            except (IndexError, ValueError):\n",
    "                                pass  # Skip if we can't calculate volume\n",
    "                                    \n",
    "                    except Exception as e:\n",
    "                        if \"500\" not in str(e):  # Don't log 500 errors\n",
    "                            logging.error(f\"Error processing {pair['Token']}{pair['Quote']}: {str(e)}\")\n",
    "                    finally:\n",
    "                        pbar.update(1)\n",
    "            \n",
    "            # Sort by volume\n",
    "            all_results.sort(key=lambda x: x['volume_usd'], reverse=True)\n",
    "            \n",
    "            # Send Telegram alert if we found any patterns\n",
    "            if all_results:\n",
    "                await self.send_telegram_alert(all_results)\n",
    "            \n",
    "            return all_results\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error scanning markets: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "async def run_confluence_scanner(exchange, timeframe, offset=1):\n",
    "    \"\"\"\n",
    "    Run the Confluence scanner\n",
    "    \n",
    "    Parameters:\n",
    "    exchange (str): Exchange name (Kucoin, Mexc, Binance)\n",
    "    timeframe (str): Time period (1d, 2d, 1w)\n",
    "    offset (int): Bar offset (0=current, 1=last closed, 2=two bars ago, etc.)\n",
    "    \"\"\"\n",
    "    \n",
    "    if offset == 0:\n",
    "        offset_desc = \"current candle\"\n",
    "    elif offset == 1:\n",
    "        offset_desc = \"last closed candle\"\n",
    "    else:\n",
    "        offset_desc = f\"{offset} candles ago\"\n",
    "    \n",
    "    print(f\"Starting Confluence scan for {offset_desc} on {exchange} {timeframe}...\")\n",
    "    \n",
    "    # Use the confluence telegram token from your big project config\n",
    "    # You should replace this with the actual token from utils/config.py TELEGRAM_TOKENS[\"confluence\"]\n",
    "    telegram_token = \"8066329517:AAHVr6kufZWe8UqCKPfmsRhSPleNlt_7G-g\"  # Replace with confluence token\n",
    "    telegram_chat_id = \"375812423\"  # Your chat ID\n",
    "    \n",
    "    scanner = ConfluenceScanner(telegram_token, telegram_chat_id, exchange, timeframe, offset)\n",
    "    results = await scanner.scan_all_markets()\n",
    "    \n",
    "    if results:\n",
    "        print(f\"\\nFound {len(results)} Confluence patterns:\")\n",
    "        \n",
    "        # Convert results to DataFrame for console display\n",
    "        df_results = pd.DataFrame(results)\n",
    "        \n",
    "        # Round numeric columns\n",
    "        df_results['volume_usd'] = df_results['volume_usd'].round(2)\n",
    "        df_results['close'] = df_results['close'].round(8)\n",
    "        df_results['volume'] = df_results['volume'].round(2)\n",
    "        df_results['volume_ratio'] = df_results['volume_ratio'].round(2)\n",
    "        df_results['close_off_low'] = df_results['close_off_low'].round(1)\n",
    "        df_results['momentum_score'] = df_results['momentum_score'].round(4)\n",
    "        \n",
    "        # Reorder columns for better display\n",
    "        display_cols = ['symbol', 'close', 'volume_usd', 'volume_ratio', 'close_off_low', \n",
    "                       'momentum_score', 'high_volume', 'spread_breakout', 'momentum_breakout']\n",
    "        available_cols = [col for col in display_cols if col in df_results.columns]\n",
    "        \n",
    "        # Display the results\n",
    "        print(df_results[available_cols])\n",
    "        \n",
    "        # Show component analysis\n",
    "        print(f\"\\n🔧 COMPONENT ANALYSIS:\")\n",
    "        vol_count = df_results['high_volume'].sum()\n",
    "        spread_count = df_results['spread_breakout'].sum()\n",
    "        momentum_count = df_results['momentum_breakout'].sum()\n",
    "        \n",
    "        print(f\"High Volume signals: {vol_count}/{len(results)} ({vol_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Spread Breakout signals: {spread_count}/{len(results)} ({spread_count/len(results)*100:.1f}%)\")\n",
    "        print(f\"Momentum Breakout signals: {momentum_count}/{len(results)} ({momentum_count/len(results)*100:.1f}%)\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nNo Confluence patterns found in {offset_desc}\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "# Apply nest_asyncio to allow async operations in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Example usage functions\n",
    "async def scan_current_confluence():\n",
    "    \"\"\"Scan current candle for confluence\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", offset=0)\n",
    "\n",
    "async def scan_closed_confluence():\n",
    "    \"\"\"Scan last closed candle for confluence\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", offset=1)\n",
    "\n",
    "async def scan_previous_confluence():\n",
    "    \"\"\"Scan two candles ago for confluence\"\"\"\n",
    "    await run_confluence_scanner(\"Kucoin\", \"1w\", offset=2)\n",
    "\n",
    "# Main execution function\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    Main execution - modify parameters here\n",
    "    \"\"\"\n",
    "    exchange = \"Mexc\"  # Binance, Kucoin, Mexc\n",
    "    timeframe = \"1w\"     # 1d, 2d, 1w\n",
    "    offset = 0           # 0 = current candle, 1 = last closed candle, 2 = two candles ago\n",
    "    \n",
    "    await run_confluence_scanner(exchange, timeframe, offset)\n",
    "\n",
    "# Run the async main function\n",
    "print(\"🔍 CONFLUENCE SCANNER\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Available functions:\")\n",
    "print(\"• await main() - Run with default settings\")\n",
    "print(\"• await scan_current_confluence() - Scan current candle\")\n",
    "print(\"• await scan_closed_confluence() - Scan last closed candle\")\n",
    "print(\"• await scan_previous_confluence() - Scan two candles ago\")\n",
    "print(\"• await run_confluence_scanner('Exchange', 'timeframe', offset) - Custom scan\")\n",
    "print(\"\\nExample: await main()\")\n",
    "\n",
    "# Uncomment to auto-run:\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016f39c-4a43-4dba-ab57-5c161bff6e4a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Direct Test Bar Pattern Tester\n",
    "# This script directly tests the calculate_test_bar function\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Apply nest_asyncio to make asyncio work in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "\n",
    "# Add project directory to path\n",
    "project_dir = os.path.join(os.getcwd(), \"Project\")\n",
    "sys.path.insert(0, project_dir)\n",
    "print(f\"✓ Added {project_dir} to sys.path\")\n",
    "\n",
    "# Import the necessary modules\n",
    "from exchanges import MexcSpotClient, BybitSpotClient, KucoinSpotClient\n",
    "\n",
    "def calculate_test_bar_direct(df):\n",
    "    \"\"\"\n",
    "    Direct implementation of Test Bar pattern detection for testing\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate basic metrics\n",
    "    df['bar_range'] = df['high'] - df['low']\n",
    "    \n",
    "    # Function to check if current bar is an inside bar\n",
    "    df['is_inside_bar'] = (df['high'] < df['high'].shift(1)) & (df['low'] > df['low'].shift(1))\n",
    "    \n",
    "    # Function to check if bar is down (close < open)\n",
    "    df['is_down_bar'] = df['close'] < df['open']\n",
    "    \n",
    "    # Function to check if close is in higher 65% of the spread (closing off the lows)\n",
    "    df['close_position'] = np.where(df['bar_range'] != 0, (df['close'] - df['low']) / df['bar_range'], 0)\n",
    "    df['close_off_lows'] = df['close_position'] >= 0.65\n",
    "    \n",
    "    # Function to check if current volume is less than 40% of previous bar volume\n",
    "    df['lower_volume_than_prev'] = df['volume'] < (df['volume'].shift(1) * 0.4)\n",
    "    \n",
    "    # Function to check if current volume is the lowest in last 3 bars\n",
    "    df['lowest_volume_in_3_bars'] = (df['volume'] < df['volume'].shift(1)) & (df['volume'] < df['volume'].shift(2))\n",
    "    \n",
    "    # Debug columns\n",
    "    df['debug_inside'] = df['is_inside_bar']\n",
    "    df['debug_down'] = df['is_down_bar'] \n",
    "    df['debug_close_off_lows'] = df['close_off_lows']\n",
    "    df['debug_lower_vol'] = df['lower_volume_than_prev']\n",
    "    df['debug_lowest_vol_3'] = df['lowest_volume_in_3_bars']\n",
    "    \n",
    "    # Main condition: all criteria must be met\n",
    "    test_bar_pattern = (\n",
    "        df['is_inside_bar'] &\n",
    "        df['is_down_bar'] &\n",
    "        df['close_off_lows'] &\n",
    "        df['lower_volume_than_prev'] &\n",
    "        df['lowest_volume_in_3_bars']\n",
    "    )\n",
    "    \n",
    "    # Signal only new occurrences\n",
    "    test_bar = test_bar_pattern & ~test_bar_pattern.shift(1).fillna(False)\n",
    "    \n",
    "    return test_bar, df\n",
    "\n",
    "async def test_direct_test_bar(exchange_client_class, timeframe, symbol):\n",
    "    \"\"\"Test the direct test_bar function on a specific symbol\"\"\"\n",
    "    print(f\"Testing DIRECT Test Bar detection on {symbol} ({timeframe})\")\n",
    "    \n",
    "    # Initialize exchange client and fetch data\n",
    "    client = exchange_client_class(timeframe=timeframe)\n",
    "    try:\n",
    "        await client.init_session()\n",
    "        df = await client.fetch_klines(symbol)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {symbol}: {str(e)}\")\n",
    "        return\n",
    "    finally:\n",
    "        await client.close_session()\n",
    "    \n",
    "    if df is None or len(df) < 10:\n",
    "        print(f\"No data fetched for {symbol} or insufficient data\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\\\nLast 5 bars for {symbol}:\")\n",
    "    print(df[['open', 'high', 'low', 'close', 'volume']].tail(5))\n",
    "    \n",
    "    # Apply direct test_bar function\n",
    "    print(\"\\\\nApplying direct test_bar detection...\")\n",
    "    try:\n",
    "        test_bar_signals, df_with_debug = calculate_test_bar_direct(df)\n",
    "        \n",
    "        # Quick results first\n",
    "        current_detected = test_bar_signals.iloc[-1]\n",
    "        prev_detected = test_bar_signals.iloc[-2] if len(df) > 1 else False\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"QUICK RESULTS\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Current Bar Test Pattern:  {current_detected}\")\n",
    "        print(f\"Previous Bar Test Pattern: {prev_detected}\")\n",
    "        \n",
    "        # If pattern detected, show which bar(s)\n",
    "        if current_detected or prev_detected:\n",
    "            print(\"\\\\nPATTERN DETECTED!\")\n",
    "            if current_detected:\n",
    "                print(\"  -> Current bar matches test pattern\")\n",
    "            if prev_detected:\n",
    "                print(\"  -> Previous bar matches test pattern\")\n",
    "        else:\n",
    "            print(\"\\\\nNO PATTERN DETECTED\")\n",
    "        \n",
    "        print(\"\\\\n\" + \"=\"*60)\n",
    "        print(\"CONDITION BREAKDOWN\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Show only last 2 bars for condition analysis\n",
    "        for i in range(max(0, len(df)-2), len(df)):\n",
    "            if i < 2:  # Skip early bars that don't have enough history\n",
    "                continue\n",
    "            \n",
    "            bar_range = df['high'].iloc[i] - df['low'].iloc[i]\n",
    "            close_position = (df['close'].iloc[i] - df['low'].iloc[i]) / bar_range * 100 if bar_range > 0 else 0\n",
    "            \n",
    "            print(f\"\\\\nBAR {i} ({df.index[i].date()})\")\n",
    "            print(f\"OHLC: O={df['open'].iloc[i]:.6f} H={df['high'].iloc[i]:.6f} L={df['low'].iloc[i]:.6f} C={df['close'].iloc[i]:.6f}\")\n",
    "            print(f\"Volume: {df['volume'].iloc[i]:,.0f}\")\n",
    "            \n",
    "            if i > 0:\n",
    "                prev_high = df['high'].iloc[i-1]\n",
    "                prev_low = df['low'].iloc[i-1]\n",
    "                prev_volume = df['volume'].iloc[i-1]\n",
    "                volume_40_pct = prev_volume * 0.4\n",
    "                \n",
    "                # Show conditions in a clean table format\n",
    "                conditions = [\n",
    "                    (\"Inside Bar\", df_with_debug['debug_inside'].iloc[i]),\n",
    "                    (\"Down Bar\", df_with_debug['debug_down'].iloc[i]),\n",
    "                    (\"Close >= 65% from Low\", df_with_debug['debug_close_off_lows'].iloc[i]),\n",
    "                    (\"Volume < 40% of Previous\", df_with_debug['debug_lower_vol'].iloc[i]),\n",
    "                    (\"Lowest Volume in 3 bars\", df_with_debug['debug_lowest_vol_3'].iloc[i])\n",
    "                ]\n",
    "                \n",
    "                print(\"\\\\nConditions:\")\n",
    "                for condition_name, result in conditions:\n",
    "                    status = \"✓\" if result else \"✗\"\n",
    "                    print(f\"  {status} {condition_name:<25} {result}\")\n",
    "                \n",
    "                # Show key metrics\n",
    "                print(\"\\\\nKey Metrics:\")\n",
    "                print(f\"  Close Position: {close_position:.1f}% from low\")\n",
    "                print(f\"  Current Volume: {df['volume'].iloc[i]:,.0f}\")\n",
    "                print(f\"  40% of Prev Vol: {volume_40_pct:,.0f}\")\n",
    "                \n",
    "                if i > 1:\n",
    "                    vol_prev_2 = df['volume'].iloc[i-2]\n",
    "                    print(f\"  Previous Vol: {prev_volume:,.0f}\")\n",
    "                    print(f\"  Previous-2 Vol: {vol_prev_2:,.0f}\")\n",
    "                \n",
    "                # Final result for this bar\n",
    "                all_conditions_met = all(result for _, result in conditions)\n",
    "                print(f\"\\\\nAll Conditions Met: {all_conditions_met}\")\n",
    "                print(f\"Test Bar Signal: {test_bar_signals.iloc[i]}\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error running direct test_bar detection: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Test parameters\n",
    "exchange_client = KucoinSpotClient\n",
    "timeframe = \"1d\"\n",
    "symbol = \"TEL-USDT\"\n",
    "\n",
    "# Run the test\n",
    "await test_direct_test_bar(exchange_client, timeframe, symbol)\n",
    "\n",
    "print(\"\\\\n✅ Direct test bar detection test completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f0c836-afa7-4fba-94d7-0dfafef0f8c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Standalone HLC Bar Chart Plotter\n",
    "A reusable function for plotting HLC bars with optional pattern highlighting\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "def plot_hlc_bars(data, highlighted_bars=None, title=\"HLC Chart\", symbol=\"SYMBOL\", \n",
    "                  interval=\"1d\", semilog=False, highlight_color=\"fuchsia\", \n",
    "                  highlight_label=\"Pattern\", figsize=(14, 10), show_volume=True):\n",
    "    \"\"\"\n",
    "    Plot HLC bar chart with optional pattern highlighting\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pandas.DataFrame\n",
    "        DataFrame with columns: ['datetime', 'high', 'low', 'close', 'volume']\n",
    "        - datetime: timestamp column (will be used for x-axis)\n",
    "        - high: high prices\n",
    "        - low: low prices  \n",
    "        - close: close prices\n",
    "        - volume: volume data (optional if show_volume=False)\n",
    "        \n",
    "    highlighted_bars : pandas.Series or list/array, optional\n",
    "        Boolean series or array indicating which bars to highlight\n",
    "        Length must match data length\n",
    "        \n",
    "    title : str, default \"HLC Chart\"\n",
    "        Chart title\n",
    "        \n",
    "    symbol : str, default \"SYMBOL\" \n",
    "        Symbol name for display\n",
    "        \n",
    "    interval : str, default \"1d\"\n",
    "        Time interval for date formatting (1m, 5m, 15m, 30m, 1h, 4h, 1d, 3d, 1w, 1M)\n",
    "        \n",
    "    semilog : bool, default False\n",
    "        Use logarithmic scale for price chart\n",
    "        \n",
    "    highlight_color : str, default \"fuchsia\"\n",
    "        Color for highlighted bars\n",
    "        \n",
    "    highlight_label : str, default \"Pattern\"\n",
    "        Label for highlighted bars in legend\n",
    "        \n",
    "    figsize : tuple, default (14, 10)\n",
    "        Figure size (width, height)\n",
    "        \n",
    "    show_volume : bool, default True\n",
    "        Whether to show volume subplot\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    matplotlib.figure.Figure\n",
    "        The created figure object\n",
    "    \"\"\"\n",
    "    \n",
    "    # Input validation\n",
    "    if not isinstance(data, pd.DataFrame):\n",
    "        raise ValueError(\"data must be a pandas DataFrame\")\n",
    "    \n",
    "    # Check required columns\n",
    "    required_cols = ['datetime', 'high', 'low', 'close']\n",
    "    if show_volume:\n",
    "        required_cols.append('volume')\n",
    "    \n",
    "    missing_cols = [col for col in required_cols if col not in data.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        raise ValueError(\"data DataFrame is empty\")\n",
    "    \n",
    "    # Validate highlighted_bars\n",
    "    if highlighted_bars is not None:\n",
    "        if len(highlighted_bars) != len(data):\n",
    "            raise ValueError(\"highlighted_bars length must match data length\")\n",
    "        # Convert to boolean array\n",
    "        highlighted_bars = np.array(highlighted_bars, dtype=bool)\n",
    "    else:\n",
    "        highlighted_bars = np.zeros(len(data), dtype=bool)\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    if show_volume:\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=figsize, \n",
    "                                       gridspec_kw={'height_ratios': [3, 1]})\n",
    "    else:\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=figsize)\n",
    "        ax2 = None\n",
    "    \n",
    "    # Convert dates to numbers for plotting\n",
    "    dates = mdates.date2num(data['datetime'])\n",
    "    \n",
    "    # Calculate margins and tick length\n",
    "    date_range = dates[-1] - dates[0] if len(dates) > 1 else 1\n",
    "    margin = date_range * 0.05\n",
    "    \n",
    "    # Calculate actual bar spacing for consistent tick length\n",
    "    if len(dates) > 1:\n",
    "        avg_bar_spacing = date_range / (len(dates) - 1)\n",
    "        tick_length = avg_bar_spacing * 0.4  # 40% of bar spacing\n",
    "        volume_bar_width = avg_bar_spacing * 0.8\n",
    "    else:\n",
    "        tick_length = date_range * 0.01\n",
    "        volume_bar_width = date_range * 0.02\n",
    "    \n",
    "    # Draw HLC bars\n",
    "    for i, (date, high, low, close) in enumerate(zip(dates, data['high'], data['low'], data['close'])):\n",
    "        is_highlighted = highlighted_bars[i]\n",
    "        color = highlight_color if is_highlighted else 'black'\n",
    "        line_width = 1.2\n",
    "        \n",
    "        # Vertical line from low to high\n",
    "        ax1.plot([date, date], [low, high], color=color, linewidth=line_width, solid_capstyle='butt')\n",
    "        \n",
    "        # Horizontal tick mark for close (on the right side)\n",
    "        ax1.plot([date, date + tick_length], [close, close], color=color, \n",
    "                linewidth=line_width+0.5, solid_capstyle='butt')\n",
    "    \n",
    "    # Configure price chart\n",
    "    if semilog:\n",
    "        ax1.set_yscale('log')\n",
    "        scale_text = \"Semilog Scale\"\n",
    "    else:\n",
    "        scale_text = \"Linear Scale\"\n",
    "    \n",
    "    ax1.set_title(f'{symbol} {title} - {scale_text}', fontsize=16, fontweight='bold')\n",
    "    ax1.set_ylabel('Price', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format x-axis based on timeframe\n",
    "    _format_datetime_axis(ax1, interval)\n",
    "    ax1.set_xlim(dates[0] - margin, dates[-1] + margin)\n",
    "    \n",
    "    # Volume chart\n",
    "    if show_volume and ax2 is not None:\n",
    "        volume_colors = [highlight_color if highlighted_bars[i] else 'orange' for i in range(len(dates))]\n",
    "        volume_edges = ['darkmagenta' if highlighted_bars[i] else 'darkorange' for i in range(len(dates))]\n",
    "        \n",
    "        ax2.bar(dates, data['volume'], width=volume_bar_width, alpha=0.6, \n",
    "                color=volume_colors, edgecolor=volume_edges)\n",
    "        ax2.set_ylabel('Volume', fontsize=12)\n",
    "        ax2.set_xlabel('Date', fontsize=12)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        _format_datetime_axis(ax2, interval)\n",
    "        ax2.set_xlim(dates[0] - margin, dates[-1] + margin)\n",
    "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
    "    else:\n",
    "        ax1.set_xlabel('Date', fontsize=12)\n",
    "    \n",
    "    # Create legend\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='black', linewidth=2, label='High-Low Range'),\n",
    "        Line2D([0], [0], color='black', linewidth=3, label='Close Price (right tick)')\n",
    "    ]\n",
    "    \n",
    "    # Add highlighted bars to legend if any exist\n",
    "    if highlighted_bars.any():\n",
    "        legend_elements.append(\n",
    "            Line2D([0], [0], color=highlight_color, linewidth=3, label=highlight_label)\n",
    "        )\n",
    "        highlight_count = highlighted_bars.sum()\n",
    "    else:\n",
    "        highlight_count = 0\n",
    "    \n",
    "    ax1.legend(handles=legend_elements, loc='upper left', title=scale_text)\n",
    "    \n",
    "    # Add pattern count if patterns exist\n",
    "    if highlight_count > 0:\n",
    "        ax1.text(0.99, 0.95, f'{highlight_label}: {highlight_count}', \n",
    "                transform=ax1.transAxes, ha='right', va='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                fontsize=10)\n",
    "    \n",
    "    plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def _format_datetime_axis(ax, interval):\n",
    "    \"\"\"Helper function to format datetime axis based on interval\"\"\"\n",
    "    if interval in ['1m', '5m', '15m', '30m']:\n",
    "        ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d %H:%M'))\n",
    "    elif interval in ['1h', '2h', '4h', '6h', '12h']:\n",
    "        ax.xaxis.set_major_locator(mdates.DayLocator(interval=1))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "    elif interval in ['1d', '3d']:\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    else:  # weekly, monthly\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=6))\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "\n",
    "# Example usage and test function\n",
    "def example_usage():\n",
    "    \"\"\"Example showing how to use the plot_hlc_bars function\"\"\"\n",
    "    \n",
    "    # Create sample data\n",
    "    import datetime\n",
    "    dates = pd.date_range('2023-01-01', periods=100, freq='D')\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate realistic OHLC data\n",
    "    closes = 100 + np.cumsum(np.random.randn(100) * 0.02)\n",
    "    highs = closes + np.random.rand(100) * 5\n",
    "    lows = closes - np.random.rand(100) * 5\n",
    "    volumes = np.random.rand(100) * 1000000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'datetime': dates,\n",
    "        'high': highs,\n",
    "        'low': lows, \n",
    "        'close': closes,\n",
    "        'volume': volumes\n",
    "    })\n",
    "    \n",
    "    # Create some random pattern detections\n",
    "    pattern_detected = np.random.choice([True, False], size=100, p=[0.1, 0.9])\n",
    "    \n",
    "    # Plot with pattern highlighting\n",
    "    fig = plot_hlc_bars(\n",
    "        data=data,\n",
    "        highlighted_bars=pattern_detected,\n",
    "        title=\"Daily Chart with Pattern Detection\",\n",
    "        symbol=\"EXAMPLE\",\n",
    "        interval=\"1d\",\n",
    "        semilog=False,\n",
    "        highlight_color=\"red\",\n",
    "        highlight_label=\"Detected Pattern\"\n",
    "    )\n",
    "    \n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "# Scanner integration example\n",
    "def scanner_integration_example():\n",
    "    \"\"\"Example of how to integrate with a scanner function\"\"\"\n",
    "    \n",
    "    def my_pattern_scanner(data):\n",
    "        \"\"\"\n",
    "        Example scanner function - replace with your actual scanner logic\n",
    "        Returns boolean array indicating pattern detection\n",
    "        \"\"\"\n",
    "        # Example: detect when close > 20-period moving average\n",
    "        ma20 = data['close'].rolling(20).mean()\n",
    "        pattern = (data['close'] > ma20) & (data['volume'] > data['volume'].rolling(10).mean())\n",
    "        return pattern.fillna(False)\n",
    "    \n",
    "    # Your data loading logic here\n",
    "    # data = load_your_data()  # Replace with actual data loading\n",
    "    \n",
    "    # For demo, create sample data\n",
    "    dates = pd.date_range('2023-01-01', periods=200, freq='D')\n",
    "    np.random.seed(42)\n",
    "    closes = 100 + np.cumsum(np.random.randn(200) * 0.02)\n",
    "    highs = closes + np.random.rand(200) * 3\n",
    "    lows = closes - np.random.rand(200) * 3\n",
    "    volumes = np.random.rand(200) * 1000000\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'datetime': dates,\n",
    "        'high': highs,\n",
    "        'low': lows,\n",
    "        'close': closes,\n",
    "        'volume': volumes\n",
    "    })\n",
    "    \n",
    "    # Run your scanner\n",
    "    detected_patterns = my_pattern_scanner(data)\n",
    "    \n",
    "    # Plot only if patterns are detected\n",
    "    if detected_patterns.any():\n",
    "        print(f\"Patterns detected! Found {detected_patterns.sum()} occurrences\")\n",
    "        fig = plot_hlc_bars(\n",
    "            data=data,\n",
    "            highlighted_bars=detected_patterns,\n",
    "            title=\"Scanner Results\",\n",
    "            symbol=\"SCANNED_SYMBOL\",\n",
    "            interval=\"1d\",\n",
    "            highlight_color=\"lime\",\n",
    "            highlight_label=\"Scanner Hit\"\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No patterns detected\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run example\n",
    "    example_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
